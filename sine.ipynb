{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWYb/ol4xLuI/RFGG/gsIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohankrishna9581/sinex/blob/main/sine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zKZyCoFLLU6n",
        "outputId": "3b57be63-d055-4b35-9065-99ad5a787f03"
      },
      "source": [
        "#Toy Problem Y=sin(x) 1000 samples of period -2pi to 2pi\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 1000                                                                   # No.of samples\n",
        "SEED = 1400                                                                                                     \n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=-(2*math.pi), high=2*math.pi,size=SAMPLES)      # x values selected uniformly in the range of -2pi to 2pi\n",
        "np.random.shuffle(x_values)                                                                                   \n",
        "y_values = np.sin(x_values)                                                      # y = sin(x)\n",
        "plt.plot(x_values,y_values, 'b.')                                                # plotting x,y values\n",
        "#plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)                                 # adding some random noise tol sine plot\n",
        "plt.plot(x_values, y_values, 'b.')                                               # plotting noisy data \n",
        "#plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)                                                 # splitting training data from samples\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)                                    # splitting test data from samples\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])      \n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])      \n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES                 # asserting samples to train, validate and test\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")                                  # plotting train graph\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")                         # plotting validate graph\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")                                     # plotting test graph \n",
        "plt.legend()                                                                     # plotting three graphs on one plot\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_1 = tf.keras.Sequential()                                                   \n",
        "model_1.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_1.add(layers.Dense(16, activation='relu'))\n",
        "model_1.add(layers.Dense(1))\n",
        "model_1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "#model_1.summary()\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=600, batch_size=16, validation_data=(x_validate, y_validate))\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_1.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n",
            "Train on 600 samples, validate on 200 samples\n",
            "Epoch 1/600\n",
            "600/600 [==============================] - 0s 375us/sample - loss: 2.7239 - mae: 1.2051 - val_loss: 1.4306 - val_mae: 0.8887\n",
            "Epoch 2/600\n",
            "600/600 [==============================] - 0s 82us/sample - loss: 1.0300 - mae: 0.8052 - val_loss: 0.6717 - val_mae: 0.6837\n",
            "Epoch 3/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.5565 - mae: 0.6425 - val_loss: 0.4520 - val_mae: 0.5669\n",
            "Epoch 4/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.4289 - mae: 0.5634 - val_loss: 0.3911 - val_mae: 0.5224\n",
            "Epoch 5/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.3849 - mae: 0.5288 - val_loss: 0.3592 - val_mae: 0.5044\n",
            "Epoch 6/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.3595 - mae: 0.5147 - val_loss: 0.3551 - val_mae: 0.4933\n",
            "Epoch 7/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.3332 - mae: 0.4935 - val_loss: 0.3099 - val_mae: 0.4674\n",
            "Epoch 8/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.2981 - mae: 0.4701 - val_loss: 0.2782 - val_mae: 0.4430\n",
            "Epoch 9/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.2730 - mae: 0.4493 - val_loss: 0.2572 - val_mae: 0.4294\n",
            "Epoch 10/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.2585 - mae: 0.4398 - val_loss: 0.2381 - val_mae: 0.4096\n",
            "Epoch 11/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.2435 - mae: 0.4263 - val_loss: 0.2397 - val_mae: 0.4080\n",
            "Epoch 12/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.2259 - mae: 0.4082 - val_loss: 0.2259 - val_mae: 0.3959\n",
            "Epoch 13/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.2138 - mae: 0.3971 - val_loss: 0.1976 - val_mae: 0.3724\n",
            "Epoch 14/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.2025 - mae: 0.3830 - val_loss: 0.1829 - val_mae: 0.3592\n",
            "Epoch 15/600\n",
            "600/600 [==============================] - 0s 82us/sample - loss: 0.1897 - mae: 0.3713 - val_loss: 0.1776 - val_mae: 0.3497\n",
            "Epoch 16/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.1833 - mae: 0.3625 - val_loss: 0.1693 - val_mae: 0.3421\n",
            "Epoch 17/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.1785 - mae: 0.3567 - val_loss: 0.1560 - val_mae: 0.3281\n",
            "Epoch 18/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.1690 - mae: 0.3452 - val_loss: 0.1510 - val_mae: 0.3211\n",
            "Epoch 19/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1660 - mae: 0.3393 - val_loss: 0.1527 - val_mae: 0.3170\n",
            "Epoch 20/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.1592 - mae: 0.3290 - val_loss: 0.1431 - val_mae: 0.3077\n",
            "Epoch 21/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.1564 - mae: 0.3213 - val_loss: 0.1495 - val_mae: 0.3109\n",
            "Epoch 22/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.1535 - mae: 0.3191 - val_loss: 0.1379 - val_mae: 0.2995\n",
            "Epoch 23/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.1512 - mae: 0.3144 - val_loss: 0.1441 - val_mae: 0.3000\n",
            "Epoch 24/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1504 - mae: 0.3117 - val_loss: 0.1296 - val_mae: 0.2895\n",
            "Epoch 25/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1467 - mae: 0.3048 - val_loss: 0.1320 - val_mae: 0.2845\n",
            "Epoch 26/600\n",
            "600/600 [==============================] - 0s 84us/sample - loss: 0.1472 - mae: 0.3026 - val_loss: 0.1332 - val_mae: 0.2859\n",
            "Epoch 27/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.1446 - mae: 0.2993 - val_loss: 0.1290 - val_mae: 0.2817\n",
            "Epoch 28/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1394 - mae: 0.2931 - val_loss: 0.1311 - val_mae: 0.2814\n",
            "Epoch 29/600\n",
            "600/600 [==============================] - 0s 83us/sample - loss: 0.1432 - mae: 0.2957 - val_loss: 0.1347 - val_mae: 0.2841\n",
            "Epoch 30/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1399 - mae: 0.2925 - val_loss: 0.1314 - val_mae: 0.2794\n",
            "Epoch 31/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1408 - mae: 0.2899 - val_loss: 0.1230 - val_mae: 0.2736\n",
            "Epoch 32/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.1398 - mae: 0.2875 - val_loss: 0.1207 - val_mae: 0.2697\n",
            "Epoch 33/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1381 - mae: 0.2879 - val_loss: 0.1227 - val_mae: 0.2689\n",
            "Epoch 34/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.1375 - mae: 0.2863 - val_loss: 0.1190 - val_mae: 0.2686\n",
            "Epoch 35/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.1326 - mae: 0.2810 - val_loss: 0.1215 - val_mae: 0.2709\n",
            "Epoch 36/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.1363 - mae: 0.2838 - val_loss: 0.1191 - val_mae: 0.2653\n",
            "Epoch 37/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.1335 - mae: 0.2780 - val_loss: 0.1359 - val_mae: 0.2780\n",
            "Epoch 38/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.1303 - mae: 0.2750 - val_loss: 0.1257 - val_mae: 0.2688\n",
            "Epoch 39/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1312 - mae: 0.2770 - val_loss: 0.1145 - val_mae: 0.2619\n",
            "Epoch 40/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.1307 - mae: 0.2742 - val_loss: 0.1150 - val_mae: 0.2604\n",
            "Epoch 41/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1305 - mae: 0.2741 - val_loss: 0.1154 - val_mae: 0.2639\n",
            "Epoch 42/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1306 - mae: 0.2758 - val_loss: 0.1156 - val_mae: 0.2612\n",
            "Epoch 43/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.1286 - mae: 0.2737 - val_loss: 0.1122 - val_mae: 0.2564\n",
            "Epoch 44/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.1286 - mae: 0.2700 - val_loss: 0.1110 - val_mae: 0.2568\n",
            "Epoch 45/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.1279 - mae: 0.2709 - val_loss: 0.1124 - val_mae: 0.2587\n",
            "Epoch 46/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.1264 - mae: 0.2676 - val_loss: 0.1143 - val_mae: 0.2587\n",
            "Epoch 47/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.1260 - mae: 0.2672 - val_loss: 0.1137 - val_mae: 0.2600\n",
            "Epoch 48/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1210 - mae: 0.2628 - val_loss: 0.1145 - val_mae: 0.2603\n",
            "Epoch 49/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1233 - mae: 0.2652 - val_loss: 0.1094 - val_mae: 0.2520\n",
            "Epoch 50/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1205 - mae: 0.2633 - val_loss: 0.1162 - val_mae: 0.2582\n",
            "Epoch 51/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.1219 - mae: 0.2603 - val_loss: 0.1155 - val_mae: 0.2600\n",
            "Epoch 52/600\n",
            "600/600 [==============================] - 0s 81us/sample - loss: 0.1170 - mae: 0.2557 - val_loss: 0.1148 - val_mae: 0.2586\n",
            "Epoch 53/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.1172 - mae: 0.2586 - val_loss: 0.1088 - val_mae: 0.2511\n",
            "Epoch 54/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.1197 - mae: 0.2605 - val_loss: 0.1088 - val_mae: 0.2493\n",
            "Epoch 55/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.1153 - mae: 0.2545 - val_loss: 0.1174 - val_mae: 0.2595\n",
            "Epoch 56/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.1156 - mae: 0.2551 - val_loss: 0.1086 - val_mae: 0.2490\n",
            "Epoch 57/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.1157 - mae: 0.2522 - val_loss: 0.1018 - val_mae: 0.2413\n",
            "Epoch 58/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1142 - mae: 0.2526 - val_loss: 0.1011 - val_mae: 0.2419\n",
            "Epoch 59/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.1131 - mae: 0.2525 - val_loss: 0.1062 - val_mae: 0.2410\n",
            "Epoch 60/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1122 - mae: 0.2495 - val_loss: 0.1063 - val_mae: 0.2472\n",
            "Epoch 61/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.1098 - mae: 0.2462 - val_loss: 0.1006 - val_mae: 0.2404\n",
            "Epoch 62/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.1115 - mae: 0.2492 - val_loss: 0.1007 - val_mae: 0.2427\n",
            "Epoch 63/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.1086 - mae: 0.2442 - val_loss: 0.1019 - val_mae: 0.2433\n",
            "Epoch 64/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.1110 - mae: 0.2473 - val_loss: 0.1039 - val_mae: 0.2448\n",
            "Epoch 65/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.1069 - mae: 0.2424 - val_loss: 0.0962 - val_mae: 0.2327\n",
            "Epoch 66/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1034 - mae: 0.2419 - val_loss: 0.0972 - val_mae: 0.2348\n",
            "Epoch 67/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0992 - mae: 0.2347 - val_loss: 0.0924 - val_mae: 0.2293\n",
            "Epoch 68/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.1009 - mae: 0.2384 - val_loss: 0.0981 - val_mae: 0.2336\n",
            "Epoch 69/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.1018 - mae: 0.2358 - val_loss: 0.0905 - val_mae: 0.2285\n",
            "Epoch 70/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0991 - mae: 0.2350 - val_loss: 0.0883 - val_mae: 0.2244\n",
            "Epoch 71/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0997 - mae: 0.2367 - val_loss: 0.0906 - val_mae: 0.2231\n",
            "Epoch 72/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0975 - mae: 0.2304 - val_loss: 0.0943 - val_mae: 0.2327\n",
            "Epoch 73/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0973 - mae: 0.2318 - val_loss: 0.0902 - val_mae: 0.2303\n",
            "Epoch 74/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0934 - mae: 0.2271 - val_loss: 0.1040 - val_mae: 0.2366\n",
            "Epoch 75/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0956 - mae: 0.2286 - val_loss: 0.0895 - val_mae: 0.2256\n",
            "Epoch 76/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0922 - mae: 0.2276 - val_loss: 0.0990 - val_mae: 0.2284\n",
            "Epoch 77/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0945 - mae: 0.2285 - val_loss: 0.0903 - val_mae: 0.2266\n",
            "Epoch 78/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0922 - mae: 0.2257 - val_loss: 0.0981 - val_mae: 0.2374\n",
            "Epoch 79/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0920 - mae: 0.2230 - val_loss: 0.0864 - val_mae: 0.2232\n",
            "Epoch 80/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0928 - mae: 0.2257 - val_loss: 0.0813 - val_mae: 0.2137\n",
            "Epoch 81/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0914 - mae: 0.2213 - val_loss: 0.0806 - val_mae: 0.2131\n",
            "Epoch 82/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0879 - mae: 0.2201 - val_loss: 0.0900 - val_mae: 0.2295\n",
            "Epoch 83/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0885 - mae: 0.2200 - val_loss: 0.0793 - val_mae: 0.2105\n",
            "Epoch 84/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0862 - mae: 0.2190 - val_loss: 0.0906 - val_mae: 0.2171\n",
            "Epoch 85/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0867 - mae: 0.2159 - val_loss: 0.0776 - val_mae: 0.2085\n",
            "Epoch 86/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0843 - mae: 0.2144 - val_loss: 0.0836 - val_mae: 0.2153\n",
            "Epoch 87/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0852 - mae: 0.2171 - val_loss: 0.0831 - val_mae: 0.2144\n",
            "Epoch 88/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0849 - mae: 0.2133 - val_loss: 0.0817 - val_mae: 0.2120\n",
            "Epoch 89/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0831 - mae: 0.2122 - val_loss: 0.0775 - val_mae: 0.2119\n",
            "Epoch 90/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0834 - mae: 0.2110 - val_loss: 0.0752 - val_mae: 0.2047\n",
            "Epoch 91/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0820 - mae: 0.2106 - val_loss: 0.0746 - val_mae: 0.1997\n",
            "Epoch 92/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0806 - mae: 0.2080 - val_loss: 0.0740 - val_mae: 0.2023\n",
            "Epoch 93/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0788 - mae: 0.2077 - val_loss: 0.0741 - val_mae: 0.2071\n",
            "Epoch 94/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.0794 - mae: 0.2083 - val_loss: 0.0759 - val_mae: 0.2079\n",
            "Epoch 95/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.0774 - mae: 0.2046 - val_loss: 0.0707 - val_mae: 0.1950\n",
            "Epoch 96/600\n",
            "600/600 [==============================] - 0s 118us/sample - loss: 0.0768 - mae: 0.2049 - val_loss: 0.0750 - val_mae: 0.2055\n",
            "Epoch 97/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0766 - mae: 0.2009 - val_loss: 0.0707 - val_mae: 0.1999\n",
            "Epoch 98/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0740 - mae: 0.2009 - val_loss: 0.0719 - val_mae: 0.1939\n",
            "Epoch 99/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0742 - mae: 0.1980 - val_loss: 0.0690 - val_mae: 0.1977\n",
            "Epoch 100/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0714 - mae: 0.1961 - val_loss: 0.0823 - val_mae: 0.2151\n",
            "Epoch 101/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0721 - mae: 0.1999 - val_loss: 0.0784 - val_mae: 0.2057\n",
            "Epoch 102/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0712 - mae: 0.1964 - val_loss: 0.0662 - val_mae: 0.1889\n",
            "Epoch 103/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0706 - mae: 0.1942 - val_loss: 0.0697 - val_mae: 0.1955\n",
            "Epoch 104/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0693 - mae: 0.1945 - val_loss: 0.0660 - val_mae: 0.1951\n",
            "Epoch 105/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0686 - mae: 0.1912 - val_loss: 0.0669 - val_mae: 0.1857\n",
            "Epoch 106/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0668 - mae: 0.1900 - val_loss: 0.0616 - val_mae: 0.1773\n",
            "Epoch 107/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0667 - mae: 0.1896 - val_loss: 0.0611 - val_mae: 0.1789\n",
            "Epoch 108/600\n",
            "600/600 [==============================] - 0s 118us/sample - loss: 0.0655 - mae: 0.1860 - val_loss: 0.0601 - val_mae: 0.1777\n",
            "Epoch 109/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0631 - mae: 0.1842 - val_loss: 0.0583 - val_mae: 0.1742\n",
            "Epoch 110/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0628 - mae: 0.1828 - val_loss: 0.0573 - val_mae: 0.1789\n",
            "Epoch 111/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.0612 - mae: 0.1803 - val_loss: 0.0594 - val_mae: 0.1784\n",
            "Epoch 112/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0612 - mae: 0.1816 - val_loss: 0.0546 - val_mae: 0.1719\n",
            "Epoch 113/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0578 - mae: 0.1781 - val_loss: 0.0530 - val_mae: 0.1648\n",
            "Epoch 114/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0573 - mae: 0.1742 - val_loss: 0.0522 - val_mae: 0.1651\n",
            "Epoch 115/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0566 - mae: 0.1756 - val_loss: 0.0570 - val_mae: 0.1754\n",
            "Epoch 116/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0553 - mae: 0.1726 - val_loss: 0.0514 - val_mae: 0.1681\n",
            "Epoch 117/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0548 - mae: 0.1721 - val_loss: 0.0556 - val_mae: 0.1693\n",
            "Epoch 118/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0541 - mae: 0.1695 - val_loss: 0.0526 - val_mae: 0.1690\n",
            "Epoch 119/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0538 - mae: 0.1712 - val_loss: 0.0472 - val_mae: 0.1579\n",
            "Epoch 120/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.0525 - mae: 0.1667 - val_loss: 0.0472 - val_mae: 0.1609\n",
            "Epoch 121/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0510 - mae: 0.1649 - val_loss: 0.0532 - val_mae: 0.1686\n",
            "Epoch 122/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0500 - mae: 0.1640 - val_loss: 0.0468 - val_mae: 0.1605\n",
            "Epoch 123/600\n",
            "600/600 [==============================] - 0s 84us/sample - loss: 0.0478 - mae: 0.1608 - val_loss: 0.0436 - val_mae: 0.1540\n",
            "Epoch 124/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0466 - mae: 0.1572 - val_loss: 0.0485 - val_mae: 0.1580\n",
            "Epoch 125/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0458 - mae: 0.1555 - val_loss: 0.0450 - val_mae: 0.1559\n",
            "Epoch 126/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.0456 - mae: 0.1591 - val_loss: 0.0470 - val_mae: 0.1594\n",
            "Epoch 127/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0451 - mae: 0.1536 - val_loss: 0.0466 - val_mae: 0.1619\n",
            "Epoch 128/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0436 - mae: 0.1555 - val_loss: 0.0411 - val_mae: 0.1491\n",
            "Epoch 129/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0415 - mae: 0.1500 - val_loss: 0.0429 - val_mae: 0.1600\n",
            "Epoch 130/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0416 - mae: 0.1512 - val_loss: 0.0373 - val_mae: 0.1399\n",
            "Epoch 131/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0412 - mae: 0.1508 - val_loss: 0.0375 - val_mae: 0.1427\n",
            "Epoch 132/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0389 - mae: 0.1467 - val_loss: 0.0381 - val_mae: 0.1439\n",
            "Epoch 133/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0384 - mae: 0.1440 - val_loss: 0.0402 - val_mae: 0.1521\n",
            "Epoch 134/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0375 - mae: 0.1437 - val_loss: 0.0338 - val_mae: 0.1357\n",
            "Epoch 135/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0370 - mae: 0.1430 - val_loss: 0.0426 - val_mae: 0.1588\n",
            "Epoch 136/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0356 - mae: 0.1405 - val_loss: 0.0349 - val_mae: 0.1349\n",
            "Epoch 137/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0343 - mae: 0.1370 - val_loss: 0.0417 - val_mae: 0.1498\n",
            "Epoch 138/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0328 - mae: 0.1340 - val_loss: 0.0370 - val_mae: 0.1424\n",
            "Epoch 139/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0347 - mae: 0.1382 - val_loss: 0.0316 - val_mae: 0.1256\n",
            "Epoch 140/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0318 - mae: 0.1324 - val_loss: 0.0329 - val_mae: 0.1351\n",
            "Epoch 141/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0300 - mae: 0.1305 - val_loss: 0.0335 - val_mae: 0.1330\n",
            "Epoch 142/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0315 - mae: 0.1316 - val_loss: 0.0279 - val_mae: 0.1225\n",
            "Epoch 143/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0313 - mae: 0.1308 - val_loss: 0.0293 - val_mae: 0.1273\n",
            "Epoch 144/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0285 - mae: 0.1257 - val_loss: 0.0286 - val_mae: 0.1264\n",
            "Epoch 145/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0283 - mae: 0.1258 - val_loss: 0.0298 - val_mae: 0.1274\n",
            "Epoch 146/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0287 - mae: 0.1279 - val_loss: 0.0306 - val_mae: 0.1295\n",
            "Epoch 147/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0275 - mae: 0.1246 - val_loss: 0.0286 - val_mae: 0.1284\n",
            "Epoch 148/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0273 - mae: 0.1249 - val_loss: 0.0256 - val_mae: 0.1195\n",
            "Epoch 149/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0253 - mae: 0.1211 - val_loss: 0.0285 - val_mae: 0.1284\n",
            "Epoch 150/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0254 - mae: 0.1208 - val_loss: 0.0246 - val_mae: 0.1185\n",
            "Epoch 151/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0247 - mae: 0.1186 - val_loss: 0.0263 - val_mae: 0.1244\n",
            "Epoch 152/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0234 - mae: 0.1181 - val_loss: 0.0263 - val_mae: 0.1204\n",
            "Epoch 153/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0243 - mae: 0.1180 - val_loss: 0.0236 - val_mae: 0.1147\n",
            "Epoch 154/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0228 - mae: 0.1124 - val_loss: 0.0226 - val_mae: 0.1116\n",
            "Epoch 155/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0233 - mae: 0.1166 - val_loss: 0.0218 - val_mae: 0.1100\n",
            "Epoch 156/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0227 - mae: 0.1170 - val_loss: 0.0234 - val_mae: 0.1104\n",
            "Epoch 157/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0215 - mae: 0.1115 - val_loss: 0.0215 - val_mae: 0.1082\n",
            "Epoch 158/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0219 - mae: 0.1142 - val_loss: 0.0212 - val_mae: 0.1093\n",
            "Epoch 159/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0220 - mae: 0.1136 - val_loss: 0.0284 - val_mae: 0.1226\n",
            "Epoch 160/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0196 - mae: 0.1068 - val_loss: 0.0193 - val_mae: 0.1032\n",
            "Epoch 161/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0201 - mae: 0.1080 - val_loss: 0.0227 - val_mae: 0.1115\n",
            "Epoch 162/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0200 - mae: 0.1078 - val_loss: 0.0216 - val_mae: 0.1098\n",
            "Epoch 163/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.0190 - mae: 0.1066 - val_loss: 0.0308 - val_mae: 0.1371\n",
            "Epoch 164/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0193 - mae: 0.1061 - val_loss: 0.0202 - val_mae: 0.1042\n",
            "Epoch 165/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0188 - mae: 0.1043 - val_loss: 0.0175 - val_mae: 0.0988\n",
            "Epoch 166/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.0185 - mae: 0.1053 - val_loss: 0.0186 - val_mae: 0.1047\n",
            "Epoch 167/600\n",
            "600/600 [==============================] - 0s 82us/sample - loss: 0.0188 - mae: 0.1051 - val_loss: 0.0177 - val_mae: 0.1006\n",
            "Epoch 168/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0181 - mae: 0.1047 - val_loss: 0.0199 - val_mae: 0.1103\n",
            "Epoch 169/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0173 - mae: 0.1012 - val_loss: 0.0166 - val_mae: 0.0984\n",
            "Epoch 170/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0169 - mae: 0.1004 - val_loss: 0.0169 - val_mae: 0.1007\n",
            "Epoch 171/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0165 - mae: 0.1005 - val_loss: 0.0227 - val_mae: 0.1171\n",
            "Epoch 172/600\n",
            "600/600 [==============================] - 0s 125us/sample - loss: 0.0176 - mae: 0.1008 - val_loss: 0.0168 - val_mae: 0.0991\n",
            "Epoch 173/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0162 - mae: 0.0993 - val_loss: 0.0160 - val_mae: 0.0979\n",
            "Epoch 174/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.0165 - mae: 0.0986 - val_loss: 0.0184 - val_mae: 0.1023\n",
            "Epoch 175/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0161 - mae: 0.0989 - val_loss: 0.0210 - val_mae: 0.1054\n",
            "Epoch 176/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0165 - mae: 0.0999 - val_loss: 0.0250 - val_mae: 0.1168\n",
            "Epoch 177/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0150 - mae: 0.0943 - val_loss: 0.0176 - val_mae: 0.1017\n",
            "Epoch 178/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0157 - mae: 0.0980 - val_loss: 0.0170 - val_mae: 0.1023\n",
            "Epoch 179/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0157 - mae: 0.0969 - val_loss: 0.0147 - val_mae: 0.0933\n",
            "Epoch 180/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0150 - mae: 0.0951 - val_loss: 0.0318 - val_mae: 0.1441\n",
            "Epoch 181/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.0162 - mae: 0.0991 - val_loss: 0.0201 - val_mae: 0.1113\n",
            "Epoch 182/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.0142 - mae: 0.0945 - val_loss: 0.0146 - val_mae: 0.0933\n",
            "Epoch 183/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0146 - mae: 0.0946 - val_loss: 0.0203 - val_mae: 0.1113\n",
            "Epoch 184/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0150 - mae: 0.0954 - val_loss: 0.0175 - val_mae: 0.1029\n",
            "Epoch 185/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0157 - mae: 0.0965 - val_loss: 0.0180 - val_mae: 0.1018\n",
            "Epoch 186/600\n",
            "600/600 [==============================] - 0s 87us/sample - loss: 0.0138 - mae: 0.0930 - val_loss: 0.0253 - val_mae: 0.1262\n",
            "Epoch 187/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0143 - mae: 0.0954 - val_loss: 0.0179 - val_mae: 0.1059\n",
            "Epoch 188/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0143 - mae: 0.0951 - val_loss: 0.0165 - val_mae: 0.0995\n",
            "Epoch 189/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0145 - mae: 0.0935 - val_loss: 0.0276 - val_mae: 0.1278\n",
            "Epoch 190/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0141 - mae: 0.0933 - val_loss: 0.0156 - val_mae: 0.0964\n",
            "Epoch 191/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0150 - mae: 0.0968 - val_loss: 0.0212 - val_mae: 0.1100\n",
            "Epoch 192/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0129 - mae: 0.0906 - val_loss: 0.0286 - val_mae: 0.1295\n",
            "Epoch 193/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0146 - mae: 0.0950 - val_loss: 0.0264 - val_mae: 0.1282\n",
            "Epoch 194/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0152 - mae: 0.0962 - val_loss: 0.0186 - val_mae: 0.1052\n",
            "Epoch 195/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0144 - mae: 0.0941 - val_loss: 0.0169 - val_mae: 0.1034\n",
            "Epoch 196/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0142 - mae: 0.0943 - val_loss: 0.0143 - val_mae: 0.0953\n",
            "Epoch 197/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.0126 - mae: 0.0907 - val_loss: 0.0178 - val_mae: 0.1025\n",
            "Epoch 198/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0139 - mae: 0.0934 - val_loss: 0.0218 - val_mae: 0.1093\n",
            "Epoch 199/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0136 - mae: 0.0936 - val_loss: 0.0202 - val_mae: 0.1049\n",
            "Epoch 200/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0139 - mae: 0.0937 - val_loss: 0.0212 - val_mae: 0.1141\n",
            "Epoch 201/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.0138 - mae: 0.0915 - val_loss: 0.0208 - val_mae: 0.1156\n",
            "Epoch 202/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0145 - mae: 0.0941 - val_loss: 0.0165 - val_mae: 0.0995\n",
            "Epoch 203/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0132 - mae: 0.0925 - val_loss: 0.0259 - val_mae: 0.1180\n",
            "Epoch 204/600\n",
            "600/600 [==============================] - 0s 117us/sample - loss: 0.0131 - mae: 0.0915 - val_loss: 0.0160 - val_mae: 0.0975\n",
            "Epoch 205/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0131 - mae: 0.0931 - val_loss: 0.0161 - val_mae: 0.0970\n",
            "Epoch 206/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0136 - mae: 0.0940 - val_loss: 0.0173 - val_mae: 0.0997\n",
            "Epoch 207/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0138 - mae: 0.0908 - val_loss: 0.0163 - val_mae: 0.0976\n",
            "Epoch 208/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0137 - mae: 0.0935 - val_loss: 0.0145 - val_mae: 0.0941\n",
            "Epoch 209/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0138 - mae: 0.0925 - val_loss: 0.0204 - val_mae: 0.1151\n",
            "Epoch 210/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0144 - mae: 0.0947 - val_loss: 0.0139 - val_mae: 0.0929\n",
            "Epoch 211/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0132 - mae: 0.0909 - val_loss: 0.0162 - val_mae: 0.1007\n",
            "Epoch 212/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0132 - mae: 0.0907 - val_loss: 0.0165 - val_mae: 0.0981\n",
            "Epoch 213/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0127 - mae: 0.0887 - val_loss: 0.0272 - val_mae: 0.1320\n",
            "Epoch 214/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0131 - mae: 0.0914 - val_loss: 0.0139 - val_mae: 0.0933\n",
            "Epoch 215/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0133 - mae: 0.0911 - val_loss: 0.0164 - val_mae: 0.1007\n",
            "Epoch 216/600\n",
            "600/600 [==============================] - 0s 128us/sample - loss: 0.0131 - mae: 0.0909 - val_loss: 0.0226 - val_mae: 0.1090\n",
            "Epoch 217/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0132 - mae: 0.0915 - val_loss: 0.0131 - val_mae: 0.0897\n",
            "Epoch 218/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0131 - mae: 0.0916 - val_loss: 0.0146 - val_mae: 0.0947\n",
            "Epoch 219/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0130 - mae: 0.0907 - val_loss: 0.0158 - val_mae: 0.0960\n",
            "Epoch 220/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0130 - mae: 0.0902 - val_loss: 0.0165 - val_mae: 0.0972\n",
            "Epoch 221/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0135 - mae: 0.0907 - val_loss: 0.0256 - val_mae: 0.1179\n",
            "Epoch 222/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0135 - mae: 0.0918 - val_loss: 0.0133 - val_mae: 0.0896\n",
            "Epoch 223/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0123 - mae: 0.0882 - val_loss: 0.0126 - val_mae: 0.0868\n",
            "Epoch 224/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0128 - mae: 0.0903 - val_loss: 0.0124 - val_mae: 0.0871\n",
            "Epoch 225/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0133 - mae: 0.0921 - val_loss: 0.0143 - val_mae: 0.0946\n",
            "Epoch 226/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0131 - mae: 0.0904 - val_loss: 0.0128 - val_mae: 0.0892\n",
            "Epoch 227/600\n",
            "600/600 [==============================] - 0s 88us/sample - loss: 0.0125 - mae: 0.0898 - val_loss: 0.0158 - val_mae: 0.0964\n",
            "Epoch 228/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0119 - mae: 0.0880 - val_loss: 0.0128 - val_mae: 0.0887\n",
            "Epoch 229/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0129 - mae: 0.0909 - val_loss: 0.0138 - val_mae: 0.0925\n",
            "Epoch 230/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0128 - mae: 0.0906 - val_loss: 0.0272 - val_mae: 0.1265\n",
            "Epoch 231/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0135 - mae: 0.0919 - val_loss: 0.0221 - val_mae: 0.1195\n",
            "Epoch 232/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0137 - mae: 0.0922 - val_loss: 0.0135 - val_mae: 0.0914\n",
            "Epoch 233/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0131 - mae: 0.0916 - val_loss: 0.0136 - val_mae: 0.0908\n",
            "Epoch 234/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0124 - mae: 0.0892 - val_loss: 0.0208 - val_mae: 0.1089\n",
            "Epoch 235/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0129 - mae: 0.0919 - val_loss: 0.0173 - val_mae: 0.0997\n",
            "Epoch 236/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0124 - mae: 0.0881 - val_loss: 0.0124 - val_mae: 0.0865\n",
            "Epoch 237/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - mae: 0.0882 - val_loss: 0.0147 - val_mae: 0.0938\n",
            "Epoch 238/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0131 - mae: 0.0917 - val_loss: 0.0130 - val_mae: 0.0893\n",
            "Epoch 239/600\n",
            "600/600 [==============================] - 0s 116us/sample - loss: 0.0121 - mae: 0.0876 - val_loss: 0.0124 - val_mae: 0.0864\n",
            "Epoch 240/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0121 - mae: 0.0882 - val_loss: 0.0154 - val_mae: 0.0969\n",
            "Epoch 241/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0124 - mae: 0.0885 - val_loss: 0.0119 - val_mae: 0.0843\n",
            "Epoch 242/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0130 - mae: 0.0908 - val_loss: 0.0143 - val_mae: 0.0930\n",
            "Epoch 243/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0127 - mae: 0.0899 - val_loss: 0.0203 - val_mae: 0.1129\n",
            "Epoch 244/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0129 - mae: 0.0912 - val_loss: 0.0132 - val_mae: 0.0895\n",
            "Epoch 245/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0128 - mae: 0.0901 - val_loss: 0.0121 - val_mae: 0.0865\n",
            "Epoch 246/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0125 - mae: 0.0881 - val_loss: 0.0224 - val_mae: 0.1167\n",
            "Epoch 247/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0123 - mae: 0.0873 - val_loss: 0.0149 - val_mae: 0.0944\n",
            "Epoch 248/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0127 - mae: 0.0890 - val_loss: 0.0127 - val_mae: 0.0876\n",
            "Epoch 249/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0113 - mae: 0.0852 - val_loss: 0.0257 - val_mae: 0.1263\n",
            "Epoch 250/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0123 - mae: 0.0885 - val_loss: 0.0181 - val_mae: 0.1005\n",
            "Epoch 251/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0126 - mae: 0.0898 - val_loss: 0.0138 - val_mae: 0.0903\n",
            "Epoch 252/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0128 - mae: 0.0896 - val_loss: 0.0147 - val_mae: 0.0943\n",
            "Epoch 253/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - mae: 0.0872 - val_loss: 0.0151 - val_mae: 0.0949\n",
            "Epoch 254/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0131 - mae: 0.0910 - val_loss: 0.0224 - val_mae: 0.1152\n",
            "Epoch 255/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0124 - mae: 0.0904 - val_loss: 0.0148 - val_mae: 0.0939\n",
            "Epoch 256/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0124 - mae: 0.0888 - val_loss: 0.0261 - val_mae: 0.1250\n",
            "Epoch 257/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0137 - mae: 0.0914 - val_loss: 0.0168 - val_mae: 0.0983\n",
            "Epoch 258/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0124 - mae: 0.0889 - val_loss: 0.0113 - val_mae: 0.0831\n",
            "Epoch 259/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0117 - mae: 0.0881 - val_loss: 0.0343 - val_mae: 0.1369\n",
            "Epoch 260/600\n",
            "600/600 [==============================] - 0s 125us/sample - loss: 0.0119 - mae: 0.0874 - val_loss: 0.0126 - val_mae: 0.0880\n",
            "Epoch 261/600\n",
            "600/600 [==============================] - 0s 132us/sample - loss: 0.0120 - mae: 0.0884 - val_loss: 0.0166 - val_mae: 0.1009\n",
            "Epoch 262/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0130 - mae: 0.0911 - val_loss: 0.0135 - val_mae: 0.0907\n",
            "Epoch 263/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - mae: 0.0876 - val_loss: 0.0138 - val_mae: 0.0913\n",
            "Epoch 264/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0118 - mae: 0.0874 - val_loss: 0.0128 - val_mae: 0.0888\n",
            "Epoch 265/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0125 - mae: 0.0881 - val_loss: 0.0126 - val_mae: 0.0871\n",
            "Epoch 266/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0119 - mae: 0.0869 - val_loss: 0.0121 - val_mae: 0.0871\n",
            "Epoch 267/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0122 - mae: 0.0879 - val_loss: 0.0186 - val_mae: 0.1076\n",
            "Epoch 268/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0126 - mae: 0.0902 - val_loss: 0.0142 - val_mae: 0.0915\n",
            "Epoch 269/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0114 - mae: 0.0854 - val_loss: 0.0221 - val_mae: 0.1146\n",
            "Epoch 270/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0128 - mae: 0.0916 - val_loss: 0.0130 - val_mae: 0.0892\n",
            "Epoch 271/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0120 - mae: 0.0878 - val_loss: 0.0136 - val_mae: 0.0912\n",
            "Epoch 272/600\n",
            "600/600 [==============================] - 0s 114us/sample - loss: 0.0125 - mae: 0.0888 - val_loss: 0.0263 - val_mae: 0.1130\n",
            "Epoch 273/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0127 - mae: 0.0893 - val_loss: 0.0133 - val_mae: 0.0899\n",
            "Epoch 274/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0126 - mae: 0.0890 - val_loss: 0.0135 - val_mae: 0.0914\n",
            "Epoch 275/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0124 - mae: 0.0877 - val_loss: 0.0160 - val_mae: 0.0950\n",
            "Epoch 276/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0120 - mae: 0.0876 - val_loss: 0.0163 - val_mae: 0.0991\n",
            "Epoch 277/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0128 - mae: 0.0897 - val_loss: 0.0202 - val_mae: 0.1043\n",
            "Epoch 278/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0115 - mae: 0.0858 - val_loss: 0.0211 - val_mae: 0.1083\n",
            "Epoch 279/600\n",
            "600/600 [==============================] - 0s 126us/sample - loss: 0.0120 - mae: 0.0868 - val_loss: 0.0127 - val_mae: 0.0893\n",
            "Epoch 280/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0269 - val_mae: 0.1227\n",
            "Epoch 281/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0180 - val_mae: 0.1069\n",
            "Epoch 282/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0119 - mae: 0.0872 - val_loss: 0.0181 - val_mae: 0.1080\n",
            "Epoch 283/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0125 - mae: 0.0876 - val_loss: 0.0133 - val_mae: 0.0907\n",
            "Epoch 284/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0123 - mae: 0.0885 - val_loss: 0.0136 - val_mae: 0.0915\n",
            "Epoch 285/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0119 - mae: 0.0876 - val_loss: 0.0122 - val_mae: 0.0862\n",
            "Epoch 286/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0119 - mae: 0.0875 - val_loss: 0.0144 - val_mae: 0.0931\n",
            "Epoch 287/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0126 - mae: 0.0904 - val_loss: 0.0323 - val_mae: 0.1394\n",
            "Epoch 288/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0123 - mae: 0.0894 - val_loss: 0.0171 - val_mae: 0.1008\n",
            "Epoch 289/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0127 - mae: 0.0907 - val_loss: 0.0129 - val_mae: 0.0895\n",
            "Epoch 290/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0114 - mae: 0.0837 - val_loss: 0.0197 - val_mae: 0.1043\n",
            "Epoch 291/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0122 - mae: 0.0877 - val_loss: 0.0175 - val_mae: 0.1032\n",
            "Epoch 292/600\n",
            "600/600 [==============================] - 0s 138us/sample - loss: 0.0120 - mae: 0.0870 - val_loss: 0.0127 - val_mae: 0.0893\n",
            "Epoch 293/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0126 - mae: 0.0891 - val_loss: 0.0163 - val_mae: 0.1003\n",
            "Epoch 294/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0123 - mae: 0.0875 - val_loss: 0.0149 - val_mae: 0.0966\n",
            "Epoch 295/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0126 - mae: 0.0890 - val_loss: 0.0150 - val_mae: 0.0953\n",
            "Epoch 296/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0118 - mae: 0.0865 - val_loss: 0.0137 - val_mae: 0.0906\n",
            "Epoch 297/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0113 - mae: 0.0848 - val_loss: 0.0141 - val_mae: 0.0913\n",
            "Epoch 298/600\n",
            "600/600 [==============================] - 0s 89us/sample - loss: 0.0122 - mae: 0.0877 - val_loss: 0.0134 - val_mae: 0.0889\n",
            "Epoch 299/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0126 - mae: 0.0899 - val_loss: 0.0141 - val_mae: 0.0928\n",
            "Epoch 300/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0124 - mae: 0.0883 - val_loss: 0.0137 - val_mae: 0.0917\n",
            "Epoch 301/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0111 - mae: 0.0847 - val_loss: 0.0131 - val_mae: 0.0903\n",
            "Epoch 302/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0122 - mae: 0.0869 - val_loss: 0.0125 - val_mae: 0.0878\n",
            "Epoch 303/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0122 - mae: 0.0879 - val_loss: 0.0160 - val_mae: 0.0987\n",
            "Epoch 304/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0124 - mae: 0.0875 - val_loss: 0.0192 - val_mae: 0.1095\n",
            "Epoch 305/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0127 - mae: 0.0891 - val_loss: 0.0231 - val_mae: 0.1176\n",
            "Epoch 306/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0117 - mae: 0.0865 - val_loss: 0.0203 - val_mae: 0.1119\n",
            "Epoch 307/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0119 - mae: 0.0868 - val_loss: 0.0123 - val_mae: 0.0881\n",
            "Epoch 308/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0118 - val_mae: 0.0857\n",
            "Epoch 309/600\n",
            "600/600 [==============================] - 0s 147us/sample - loss: 0.0120 - mae: 0.0871 - val_loss: 0.0121 - val_mae: 0.0864\n",
            "Epoch 310/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0118 - mae: 0.0881 - val_loss: 0.0133 - val_mae: 0.0906\n",
            "Epoch 311/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0110 - mae: 0.0839 - val_loss: 0.0120 - val_mae: 0.0851\n",
            "Epoch 312/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0123 - mae: 0.0877 - val_loss: 0.0137 - val_mae: 0.0911\n",
            "Epoch 313/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0115 - mae: 0.0843 - val_loss: 0.0137 - val_mae: 0.0912\n",
            "Epoch 314/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0132 - mae: 0.0907 - val_loss: 0.0154 - val_mae: 0.0970\n",
            "Epoch 315/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0115 - mae: 0.0854 - val_loss: 0.0180 - val_mae: 0.1026\n",
            "Epoch 316/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0118 - mae: 0.0869 - val_loss: 0.0150 - val_mae: 0.0970\n",
            "Epoch 317/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0121 - mae: 0.0871 - val_loss: 0.0117 - val_mae: 0.0848\n",
            "Epoch 318/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0156 - val_mae: 0.0974\n",
            "Epoch 319/600\n",
            "600/600 [==============================] - 0s 116us/sample - loss: 0.0124 - mae: 0.0879 - val_loss: 0.0179 - val_mae: 0.1046\n",
            "Epoch 320/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0119 - mae: 0.0869 - val_loss: 0.0169 - val_mae: 0.1011\n",
            "Epoch 321/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0117 - mae: 0.0862 - val_loss: 0.0193 - val_mae: 0.1083\n",
            "Epoch 322/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0120 - mae: 0.0860 - val_loss: 0.0120 - val_mae: 0.0865\n",
            "Epoch 323/600\n",
            "600/600 [==============================] - 0s 85us/sample - loss: 0.0121 - mae: 0.0875 - val_loss: 0.0143 - val_mae: 0.0956\n",
            "Epoch 324/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0121 - mae: 0.0871 - val_loss: 0.0144 - val_mae: 0.0925\n",
            "Epoch 325/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0124 - mae: 0.0885 - val_loss: 0.0128 - val_mae: 0.0885\n",
            "Epoch 326/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0118 - mae: 0.0858 - val_loss: 0.0186 - val_mae: 0.1066\n",
            "Epoch 327/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0124 - mae: 0.0878 - val_loss: 0.0135 - val_mae: 0.0908\n",
            "Epoch 328/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0114 - mae: 0.0867 - val_loss: 0.0121 - val_mae: 0.0853\n",
            "Epoch 329/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0110 - mae: 0.0841 - val_loss: 0.0159 - val_mae: 0.0966\n",
            "Epoch 330/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0125 - mae: 0.0871 - val_loss: 0.0126 - val_mae: 0.0890\n",
            "Epoch 331/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0116 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0880\n",
            "Epoch 332/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0117 - mae: 0.0872 - val_loss: 0.0151 - val_mae: 0.0972\n",
            "Epoch 333/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0118 - mae: 0.0874 - val_loss: 0.0178 - val_mae: 0.0989\n",
            "Epoch 334/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0120 - mae: 0.0895 - val_loss: 0.0126 - val_mae: 0.0884\n",
            "Epoch 335/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0116 - mae: 0.0861 - val_loss: 0.0148 - val_mae: 0.0962\n",
            "Epoch 336/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0118 - mae: 0.0848 - val_loss: 0.0128 - val_mae: 0.0877\n",
            "Epoch 337/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0117 - mae: 0.0870 - val_loss: 0.0177 - val_mae: 0.0977\n",
            "Epoch 338/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0119 - mae: 0.0873 - val_loss: 0.0119 - val_mae: 0.0861\n",
            "Epoch 339/600\n",
            "600/600 [==============================] - 0s 124us/sample - loss: 0.0116 - mae: 0.0864 - val_loss: 0.0187 - val_mae: 0.1064\n",
            "Epoch 340/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0117 - mae: 0.0866 - val_loss: 0.0221 - val_mae: 0.1171\n",
            "Epoch 341/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0123 - mae: 0.0894 - val_loss: 0.0145 - val_mae: 0.0953\n",
            "Epoch 342/600\n",
            "600/600 [==============================] - 0s 129us/sample - loss: 0.0112 - mae: 0.0845 - val_loss: 0.0276 - val_mae: 0.1226\n",
            "Epoch 343/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0120 - mae: 0.0887 - val_loss: 0.0273 - val_mae: 0.1199\n",
            "Epoch 344/600\n",
            "600/600 [==============================] - 0s 135us/sample - loss: 0.0120 - mae: 0.0872 - val_loss: 0.0174 - val_mae: 0.1021\n",
            "Epoch 345/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0117 - mae: 0.0854 - val_loss: 0.0130 - val_mae: 0.0894\n",
            "Epoch 346/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0126 - mae: 0.0889 - val_loss: 0.0193 - val_mae: 0.1074\n",
            "Epoch 347/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0167 - val_mae: 0.1007\n",
            "Epoch 348/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0115 - mae: 0.0854 - val_loss: 0.0121 - val_mae: 0.0861\n",
            "Epoch 349/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0120 - mae: 0.0876 - val_loss: 0.0247 - val_mae: 0.1188\n",
            "Epoch 350/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0120 - mae: 0.0864 - val_loss: 0.0195 - val_mae: 0.1041\n",
            "Epoch 351/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0115 - mae: 0.0863 - val_loss: 0.0166 - val_mae: 0.1024\n",
            "Epoch 352/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0119 - mae: 0.0857 - val_loss: 0.0127 - val_mae: 0.0873\n",
            "Epoch 353/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0119 - mae: 0.0874 - val_loss: 0.0162 - val_mae: 0.1012\n",
            "Epoch 354/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0120 - mae: 0.0872 - val_loss: 0.0194 - val_mae: 0.1098\n",
            "Epoch 355/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0123 - mae: 0.0884 - val_loss: 0.0150 - val_mae: 0.0981\n",
            "Epoch 356/600\n",
            "600/600 [==============================] - 0s 114us/sample - loss: 0.0113 - mae: 0.0862 - val_loss: 0.0128 - val_mae: 0.0890\n",
            "Epoch 357/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0122 - mae: 0.0894 - val_loss: 0.0122 - val_mae: 0.0861\n",
            "Epoch 358/600\n",
            "600/600 [==============================] - 0s 124us/sample - loss: 0.0114 - mae: 0.0855 - val_loss: 0.0286 - val_mae: 0.1222\n",
            "Epoch 359/600\n",
            "600/600 [==============================] - 0s 126us/sample - loss: 0.0127 - mae: 0.0889 - val_loss: 0.0130 - val_mae: 0.0889\n",
            "Epoch 360/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0113 - mae: 0.0851 - val_loss: 0.0162 - val_mae: 0.0976\n",
            "Epoch 361/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0113 - mae: 0.0843 - val_loss: 0.0124 - val_mae: 0.0885\n",
            "Epoch 362/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0122 - mae: 0.0885 - val_loss: 0.0132 - val_mae: 0.0904\n",
            "Epoch 363/600\n",
            "600/600 [==============================] - 0s 148us/sample - loss: 0.0115 - mae: 0.0874 - val_loss: 0.0154 - val_mae: 0.0979\n",
            "Epoch 364/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0125 - val_mae: 0.0883\n",
            "Epoch 365/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0114 - mae: 0.0847 - val_loss: 0.0148 - val_mae: 0.0949\n",
            "Epoch 366/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0122 - mae: 0.0874 - val_loss: 0.0129 - val_mae: 0.0898\n",
            "Epoch 367/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0116 - mae: 0.0859 - val_loss: 0.0131 - val_mae: 0.0892\n",
            "Epoch 368/600\n",
            "600/600 [==============================] - 0s 149us/sample - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0134 - val_mae: 0.0897\n",
            "Epoch 369/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0121 - mae: 0.0864 - val_loss: 0.0228 - val_mae: 0.1114\n",
            "Epoch 370/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0123 - mae: 0.0875 - val_loss: 0.0116 - val_mae: 0.0854\n",
            "Epoch 371/600\n",
            "600/600 [==============================] - 0s 124us/sample - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0134 - val_mae: 0.0903\n",
            "Epoch 372/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0116 - mae: 0.0865 - val_loss: 0.0140 - val_mae: 0.0925\n",
            "Epoch 373/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0161 - val_mae: 0.1012\n",
            "Epoch 374/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0115 - mae: 0.0855 - val_loss: 0.0155 - val_mae: 0.0963\n",
            "Epoch 375/600\n",
            "600/600 [==============================] - 0s 114us/sample - loss: 0.0113 - mae: 0.0850 - val_loss: 0.0136 - val_mae: 0.0919\n",
            "Epoch 376/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0116 - mae: 0.0860 - val_loss: 0.0176 - val_mae: 0.1043\n",
            "Epoch 377/600\n",
            "600/600 [==============================] - 0s 86us/sample - loss: 0.0124 - mae: 0.0878 - val_loss: 0.0128 - val_mae: 0.0889\n",
            "Epoch 378/600\n",
            "600/600 [==============================] - 0s 120us/sample - loss: 0.0109 - mae: 0.0835 - val_loss: 0.0145 - val_mae: 0.0949\n",
            "Epoch 379/600\n",
            "600/600 [==============================] - 0s 139us/sample - loss: 0.0122 - mae: 0.0886 - val_loss: 0.0123 - val_mae: 0.0883\n",
            "Epoch 380/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0120 - mae: 0.0878 - val_loss: 0.0150 - val_mae: 0.0961\n",
            "Epoch 381/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0127 - val_mae: 0.0888\n",
            "Epoch 382/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0117 - mae: 0.0863 - val_loss: 0.0118 - val_mae: 0.0851\n",
            "Epoch 383/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0126 - mae: 0.0893 - val_loss: 0.0122 - val_mae: 0.0866\n",
            "Epoch 384/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0118 - mae: 0.0863 - val_loss: 0.0146 - val_mae: 0.0937\n",
            "Epoch 385/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0109 - mae: 0.0839 - val_loss: 0.0129 - val_mae: 0.0895\n",
            "Epoch 386/600\n",
            "600/600 [==============================] - 0s 119us/sample - loss: 0.0114 - mae: 0.0856 - val_loss: 0.0127 - val_mae: 0.0880\n",
            "Epoch 387/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0119 - mae: 0.0872 - val_loss: 0.0141 - val_mae: 0.0924\n",
            "Epoch 388/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0113 - mae: 0.0851 - val_loss: 0.0137 - val_mae: 0.0919\n",
            "Epoch 389/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0118 - mae: 0.0864 - val_loss: 0.0160 - val_mae: 0.0954\n",
            "Epoch 390/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0120 - mae: 0.0869 - val_loss: 0.0117 - val_mae: 0.0841\n",
            "Epoch 391/600\n",
            "600/600 [==============================] - 0s 119us/sample - loss: 0.0112 - mae: 0.0844 - val_loss: 0.0137 - val_mae: 0.0928\n",
            "Epoch 392/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0123 - mae: 0.0876 - val_loss: 0.0212 - val_mae: 0.1111\n",
            "Epoch 393/600\n",
            "600/600 [==============================] - 0s 117us/sample - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0128 - val_mae: 0.0891\n",
            "Epoch 394/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0111 - mae: 0.0847 - val_loss: 0.0117 - val_mae: 0.0852\n",
            "Epoch 395/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0113 - mae: 0.0844 - val_loss: 0.0185 - val_mae: 0.1081\n",
            "Epoch 396/600\n",
            "600/600 [==============================] - 0s 117us/sample - loss: 0.0114 - mae: 0.0863 - val_loss: 0.0225 - val_mae: 0.1168\n",
            "Epoch 397/600\n",
            "600/600 [==============================] - 0s 143us/sample - loss: 0.0114 - mae: 0.0861 - val_loss: 0.0132 - val_mae: 0.0913\n",
            "Epoch 398/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0122 - mae: 0.0879 - val_loss: 0.0194 - val_mae: 0.1067\n",
            "Epoch 399/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0121 - mae: 0.0872 - val_loss: 0.0228 - val_mae: 0.1152\n",
            "Epoch 400/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0124 - val_mae: 0.0870\n",
            "Epoch 401/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0114 - mae: 0.0872 - val_loss: 0.0129 - val_mae: 0.0889\n",
            "Epoch 402/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0119 - mae: 0.0869 - val_loss: 0.0151 - val_mae: 0.0945\n",
            "Epoch 403/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0117 - mae: 0.0845 - val_loss: 0.0125 - val_mae: 0.0885\n",
            "Epoch 404/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0122 - mae: 0.0875 - val_loss: 0.0126 - val_mae: 0.0875\n",
            "Epoch 405/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0121 - mae: 0.0876 - val_loss: 0.0169 - val_mae: 0.1018\n",
            "Epoch 406/600\n",
            "600/600 [==============================] - 0s 128us/sample - loss: 0.0114 - mae: 0.0858 - val_loss: 0.0126 - val_mae: 0.0884\n",
            "Epoch 407/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0111 - mae: 0.0833 - val_loss: 0.0159 - val_mae: 0.0973\n",
            "Epoch 408/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0115 - mae: 0.0846 - val_loss: 0.0125 - val_mae: 0.0881\n",
            "Epoch 409/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0120 - mae: 0.0860 - val_loss: 0.0129 - val_mae: 0.0895\n",
            "Epoch 410/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0114 - mae: 0.0857 - val_loss: 0.0195 - val_mae: 0.1025\n",
            "Epoch 411/600\n",
            "600/600 [==============================] - 0s 121us/sample - loss: 0.0124 - mae: 0.0876 - val_loss: 0.0148 - val_mae: 0.0962\n",
            "Epoch 412/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0126 - mae: 0.0880 - val_loss: 0.0159 - val_mae: 0.0959\n",
            "Epoch 413/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0117 - mae: 0.0870 - val_loss: 0.0186 - val_mae: 0.1052\n",
            "Epoch 414/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0123 - mae: 0.0893 - val_loss: 0.0115 - val_mae: 0.0849\n",
            "Epoch 415/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0111 - mae: 0.0846 - val_loss: 0.0182 - val_mae: 0.1012\n",
            "Epoch 416/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0116 - mae: 0.0849 - val_loss: 0.0124 - val_mae: 0.0874\n",
            "Epoch 417/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0114 - mae: 0.0854 - val_loss: 0.0143 - val_mae: 0.0950\n",
            "Epoch 418/600\n",
            "600/600 [==============================] - 0s 134us/sample - loss: 0.0108 - mae: 0.0838 - val_loss: 0.0184 - val_mae: 0.1037\n",
            "Epoch 419/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0120 - mae: 0.0860 - val_loss: 0.0123 - val_mae: 0.0859\n",
            "Epoch 420/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0118 - mae: 0.0863 - val_loss: 0.0119 - val_mae: 0.0857\n",
            "Epoch 421/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0115 - mae: 0.0863 - val_loss: 0.0212 - val_mae: 0.1144\n",
            "Epoch 422/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0110 - mae: 0.0839 - val_loss: 0.0114 - val_mae: 0.0832\n",
            "Epoch 423/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0115 - mae: 0.0857 - val_loss: 0.0114 - val_mae: 0.0833\n",
            "Epoch 424/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0116 - mae: 0.0868 - val_loss: 0.0133 - val_mae: 0.0900\n",
            "Epoch 425/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0112 - mae: 0.0855 - val_loss: 0.0297 - val_mae: 0.1320\n",
            "Epoch 426/600\n",
            "600/600 [==============================] - 0s 116us/sample - loss: 0.0115 - mae: 0.0852 - val_loss: 0.0196 - val_mae: 0.1086\n",
            "Epoch 427/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0118 - mae: 0.0872 - val_loss: 0.0115 - val_mae: 0.0839\n",
            "Epoch 428/600\n",
            "600/600 [==============================] - 0s 121us/sample - loss: 0.0110 - mae: 0.0845 - val_loss: 0.0161 - val_mae: 0.1010\n",
            "Epoch 429/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0117 - mae: 0.0865 - val_loss: 0.0147 - val_mae: 0.0950\n",
            "Epoch 430/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0117 - mae: 0.0868 - val_loss: 0.0124 - val_mae: 0.0874\n",
            "Epoch 431/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0115 - mae: 0.0863 - val_loss: 0.0138 - val_mae: 0.0926\n",
            "Epoch 432/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0122 - mae: 0.0879 - val_loss: 0.0123 - val_mae: 0.0865\n",
            "Epoch 433/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0113 - mae: 0.0849 - val_loss: 0.0159 - val_mae: 0.0994\n",
            "Epoch 434/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0116 - mae: 0.0863 - val_loss: 0.0132 - val_mae: 0.0912\n",
            "Epoch 435/600\n",
            "600/600 [==============================] - 0s 130us/sample - loss: 0.0112 - mae: 0.0838 - val_loss: 0.0167 - val_mae: 0.1025\n",
            "Epoch 436/600\n",
            "600/600 [==============================] - 0s 119us/sample - loss: 0.0119 - mae: 0.0879 - val_loss: 0.0124 - val_mae: 0.0882\n",
            "Epoch 437/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0116 - mae: 0.0864 - val_loss: 0.0148 - val_mae: 0.0955\n",
            "Epoch 438/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0117 - mae: 0.0863 - val_loss: 0.0140 - val_mae: 0.0931\n",
            "Epoch 439/600\n",
            "600/600 [==============================] - 0s 138us/sample - loss: 0.0121 - mae: 0.0877 - val_loss: 0.0123 - val_mae: 0.0878\n",
            "Epoch 440/600\n",
            "600/600 [==============================] - 0s 134us/sample - loss: 0.0120 - mae: 0.0872 - val_loss: 0.0118 - val_mae: 0.0847\n",
            "Epoch 441/600\n",
            "600/600 [==============================] - 0s 131us/sample - loss: 0.0119 - mae: 0.0867 - val_loss: 0.0136 - val_mae: 0.0930\n",
            "Epoch 442/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0119 - mae: 0.0875 - val_loss: 0.0149 - val_mae: 0.0933\n",
            "Epoch 443/600\n",
            "600/600 [==============================] - 0s 92us/sample - loss: 0.0114 - mae: 0.0853 - val_loss: 0.0179 - val_mae: 0.1034\n",
            "Epoch 444/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0120 - mae: 0.0870 - val_loss: 0.0129 - val_mae: 0.0903\n",
            "Epoch 445/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0116 - mae: 0.0856 - val_loss: 0.0130 - val_mae: 0.0882\n",
            "Epoch 446/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0105 - mae: 0.0824 - val_loss: 0.0151 - val_mae: 0.0983\n",
            "Epoch 447/600\n",
            "600/600 [==============================] - 0s 129us/sample - loss: 0.0114 - mae: 0.0856 - val_loss: 0.0255 - val_mae: 0.1220\n",
            "Epoch 448/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0121 - mae: 0.0874 - val_loss: 0.0151 - val_mae: 0.0940\n",
            "Epoch 449/600\n",
            "600/600 [==============================] - 0s 112us/sample - loss: 0.0116 - mae: 0.0869 - val_loss: 0.0116 - val_mae: 0.0854\n",
            "Epoch 450/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0119 - mae: 0.0873 - val_loss: 0.0124 - val_mae: 0.0881\n",
            "Epoch 451/600\n",
            "600/600 [==============================] - 0s 126us/sample - loss: 0.0113 - mae: 0.0848 - val_loss: 0.0121 - val_mae: 0.0863\n",
            "Epoch 452/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0144 - val_mae: 0.0937\n",
            "Epoch 453/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0121 - mae: 0.0878 - val_loss: 0.0133 - val_mae: 0.0889\n",
            "Epoch 454/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0115 - mae: 0.0872 - val_loss: 0.0156 - val_mae: 0.0959\n",
            "Epoch 455/600\n",
            "600/600 [==============================] - 0s 136us/sample - loss: 0.0116 - mae: 0.0854 - val_loss: 0.0169 - val_mae: 0.1015\n",
            "Epoch 456/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0122 - mae: 0.0883 - val_loss: 0.0147 - val_mae: 0.0971\n",
            "Epoch 457/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0114 - mae: 0.0850 - val_loss: 0.0123 - val_mae: 0.0863\n",
            "Epoch 458/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0114 - mae: 0.0862 - val_loss: 0.0116 - val_mae: 0.0857\n",
            "Epoch 459/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0108 - mae: 0.0838 - val_loss: 0.0209 - val_mae: 0.1069\n",
            "Epoch 460/600\n",
            "600/600 [==============================] - 0s 147us/sample - loss: 0.0118 - mae: 0.0861 - val_loss: 0.0173 - val_mae: 0.1036\n",
            "Epoch 461/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0109 - mae: 0.0834 - val_loss: 0.0175 - val_mae: 0.1054\n",
            "Epoch 462/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0120 - mae: 0.0864 - val_loss: 0.0134 - val_mae: 0.0895\n",
            "Epoch 463/600\n",
            "600/600 [==============================] - 0s 128us/sample - loss: 0.0117 - mae: 0.0872 - val_loss: 0.0130 - val_mae: 0.0892\n",
            "Epoch 464/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0112 - mae: 0.0846 - val_loss: 0.0118 - val_mae: 0.0854\n",
            "Epoch 465/600\n",
            "600/600 [==============================] - 0s 140us/sample - loss: 0.0113 - mae: 0.0856 - val_loss: 0.0118 - val_mae: 0.0861\n",
            "Epoch 466/600\n",
            "600/600 [==============================] - 0s 129us/sample - loss: 0.0118 - mae: 0.0879 - val_loss: 0.0132 - val_mae: 0.0913\n",
            "Epoch 467/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0149 - val_mae: 0.0932\n",
            "Epoch 468/600\n",
            "600/600 [==============================] - 0s 113us/sample - loss: 0.0109 - mae: 0.0848 - val_loss: 0.0154 - val_mae: 0.0987\n",
            "Epoch 469/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0112 - mae: 0.0854 - val_loss: 0.0142 - val_mae: 0.0945\n",
            "Epoch 470/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0112 - val_mae: 0.0828\n",
            "Epoch 471/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0112 - mae: 0.0851 - val_loss: 0.0125 - val_mae: 0.0888\n",
            "Epoch 472/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0110 - mae: 0.0836 - val_loss: 0.0124 - val_mae: 0.0884\n",
            "Epoch 473/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0119 - mae: 0.0859 - val_loss: 0.0163 - val_mae: 0.0980\n",
            "Epoch 474/600\n",
            "600/600 [==============================] - 0s 116us/sample - loss: 0.0121 - mae: 0.0861 - val_loss: 0.0138 - val_mae: 0.0930\n",
            "Epoch 475/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0111 - mae: 0.0856 - val_loss: 0.0144 - val_mae: 0.0936\n",
            "Epoch 476/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0152 - val_mae: 0.0976\n",
            "Epoch 477/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0117 - mae: 0.0860 - val_loss: 0.0131 - val_mae: 0.0914\n",
            "Epoch 478/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0115 - mae: 0.0856 - val_loss: 0.0115 - val_mae: 0.0835\n",
            "Epoch 479/600\n",
            "600/600 [==============================] - 0s 136us/sample - loss: 0.0110 - mae: 0.0831 - val_loss: 0.0168 - val_mae: 0.1032\n",
            "Epoch 480/600\n",
            "600/600 [==============================] - 0s 93us/sample - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0165 - val_mae: 0.1020\n",
            "Epoch 481/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0110 - mae: 0.0827 - val_loss: 0.0171 - val_mae: 0.1006\n",
            "Epoch 482/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0124 - mae: 0.0883 - val_loss: 0.0141 - val_mae: 0.0931\n",
            "Epoch 483/600\n",
            "600/600 [==============================] - 0s 130us/sample - loss: 0.0112 - mae: 0.0847 - val_loss: 0.0207 - val_mae: 0.1099\n",
            "Epoch 484/600\n",
            "600/600 [==============================] - 0s 128us/sample - loss: 0.0111 - mae: 0.0831 - val_loss: 0.0217 - val_mae: 0.1047\n",
            "Epoch 485/600\n",
            "600/600 [==============================] - 0s 125us/sample - loss: 0.0120 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0877\n",
            "Epoch 486/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0117 - mae: 0.0862 - val_loss: 0.0128 - val_mae: 0.0883\n",
            "Epoch 487/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0116 - mae: 0.0856 - val_loss: 0.0126 - val_mae: 0.0865\n",
            "Epoch 488/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0112 - mae: 0.0849 - val_loss: 0.0127 - val_mae: 0.0878\n",
            "Epoch 489/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0117 - mae: 0.0867 - val_loss: 0.0135 - val_mae: 0.0906\n",
            "Epoch 490/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0115 - mae: 0.0868 - val_loss: 0.0137 - val_mae: 0.0928\n",
            "Epoch 491/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0117 - mae: 0.0864 - val_loss: 0.0141 - val_mae: 0.0939\n",
            "Epoch 492/600\n",
            "600/600 [==============================] - 0s 108us/sample - loss: 0.0114 - mae: 0.0864 - val_loss: 0.0126 - val_mae: 0.0885\n",
            "Epoch 493/600\n",
            "600/600 [==============================] - 0s 90us/sample - loss: 0.0120 - mae: 0.0871 - val_loss: 0.0126 - val_mae: 0.0879\n",
            "Epoch 494/600\n",
            "600/600 [==============================] - 0s 91us/sample - loss: 0.0109 - mae: 0.0842 - val_loss: 0.0140 - val_mae: 0.0937\n",
            "Epoch 495/600\n",
            "600/600 [==============================] - 0s 115us/sample - loss: 0.0116 - mae: 0.0862 - val_loss: 0.0153 - val_mae: 0.0944\n",
            "Epoch 496/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0115 - mae: 0.0873 - val_loss: 0.0149 - val_mae: 0.0974\n",
            "Epoch 497/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0112 - mae: 0.0842 - val_loss: 0.0151 - val_mae: 0.0972\n",
            "Epoch 498/600\n",
            "600/600 [==============================] - 0s 135us/sample - loss: 0.0120 - mae: 0.0870 - val_loss: 0.0139 - val_mae: 0.0937\n",
            "Epoch 499/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0112 - mae: 0.0840 - val_loss: 0.0186 - val_mae: 0.1051\n",
            "Epoch 500/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0113 - mae: 0.0865 - val_loss: 0.0118 - val_mae: 0.0846\n",
            "Epoch 501/600\n",
            "600/600 [==============================] - 0s 94us/sample - loss: 0.0113 - mae: 0.0862 - val_loss: 0.0183 - val_mae: 0.1087\n",
            "Epoch 502/600\n",
            "600/600 [==============================] - 0s 110us/sample - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0255 - val_mae: 0.1250\n",
            "Epoch 503/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0111 - mae: 0.0841 - val_loss: 0.0242 - val_mae: 0.1219\n",
            "Epoch 504/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0118 - mae: 0.0855 - val_loss: 0.0158 - val_mae: 0.0983\n",
            "Epoch 505/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0114 - mae: 0.0850 - val_loss: 0.0119 - val_mae: 0.0859\n",
            "Epoch 506/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0114 - mae: 0.0850 - val_loss: 0.0131 - val_mae: 0.0895\n",
            "Epoch 507/600\n",
            "600/600 [==============================] - 0s 118us/sample - loss: 0.0109 - mae: 0.0837 - val_loss: 0.0189 - val_mae: 0.1064\n",
            "Epoch 508/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0118 - mae: 0.0854 - val_loss: 0.0197 - val_mae: 0.1104\n",
            "Epoch 509/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0110 - mae: 0.0825 - val_loss: 0.0113 - val_mae: 0.0838\n",
            "Epoch 510/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0116 - mae: 0.0845 - val_loss: 0.0148 - val_mae: 0.0929\n",
            "Epoch 511/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0109 - mae: 0.0830 - val_loss: 0.0146 - val_mae: 0.0950\n",
            "Epoch 512/600\n",
            "600/600 [==============================] - 0s 140us/sample - loss: 0.0111 - mae: 0.0841 - val_loss: 0.0155 - val_mae: 0.0996\n",
            "Epoch 513/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0120 - mae: 0.0872 - val_loss: 0.0115 - val_mae: 0.0836\n",
            "Epoch 514/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0110 - mae: 0.0849 - val_loss: 0.0143 - val_mae: 0.0944\n",
            "Epoch 515/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0109 - mae: 0.0833 - val_loss: 0.0126 - val_mae: 0.0888\n",
            "Epoch 516/600\n",
            "600/600 [==============================] - 0s 137us/sample - loss: 0.0122 - mae: 0.0884 - val_loss: 0.0118 - val_mae: 0.0855\n",
            "Epoch 517/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0110 - mae: 0.0847 - val_loss: 0.0132 - val_mae: 0.0920\n",
            "Epoch 518/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0123 - val_mae: 0.0857\n",
            "Epoch 519/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0143 - val_mae: 0.0951\n",
            "Epoch 520/600\n",
            "600/600 [==============================] - 0s 147us/sample - loss: 0.0113 - mae: 0.0855 - val_loss: 0.0148 - val_mae: 0.0966\n",
            "Epoch 521/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0120 - mae: 0.0871 - val_loss: 0.0147 - val_mae: 0.0969\n",
            "Epoch 522/600\n",
            "600/600 [==============================] - 0s 131us/sample - loss: 0.0109 - mae: 0.0843 - val_loss: 0.0169 - val_mae: 0.1020\n",
            "Epoch 523/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0116 - mae: 0.0862 - val_loss: 0.0135 - val_mae: 0.0909\n",
            "Epoch 524/600\n",
            "600/600 [==============================] - 0s 130us/sample - loss: 0.0120 - mae: 0.0877 - val_loss: 0.0123 - val_mae: 0.0861\n",
            "Epoch 525/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0117 - mae: 0.0865 - val_loss: 0.0206 - val_mae: 0.1102\n",
            "Epoch 526/600\n",
            "600/600 [==============================] - 0s 138us/sample - loss: 0.0114 - mae: 0.0848 - val_loss: 0.0120 - val_mae: 0.0867\n",
            "Epoch 527/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0110 - mae: 0.0843 - val_loss: 0.0164 - val_mae: 0.0976\n",
            "Epoch 528/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0118 - mae: 0.0864 - val_loss: 0.0140 - val_mae: 0.0932\n",
            "Epoch 529/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0119 - mae: 0.0879 - val_loss: 0.0122 - val_mae: 0.0866\n",
            "Epoch 530/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0113 - mae: 0.0853 - val_loss: 0.0136 - val_mae: 0.0914\n",
            "Epoch 531/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0111 - mae: 0.0842 - val_loss: 0.0139 - val_mae: 0.0926\n",
            "Epoch 532/600\n",
            "600/600 [==============================] - 0s 126us/sample - loss: 0.0117 - mae: 0.0867 - val_loss: 0.0201 - val_mae: 0.1102\n",
            "Epoch 533/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0121 - mae: 0.0871 - val_loss: 0.0168 - val_mae: 0.1019\n",
            "Epoch 534/600\n",
            "600/600 [==============================] - 0s 134us/sample - loss: 0.0115 - mae: 0.0851 - val_loss: 0.0166 - val_mae: 0.1020\n",
            "Epoch 535/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0111 - mae: 0.0842 - val_loss: 0.0148 - val_mae: 0.0932\n",
            "Epoch 536/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0151 - val_mae: 0.0944\n",
            "Epoch 537/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0106 - mae: 0.0830 - val_loss: 0.0149 - val_mae: 0.0952\n",
            "Epoch 538/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0122 - mae: 0.0885 - val_loss: 0.0121 - val_mae: 0.0869\n",
            "Epoch 539/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0106 - mae: 0.0828 - val_loss: 0.0157 - val_mae: 0.1010\n",
            "Epoch 540/600\n",
            "600/600 [==============================] - 0s 155us/sample - loss: 0.0110 - mae: 0.0844 - val_loss: 0.0127 - val_mae: 0.0888\n",
            "Epoch 541/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0114 - mae: 0.0855 - val_loss: 0.0144 - val_mae: 0.0928\n",
            "Epoch 542/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0110 - mae: 0.0860 - val_loss: 0.0138 - val_mae: 0.0939\n",
            "Epoch 543/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0124 - mae: 0.0889 - val_loss: 0.0126 - val_mae: 0.0883\n",
            "Epoch 544/600\n",
            "600/600 [==============================] - 0s 134us/sample - loss: 0.0117 - mae: 0.0865 - val_loss: 0.0150 - val_mae: 0.0982\n",
            "Epoch 545/600\n",
            "600/600 [==============================] - 0s 136us/sample - loss: 0.0111 - mae: 0.0839 - val_loss: 0.0127 - val_mae: 0.0885\n",
            "Epoch 546/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0109 - mae: 0.0842 - val_loss: 0.0120 - val_mae: 0.0855\n",
            "Epoch 547/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0112 - mae: 0.0854 - val_loss: 0.0140 - val_mae: 0.0925\n",
            "Epoch 548/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0116 - mae: 0.0866 - val_loss: 0.0121 - val_mae: 0.0871\n",
            "Epoch 549/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0109 - mae: 0.0842 - val_loss: 0.0136 - val_mae: 0.0900\n",
            "Epoch 550/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0116 - mae: 0.0855 - val_loss: 0.0128 - val_mae: 0.0898\n",
            "Epoch 551/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0109 - mae: 0.0838 - val_loss: 0.0128 - val_mae: 0.0900\n",
            "Epoch 552/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0108 - mae: 0.0832 - val_loss: 0.0224 - val_mae: 0.1141\n",
            "Epoch 553/600\n",
            "600/600 [==============================] - 0s 114us/sample - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0127 - val_mae: 0.0895\n",
            "Epoch 554/600\n",
            "600/600 [==============================] - 0s 123us/sample - loss: 0.0117 - mae: 0.0857 - val_loss: 0.0141 - val_mae: 0.0938\n",
            "Epoch 555/600\n",
            "600/600 [==============================] - 0s 97us/sample - loss: 0.0110 - mae: 0.0825 - val_loss: 0.0123 - val_mae: 0.0869\n",
            "Epoch 556/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0110 - mae: 0.0836 - val_loss: 0.0130 - val_mae: 0.0892\n",
            "Epoch 557/600\n",
            "600/600 [==============================] - 0s 107us/sample - loss: 0.0114 - mae: 0.0862 - val_loss: 0.0129 - val_mae: 0.0887\n",
            "Epoch 558/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0117 - mae: 0.0850 - val_loss: 0.0169 - val_mae: 0.0988\n",
            "Epoch 559/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0115 - mae: 0.0856 - val_loss: 0.0119 - val_mae: 0.0856\n",
            "Epoch 560/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0116 - mae: 0.0846 - val_loss: 0.0166 - val_mae: 0.0988\n",
            "Epoch 561/600\n",
            "600/600 [==============================] - 0s 114us/sample - loss: 0.0110 - mae: 0.0846 - val_loss: 0.0148 - val_mae: 0.0980\n",
            "Epoch 562/600\n",
            "600/600 [==============================] - 0s 132us/sample - loss: 0.0106 - mae: 0.0821 - val_loss: 0.0134 - val_mae: 0.0915\n",
            "Epoch 563/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0115 - mae: 0.0853 - val_loss: 0.0117 - val_mae: 0.0847\n",
            "Epoch 564/600\n",
            "600/600 [==============================] - 0s 95us/sample - loss: 0.0116 - mae: 0.0864 - val_loss: 0.0144 - val_mae: 0.0950\n",
            "Epoch 565/600\n",
            "600/600 [==============================] - 0s 122us/sample - loss: 0.0113 - mae: 0.0842 - val_loss: 0.0120 - val_mae: 0.0862\n",
            "Epoch 566/600\n",
            "600/600 [==============================] - 0s 136us/sample - loss: 0.0113 - mae: 0.0856 - val_loss: 0.0161 - val_mae: 0.1007\n",
            "Epoch 567/600\n",
            "600/600 [==============================] - 0s 127us/sample - loss: 0.0113 - mae: 0.0863 - val_loss: 0.0138 - val_mae: 0.0925\n",
            "Epoch 568/600\n",
            "600/600 [==============================] - 0s 143us/sample - loss: 0.0118 - mae: 0.0863 - val_loss: 0.0116 - val_mae: 0.0845\n",
            "Epoch 569/600\n",
            "600/600 [==============================] - 0s 99us/sample - loss: 0.0109 - mae: 0.0829 - val_loss: 0.0130 - val_mae: 0.0899\n",
            "Epoch 570/600\n",
            "600/600 [==============================] - 0s 135us/sample - loss: 0.0113 - mae: 0.0850 - val_loss: 0.0186 - val_mae: 0.1051\n",
            "Epoch 571/600\n",
            "600/600 [==============================] - 0s 124us/sample - loss: 0.0116 - mae: 0.0862 - val_loss: 0.0125 - val_mae: 0.0886\n",
            "Epoch 572/600\n",
            "600/600 [==============================] - 0s 106us/sample - loss: 0.0117 - mae: 0.0868 - val_loss: 0.0185 - val_mae: 0.1048\n",
            "Epoch 573/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0113 - mae: 0.0851 - val_loss: 0.0146 - val_mae: 0.0946\n",
            "Epoch 574/600\n",
            "600/600 [==============================] - 0s 125us/sample - loss: 0.0109 - mae: 0.0840 - val_loss: 0.0132 - val_mae: 0.0896\n",
            "Epoch 575/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0115 - mae: 0.0855 - val_loss: 0.0158 - val_mae: 0.0972\n",
            "Epoch 576/600\n",
            "600/600 [==============================] - 0s 142us/sample - loss: 0.0109 - mae: 0.0847 - val_loss: 0.0163 - val_mae: 0.1022\n",
            "Epoch 577/600\n",
            "600/600 [==============================] - 0s 102us/sample - loss: 0.0119 - mae: 0.0852 - val_loss: 0.0125 - val_mae: 0.0870\n",
            "Epoch 578/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0115 - mae: 0.0851 - val_loss: 0.0125 - val_mae: 0.0870\n",
            "Epoch 579/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0105 - mae: 0.0834 - val_loss: 0.0147 - val_mae: 0.0959\n",
            "Epoch 580/600\n",
            "600/600 [==============================] - 0s 131us/sample - loss: 0.0112 - mae: 0.0850 - val_loss: 0.0114 - val_mae: 0.0829\n",
            "Epoch 581/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0107 - mae: 0.0815 - val_loss: 0.0160 - val_mae: 0.1003\n",
            "Epoch 582/600\n",
            "600/600 [==============================] - 0s 118us/sample - loss: 0.0105 - mae: 0.0823 - val_loss: 0.0165 - val_mae: 0.0976\n",
            "Epoch 583/600\n",
            "600/600 [==============================] - 0s 96us/sample - loss: 0.0123 - mae: 0.0888 - val_loss: 0.0128 - val_mae: 0.0878\n",
            "Epoch 584/600\n",
            "600/600 [==============================] - 0s 133us/sample - loss: 0.0116 - mae: 0.0863 - val_loss: 0.0113 - val_mae: 0.0833\n",
            "Epoch 585/600\n",
            "600/600 [==============================] - 0s 118us/sample - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0144 - val_mae: 0.0948\n",
            "Epoch 586/600\n",
            "600/600 [==============================] - 0s 152us/sample - loss: 0.0107 - mae: 0.0838 - val_loss: 0.0125 - val_mae: 0.0895\n",
            "Epoch 587/600\n",
            "600/600 [==============================] - 0s 98us/sample - loss: 0.0115 - mae: 0.0847 - val_loss: 0.0130 - val_mae: 0.0887\n",
            "Epoch 588/600\n",
            "600/600 [==============================] - 0s 138us/sample - loss: 0.0113 - mae: 0.0840 - val_loss: 0.0156 - val_mae: 0.0973\n",
            "Epoch 589/600\n",
            "600/600 [==============================] - 0s 134us/sample - loss: 0.0108 - mae: 0.0829 - val_loss: 0.0177 - val_mae: 0.1002\n",
            "Epoch 590/600\n",
            "600/600 [==============================] - 0s 101us/sample - loss: 0.0112 - mae: 0.0844 - val_loss: 0.0132 - val_mae: 0.0912\n",
            "Epoch 591/600\n",
            "600/600 [==============================] - 0s 105us/sample - loss: 0.0110 - mae: 0.0844 - val_loss: 0.0149 - val_mae: 0.0967\n",
            "Epoch 592/600\n",
            "600/600 [==============================] - 0s 109us/sample - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0118 - val_mae: 0.0861\n",
            "Epoch 593/600\n",
            "600/600 [==============================] - 0s 111us/sample - loss: 0.0107 - mae: 0.0828 - val_loss: 0.0134 - val_mae: 0.0921\n",
            "Epoch 594/600\n",
            "600/600 [==============================] - 0s 141us/sample - loss: 0.0111 - mae: 0.0840 - val_loss: 0.0220 - val_mae: 0.1087\n",
            "Epoch 595/600\n",
            "600/600 [==============================] - 0s 137us/sample - loss: 0.0117 - mae: 0.0861 - val_loss: 0.0137 - val_mae: 0.0902\n",
            "Epoch 596/600\n",
            "600/600 [==============================] - 0s 104us/sample - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0134 - val_mae: 0.0913\n",
            "Epoch 597/600\n",
            "600/600 [==============================] - 0s 100us/sample - loss: 0.0111 - mae: 0.0832 - val_loss: 0.0119 - val_mae: 0.0868\n",
            "Epoch 598/600\n",
            "600/600 [==============================] - 0s 103us/sample - loss: 0.0111 - mae: 0.0849 - val_loss: 0.0121 - val_mae: 0.0860\n",
            "Epoch 599/600\n",
            "600/600 [==============================] - 0s 119us/sample - loss: 0.0106 - mae: 0.0822 - val_loss: 0.0132 - val_mae: 0.0912\n",
            "Epoch 600/600\n",
            "600/600 [==============================] - 0s 132us/sample - loss: 0.0117 - mae: 0.0859 - val_loss: 0.0127 - val_mae: 0.0876\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4F3PKlOscBNw",
        "outputId": "12668f1b-e46f-4551-e56f-0ff8df53cfee"
      },
      "source": [
        "#Toy Problem Y=sin(x) for 250 samples of period -2pi to -pi\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 250\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=-(2*math.pi), high=-(math.pi),size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "#plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_2.summary()\n",
        "history_2 = model_2.fit(x_train, y_train, epochs=600, batch_size=16, validation_data=(x_validate, y_validate))\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_2.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 150 samples, validate on 50 samples\n",
            "Epoch 1/600\n",
            "150/150 [==============================] - 0s 1ms/sample - loss: 2.3506 - mae: 1.4582 - val_loss: 0.9299 - val_mae: 0.9019\n",
            "Epoch 2/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.5463 - mae: 0.6555 - val_loss: 0.2627 - val_mae: 0.4567\n",
            "Epoch 3/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.1739 - mae: 0.3618 - val_loss: 0.1636 - val_mae: 0.3571\n",
            "Epoch 4/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1311 - mae: 0.3070 - val_loss: 0.1506 - val_mae: 0.3186\n",
            "Epoch 5/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.1264 - mae: 0.2958 - val_loss: 0.1503 - val_mae: 0.3173\n",
            "Epoch 6/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.1233 - mae: 0.2910 - val_loss: 0.1713 - val_mae: 0.3690\n",
            "Epoch 7/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1290 - mae: 0.2991 - val_loss: 0.1482 - val_mae: 0.3225\n",
            "Epoch 8/600\n",
            "150/150 [==============================] - 0s 120us/sample - loss: 0.1311 - mae: 0.3012 - val_loss: 0.1477 - val_mae: 0.3195\n",
            "Epoch 9/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1277 - mae: 0.3021 - val_loss: 0.1716 - val_mae: 0.2996\n",
            "Epoch 10/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1246 - mae: 0.2922 - val_loss: 0.1463 - val_mae: 0.3229\n",
            "Epoch 11/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1294 - mae: 0.2953 - val_loss: 0.1494 - val_mae: 0.3353\n",
            "Epoch 12/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.1303 - mae: 0.3013 - val_loss: 0.1526 - val_mae: 0.3008\n",
            "Epoch 13/600\n",
            "150/150 [==============================] - 0s 117us/sample - loss: 0.1257 - mae: 0.2897 - val_loss: 0.1653 - val_mae: 0.3618\n",
            "Epoch 14/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.1292 - mae: 0.3010 - val_loss: 0.1483 - val_mae: 0.3345\n",
            "Epoch 15/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1246 - mae: 0.2916 - val_loss: 0.1444 - val_mae: 0.3259\n",
            "Epoch 16/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1220 - mae: 0.2883 - val_loss: 0.1423 - val_mae: 0.3137\n",
            "Epoch 17/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1283 - mae: 0.2961 - val_loss: 0.1418 - val_mae: 0.3115\n",
            "Epoch 18/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.1224 - mae: 0.2939 - val_loss: 0.1412 - val_mae: 0.3118\n",
            "Epoch 19/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1201 - mae: 0.2899 - val_loss: 0.1478 - val_mae: 0.2953\n",
            "Epoch 20/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1236 - mae: 0.2902 - val_loss: 0.1493 - val_mae: 0.2935\n",
            "Epoch 21/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1222 - mae: 0.2905 - val_loss: 0.1630 - val_mae: 0.2963\n",
            "Epoch 22/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1216 - mae: 0.2858 - val_loss: 0.1507 - val_mae: 0.3420\n",
            "Epoch 23/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.1210 - mae: 0.2910 - val_loss: 0.1446 - val_mae: 0.3313\n",
            "Epoch 24/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.1246 - mae: 0.2906 - val_loss: 0.1385 - val_mae: 0.3027\n",
            "Epoch 25/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1158 - mae: 0.2842 - val_loss: 0.1409 - val_mae: 0.3241\n",
            "Epoch 26/600\n",
            "150/150 [==============================] - 0s 116us/sample - loss: 0.1210 - mae: 0.2855 - val_loss: 0.1529 - val_mae: 0.3464\n",
            "Epoch 27/600\n",
            "150/150 [==============================] - 0s 116us/sample - loss: 0.1180 - mae: 0.2906 - val_loss: 0.1379 - val_mae: 0.2965\n",
            "Epoch 28/600\n",
            "150/150 [==============================] - 0s 120us/sample - loss: 0.1148 - mae: 0.2849 - val_loss: 0.1409 - val_mae: 0.2906\n",
            "Epoch 29/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.1236 - mae: 0.2895 - val_loss: 0.1353 - val_mae: 0.3090\n",
            "Epoch 30/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1184 - mae: 0.2849 - val_loss: 0.1450 - val_mae: 0.3344\n",
            "Epoch 31/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1174 - mae: 0.2844 - val_loss: 0.1452 - val_mae: 0.3349\n",
            "Epoch 32/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1162 - mae: 0.2878 - val_loss: 0.1509 - val_mae: 0.2923\n",
            "Epoch 33/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.1209 - mae: 0.2880 - val_loss: 0.1352 - val_mae: 0.2916\n",
            "Epoch 34/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1170 - mae: 0.2857 - val_loss: 0.1330 - val_mae: 0.3010\n",
            "Epoch 35/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.1152 - mae: 0.2832 - val_loss: 0.1334 - val_mae: 0.3091\n",
            "Epoch 36/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.1165 - mae: 0.2861 - val_loss: 0.1343 - val_mae: 0.3128\n",
            "Epoch 37/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.1194 - mae: 0.2891 - val_loss: 0.1319 - val_mae: 0.2988\n",
            "Epoch 38/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1193 - mae: 0.2880 - val_loss: 0.1405 - val_mae: 0.2882\n",
            "Epoch 39/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.1154 - mae: 0.2823 - val_loss: 0.1434 - val_mae: 0.2896\n",
            "Epoch 40/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.1144 - mae: 0.2814 - val_loss: 0.1346 - val_mae: 0.2874\n",
            "Epoch 41/600\n",
            "150/150 [==============================] - 0s 120us/sample - loss: 0.1206 - mae: 0.2876 - val_loss: 0.1308 - val_mae: 0.3027\n",
            "Epoch 42/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.1194 - mae: 0.2869 - val_loss: 0.1310 - val_mae: 0.2915\n",
            "Epoch 43/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.1139 - mae: 0.2843 - val_loss: 0.1311 - val_mae: 0.3059\n",
            "Epoch 44/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1125 - mae: 0.2785 - val_loss: 0.1399 - val_mae: 0.3275\n",
            "Epoch 45/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1131 - mae: 0.2810 - val_loss: 0.1401 - val_mae: 0.3279\n",
            "Epoch 46/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.1151 - mae: 0.2859 - val_loss: 0.1587 - val_mae: 0.2966\n",
            "Epoch 47/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.1198 - mae: 0.2857 - val_loss: 0.1299 - val_mae: 0.2886\n",
            "Epoch 48/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1135 - mae: 0.2796 - val_loss: 0.1288 - val_mae: 0.2901\n",
            "Epoch 49/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.1123 - mae: 0.2812 - val_loss: 0.1578 - val_mae: 0.2963\n",
            "Epoch 50/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1179 - mae: 0.2812 - val_loss: 0.1580 - val_mae: 0.3538\n",
            "Epoch 51/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1156 - mae: 0.2832 - val_loss: 0.1311 - val_mae: 0.2854\n",
            "Epoch 52/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1129 - mae: 0.2766 - val_loss: 0.1287 - val_mae: 0.3025\n",
            "Epoch 53/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1102 - mae: 0.2766 - val_loss: 0.1592 - val_mae: 0.3552\n",
            "Epoch 54/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1108 - mae: 0.2800 - val_loss: 0.1271 - val_mae: 0.2888\n",
            "Epoch 55/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1151 - mae: 0.2847 - val_loss: 0.1292 - val_mae: 0.2853\n",
            "Epoch 56/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1124 - mae: 0.2807 - val_loss: 0.1314 - val_mae: 0.2850\n",
            "Epoch 57/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.1130 - mae: 0.2760 - val_loss: 0.1434 - val_mae: 0.3339\n",
            "Epoch 58/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.1151 - mae: 0.2863 - val_loss: 0.1289 - val_mae: 0.3058\n",
            "Epoch 59/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.1136 - mae: 0.2815 - val_loss: 0.1271 - val_mae: 0.2998\n",
            "Epoch 60/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.1128 - mae: 0.2766 - val_loss: 0.1258 - val_mae: 0.2877\n",
            "Epoch 61/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.1130 - mae: 0.2772 - val_loss: 0.1254 - val_mae: 0.2880\n",
            "Epoch 62/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.1107 - mae: 0.2762 - val_loss: 0.1248 - val_mae: 0.2920\n",
            "Epoch 63/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1139 - mae: 0.2782 - val_loss: 0.1246 - val_mae: 0.2888\n",
            "Epoch 64/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1140 - mae: 0.2807 - val_loss: 0.1243 - val_mae: 0.2898\n",
            "Epoch 65/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.1138 - mae: 0.2771 - val_loss: 0.1244 - val_mae: 0.2879\n",
            "Epoch 66/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1107 - mae: 0.2740 - val_loss: 0.1292 - val_mae: 0.3079\n",
            "Epoch 67/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1100 - mae: 0.2737 - val_loss: 0.1436 - val_mae: 0.3336\n",
            "Epoch 68/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.1131 - mae: 0.2801 - val_loss: 0.1237 - val_mae: 0.2905\n",
            "Epoch 69/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1066 - mae: 0.2705 - val_loss: 0.1238 - val_mae: 0.2878\n",
            "Epoch 70/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1133 - mae: 0.2790 - val_loss: 0.1285 - val_mae: 0.3066\n",
            "Epoch 71/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1116 - mae: 0.2785 - val_loss: 0.1266 - val_mae: 0.2845\n",
            "Epoch 72/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.1071 - mae: 0.2713 - val_loss: 0.1248 - val_mae: 0.2850\n",
            "Epoch 73/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.1075 - mae: 0.2743 - val_loss: 0.1248 - val_mae: 0.2848\n",
            "Epoch 74/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1079 - mae: 0.2755 - val_loss: 0.1282 - val_mae: 0.2838\n",
            "Epoch 75/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.1062 - mae: 0.2674 - val_loss: 0.1267 - val_mae: 0.2840\n",
            "Epoch 76/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1103 - mae: 0.2734 - val_loss: 0.1234 - val_mae: 0.2930\n",
            "Epoch 77/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1101 - mae: 0.2727 - val_loss: 0.1314 - val_mae: 0.3133\n",
            "Epoch 78/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1102 - mae: 0.2746 - val_loss: 0.1264 - val_mae: 0.2840\n",
            "Epoch 79/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.1081 - mae: 0.2740 - val_loss: 0.1253 - val_mae: 0.2842\n",
            "Epoch 80/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1088 - mae: 0.2702 - val_loss: 0.1218 - val_mae: 0.2875\n",
            "Epoch 81/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.1094 - mae: 0.2737 - val_loss: 0.1227 - val_mae: 0.2924\n",
            "Epoch 82/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.1065 - mae: 0.2704 - val_loss: 0.1280 - val_mae: 0.3058\n",
            "Epoch 83/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.1084 - mae: 0.2739 - val_loss: 0.1221 - val_mae: 0.2853\n",
            "Epoch 84/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1061 - mae: 0.2697 - val_loss: 0.1215 - val_mae: 0.2890\n",
            "Epoch 85/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1127 - mae: 0.2782 - val_loss: 0.1304 - val_mae: 0.2846\n",
            "Epoch 86/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1109 - mae: 0.2710 - val_loss: 0.1224 - val_mae: 0.2928\n",
            "Epoch 87/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1144 - mae: 0.2787 - val_loss: 0.1318 - val_mae: 0.3139\n",
            "Epoch 88/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1094 - mae: 0.2761 - val_loss: 0.1354 - val_mae: 0.3201\n",
            "Epoch 89/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1115 - mae: 0.2811 - val_loss: 0.1275 - val_mae: 0.3049\n",
            "Epoch 90/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1136 - mae: 0.2804 - val_loss: 0.1282 - val_mae: 0.3065\n",
            "Epoch 91/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.1123 - mae: 0.2804 - val_loss: 0.1223 - val_mae: 0.2847\n",
            "Epoch 92/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1071 - mae: 0.2689 - val_loss: 0.1228 - val_mae: 0.2948\n",
            "Epoch 93/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.1061 - mae: 0.2701 - val_loss: 0.1208 - val_mae: 0.2856\n",
            "Epoch 94/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1090 - mae: 0.2753 - val_loss: 0.1212 - val_mae: 0.2901\n",
            "Epoch 95/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1044 - mae: 0.2691 - val_loss: 0.1278 - val_mae: 0.2835\n",
            "Epoch 96/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1110 - mae: 0.2759 - val_loss: 0.1224 - val_mae: 0.2942\n",
            "Epoch 97/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1103 - mae: 0.2737 - val_loss: 0.1207 - val_mae: 0.2851\n",
            "Epoch 98/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1106 - mae: 0.2724 - val_loss: 0.1216 - val_mae: 0.2927\n",
            "Epoch 99/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.1098 - mae: 0.2762 - val_loss: 0.1236 - val_mae: 0.2837\n",
            "Epoch 100/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.1108 - mae: 0.2744 - val_loss: 0.1263 - val_mae: 0.3029\n",
            "Epoch 101/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.1069 - mae: 0.2699 - val_loss: 0.1201 - val_mae: 0.2882\n",
            "Epoch 102/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1060 - mae: 0.2695 - val_loss: 0.1262 - val_mae: 0.3028\n",
            "Epoch 103/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1090 - mae: 0.2779 - val_loss: 0.1325 - val_mae: 0.3145\n",
            "Epoch 104/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1105 - mae: 0.2788 - val_loss: 0.1269 - val_mae: 0.3042\n",
            "Epoch 105/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1062 - mae: 0.2741 - val_loss: 0.1237 - val_mae: 0.2834\n",
            "Epoch 106/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.1069 - mae: 0.2687 - val_loss: 0.1199 - val_mae: 0.2891\n",
            "Epoch 107/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.1109 - mae: 0.2731 - val_loss: 0.1206 - val_mae: 0.2916\n",
            "Epoch 108/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1093 - mae: 0.2717 - val_loss: 0.1206 - val_mae: 0.2917\n",
            "Epoch 109/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1046 - mae: 0.2698 - val_loss: 0.1376 - val_mae: 0.2897\n",
            "Epoch 110/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.1090 - mae: 0.2703 - val_loss: 0.1191 - val_mae: 0.2862\n",
            "Epoch 111/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1071 - mae: 0.2712 - val_loss: 0.1203 - val_mae: 0.2912\n",
            "Epoch 112/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1076 - mae: 0.2719 - val_loss: 0.1194 - val_mae: 0.2848\n",
            "Epoch 113/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.1127 - mae: 0.2808 - val_loss: 0.1204 - val_mae: 0.2841\n",
            "Epoch 114/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.1029 - mae: 0.2660 - val_loss: 0.1227 - val_mae: 0.2970\n",
            "Epoch 115/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.1085 - mae: 0.2721 - val_loss: 0.1195 - val_mae: 0.2898\n",
            "Epoch 116/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1026 - mae: 0.2680 - val_loss: 0.1234 - val_mae: 0.2832\n",
            "Epoch 117/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.1123 - mae: 0.2743 - val_loss: 0.1195 - val_mae: 0.2843\n",
            "Epoch 118/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1071 - mae: 0.2633 - val_loss: 0.1374 - val_mae: 0.3222\n",
            "Epoch 119/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1083 - mae: 0.2758 - val_loss: 0.1245 - val_mae: 0.3006\n",
            "Epoch 120/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1056 - mae: 0.2708 - val_loss: 0.1213 - val_mae: 0.2945\n",
            "Epoch 121/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1077 - mae: 0.2716 - val_loss: 0.1431 - val_mae: 0.2932\n",
            "Epoch 122/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1149 - mae: 0.2779 - val_loss: 0.1191 - val_mae: 0.2893\n",
            "Epoch 123/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.1093 - mae: 0.2749 - val_loss: 0.1182 - val_mae: 0.2852\n",
            "Epoch 124/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1087 - mae: 0.2731 - val_loss: 0.1186 - val_mae: 0.2845\n",
            "Epoch 125/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.1069 - mae: 0.2684 - val_loss: 0.1185 - val_mae: 0.2846\n",
            "Epoch 126/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1070 - mae: 0.2714 - val_loss: 0.1266 - val_mae: 0.2834\n",
            "Epoch 127/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.1085 - mae: 0.2666 - val_loss: 0.1346 - val_mae: 0.2886\n",
            "Epoch 128/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.1045 - mae: 0.2658 - val_loss: 0.1185 - val_mae: 0.2882\n",
            "Epoch 129/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1077 - mae: 0.2668 - val_loss: 0.1325 - val_mae: 0.2873\n",
            "Epoch 130/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1108 - mae: 0.2699 - val_loss: 0.1217 - val_mae: 0.2957\n",
            "Epoch 131/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1062 - mae: 0.2689 - val_loss: 0.1198 - val_mae: 0.2921\n",
            "Epoch 132/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.1079 - mae: 0.2744 - val_loss: 0.1340 - val_mae: 0.2883\n",
            "Epoch 133/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1073 - mae: 0.2627 - val_loss: 0.1187 - val_mae: 0.2842\n",
            "Epoch 134/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1067 - mae: 0.2643 - val_loss: 0.1177 - val_mae: 0.2854\n",
            "Epoch 135/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1111 - mae: 0.2693 - val_loss: 0.1188 - val_mae: 0.2840\n",
            "Epoch 136/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1064 - mae: 0.2697 - val_loss: 0.1256 - val_mae: 0.3030\n",
            "Epoch 137/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1056 - mae: 0.2722 - val_loss: 0.1183 - val_mae: 0.2842\n",
            "Epoch 138/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1073 - mae: 0.2702 - val_loss: 0.1237 - val_mae: 0.2997\n",
            "Epoch 139/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.1077 - mae: 0.2702 - val_loss: 0.1201 - val_mae: 0.2834\n",
            "Epoch 140/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1081 - mae: 0.2697 - val_loss: 0.1404 - val_mae: 0.3257\n",
            "Epoch 141/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1115 - mae: 0.2765 - val_loss: 0.1179 - val_mae: 0.2874\n",
            "Epoch 142/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1062 - mae: 0.2714 - val_loss: 0.1275 - val_mae: 0.3060\n",
            "Epoch 143/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.1067 - mae: 0.2741 - val_loss: 0.1176 - val_mae: 0.2848\n",
            "Epoch 144/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1086 - mae: 0.2723 - val_loss: 0.1220 - val_mae: 0.2832\n",
            "Epoch 145/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1047 - mae: 0.2663 - val_loss: 0.1298 - val_mae: 0.3096\n",
            "Epoch 146/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1055 - mae: 0.2637 - val_loss: 0.1310 - val_mae: 0.3115\n",
            "Epoch 147/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1080 - mae: 0.2697 - val_loss: 0.1384 - val_mae: 0.3226\n",
            "Epoch 148/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1065 - mae: 0.2734 - val_loss: 0.1311 - val_mae: 0.2867\n",
            "Epoch 149/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1131 - mae: 0.2732 - val_loss: 0.1246 - val_mae: 0.2832\n",
            "Epoch 150/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1065 - mae: 0.2700 - val_loss: 0.1211 - val_mae: 0.2950\n",
            "Epoch 151/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.1043 - mae: 0.2669 - val_loss: 0.1495 - val_mae: 0.2968\n",
            "Epoch 152/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1140 - mae: 0.2747 - val_loss: 0.1186 - val_mae: 0.2838\n",
            "Epoch 153/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.1061 - mae: 0.2701 - val_loss: 0.1192 - val_mae: 0.2834\n",
            "Epoch 154/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1065 - mae: 0.2695 - val_loss: 0.1221 - val_mae: 0.2971\n",
            "Epoch 155/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.1054 - mae: 0.2687 - val_loss: 0.1424 - val_mae: 0.3280\n",
            "Epoch 156/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.1017 - mae: 0.2668 - val_loss: 0.1172 - val_mae: 0.2846\n",
            "Epoch 157/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.1065 - mae: 0.2726 - val_loss: 0.1231 - val_mae: 0.2832\n",
            "Epoch 158/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.1064 - mae: 0.2699 - val_loss: 0.1199 - val_mae: 0.2933\n",
            "Epoch 159/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.1049 - mae: 0.2673 - val_loss: 0.1385 - val_mae: 0.3222\n",
            "Epoch 160/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1078 - mae: 0.2772 - val_loss: 0.1279 - val_mae: 0.3067\n",
            "Epoch 161/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1049 - mae: 0.2709 - val_loss: 0.1325 - val_mae: 0.2879\n",
            "Epoch 162/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.1057 - mae: 0.2676 - val_loss: 0.1233 - val_mae: 0.2832\n",
            "Epoch 163/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1096 - mae: 0.2754 - val_loss: 0.1171 - val_mae: 0.2850\n",
            "Epoch 164/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.1075 - mae: 0.2716 - val_loss: 0.1252 - val_mae: 0.3025\n",
            "Epoch 165/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.1095 - mae: 0.2718 - val_loss: 0.1212 - val_mae: 0.2832\n",
            "Epoch 166/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1087 - mae: 0.2713 - val_loss: 0.1188 - val_mae: 0.2913\n",
            "Epoch 167/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1048 - mae: 0.2698 - val_loss: 0.1181 - val_mae: 0.2837\n",
            "Epoch 168/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1076 - mae: 0.2722 - val_loss: 0.1217 - val_mae: 0.2966\n",
            "Epoch 169/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1058 - mae: 0.2721 - val_loss: 0.1237 - val_mae: 0.2833\n",
            "Epoch 170/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.1119 - mae: 0.2771 - val_loss: 0.1385 - val_mae: 0.2916\n",
            "Epoch 171/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1072 - mae: 0.2626 - val_loss: 0.1301 - val_mae: 0.3103\n",
            "Epoch 172/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1073 - mae: 0.2730 - val_loss: 0.1170 - val_mae: 0.2867\n",
            "Epoch 173/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1090 - mae: 0.2753 - val_loss: 0.1178 - val_mae: 0.2837\n",
            "Epoch 174/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.1063 - mae: 0.2712 - val_loss: 0.1210 - val_mae: 0.2955\n",
            "Epoch 175/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.1060 - mae: 0.2709 - val_loss: 0.1358 - val_mae: 0.2901\n",
            "Epoch 176/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.1109 - mae: 0.2763 - val_loss: 0.1265 - val_mae: 0.2841\n",
            "Epoch 177/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.1052 - mae: 0.2697 - val_loss: 0.1255 - val_mae: 0.2837\n",
            "Epoch 178/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.1083 - mae: 0.2702 - val_loss: 0.1214 - val_mae: 0.2832\n",
            "Epoch 179/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1073 - mae: 0.2705 - val_loss: 0.1229 - val_mae: 0.2989\n",
            "Epoch 180/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1096 - mae: 0.2754 - val_loss: 0.1167 - val_mae: 0.2852\n",
            "Epoch 181/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1083 - mae: 0.2746 - val_loss: 0.1217 - val_mae: 0.2832\n",
            "Epoch 182/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.1054 - mae: 0.2638 - val_loss: 0.1167 - val_mae: 0.2848\n",
            "Epoch 183/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1081 - mae: 0.2713 - val_loss: 0.1179 - val_mae: 0.2836\n",
            "Epoch 184/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1092 - mae: 0.2756 - val_loss: 0.1410 - val_mae: 0.2930\n",
            "Epoch 185/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1126 - mae: 0.2724 - val_loss: 0.1170 - val_mae: 0.2841\n",
            "Epoch 186/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.1048 - mae: 0.2667 - val_loss: 0.1180 - val_mae: 0.2835\n",
            "Epoch 187/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1077 - mae: 0.2669 - val_loss: 0.1246 - val_mae: 0.3018\n",
            "Epoch 188/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.1072 - mae: 0.2691 - val_loss: 0.1216 - val_mae: 0.2832\n",
            "Epoch 189/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1070 - mae: 0.2733 - val_loss: 0.1230 - val_mae: 0.2833\n",
            "Epoch 190/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1069 - mae: 0.2638 - val_loss: 0.1191 - val_mae: 0.2832\n",
            "Epoch 191/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.1067 - mae: 0.2663 - val_loss: 0.1226 - val_mae: 0.2832\n",
            "Epoch 192/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.1057 - mae: 0.2684 - val_loss: 0.1193 - val_mae: 0.2832\n",
            "Epoch 193/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.1038 - mae: 0.2658 - val_loss: 0.1170 - val_mae: 0.2840\n",
            "Epoch 194/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1111 - mae: 0.2715 - val_loss: 0.1240 - val_mae: 0.3008\n",
            "Epoch 195/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1097 - mae: 0.2769 - val_loss: 0.1229 - val_mae: 0.2834\n",
            "Epoch 196/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1047 - mae: 0.2651 - val_loss: 0.1181 - val_mae: 0.2833\n",
            "Epoch 197/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0966 - mae: 0.2528 - val_loss: 0.1675 - val_mae: 0.3566\n",
            "Epoch 198/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.1107 - mae: 0.2754 - val_loss: 0.1194 - val_mae: 0.2930\n",
            "Epoch 199/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1046 - mae: 0.2666 - val_loss: 0.1268 - val_mae: 0.2845\n",
            "Epoch 200/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.1053 - mae: 0.2672 - val_loss: 0.1298 - val_mae: 0.3099\n",
            "Epoch 201/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1101 - mae: 0.2735 - val_loss: 0.1178 - val_mae: 0.2901\n",
            "Epoch 202/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1057 - mae: 0.2660 - val_loss: 0.1258 - val_mae: 0.3035\n",
            "Epoch 203/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1050 - mae: 0.2698 - val_loss: 0.1177 - val_mae: 0.2835\n",
            "Epoch 204/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.1142 - mae: 0.2758 - val_loss: 0.1203 - val_mae: 0.2946\n",
            "Epoch 205/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1099 - mae: 0.2755 - val_loss: 0.1165 - val_mae: 0.2846\n",
            "Epoch 206/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1067 - mae: 0.2677 - val_loss: 0.1227 - val_mae: 0.2987\n",
            "Epoch 207/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.1080 - mae: 0.2716 - val_loss: 0.1168 - val_mae: 0.2869\n",
            "Epoch 208/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.1050 - mae: 0.2693 - val_loss: 0.1214 - val_mae: 0.2832\n",
            "Epoch 209/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.1077 - mae: 0.2716 - val_loss: 0.1226 - val_mae: 0.2986\n",
            "Epoch 210/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.1052 - mae: 0.2720 - val_loss: 0.1169 - val_mae: 0.2871\n",
            "Epoch 211/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1063 - mae: 0.2697 - val_loss: 0.1166 - val_mae: 0.2855\n",
            "Epoch 212/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.1080 - mae: 0.2700 - val_loss: 0.1166 - val_mae: 0.2848\n",
            "Epoch 213/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1097 - mae: 0.2721 - val_loss: 0.1181 - val_mae: 0.2834\n",
            "Epoch 214/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1067 - mae: 0.2688 - val_loss: 0.1203 - val_mae: 0.2832\n",
            "Epoch 215/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1054 - mae: 0.2645 - val_loss: 0.1165 - val_mae: 0.2849\n",
            "Epoch 216/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1066 - mae: 0.2690 - val_loss: 0.1195 - val_mae: 0.2832\n",
            "Epoch 217/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.1128 - mae: 0.2776 - val_loss: 0.1191 - val_mae: 0.2925\n",
            "Epoch 218/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1055 - mae: 0.2686 - val_loss: 0.1165 - val_mae: 0.2853\n",
            "Epoch 219/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.1047 - mae: 0.2628 - val_loss: 0.1569 - val_mae: 0.3443\n",
            "Epoch 220/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1102 - mae: 0.2756 - val_loss: 0.1252 - val_mae: 0.2838\n",
            "Epoch 221/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.1100 - mae: 0.2721 - val_loss: 0.1170 - val_mae: 0.2839\n",
            "Epoch 222/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.1069 - mae: 0.2700 - val_loss: 0.1180 - val_mae: 0.2834\n",
            "Epoch 223/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1042 - mae: 0.2684 - val_loss: 0.1312 - val_mae: 0.2874\n",
            "Epoch 224/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.1092 - mae: 0.2685 - val_loss: 0.1297 - val_mae: 0.3098\n",
            "Epoch 225/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1061 - mae: 0.2711 - val_loss: 0.1184 - val_mae: 0.2914\n",
            "Epoch 226/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1083 - mae: 0.2737 - val_loss: 0.1269 - val_mae: 0.2846\n",
            "Epoch 227/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1107 - mae: 0.2747 - val_loss: 0.1164 - val_mae: 0.2849\n",
            "Epoch 228/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1071 - mae: 0.2714 - val_loss: 0.1180 - val_mae: 0.2906\n",
            "Epoch 229/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.1057 - mae: 0.2646 - val_loss: 0.1258 - val_mae: 0.3035\n",
            "Epoch 230/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.1100 - mae: 0.2695 - val_loss: 0.1184 - val_mae: 0.2914\n",
            "Epoch 231/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.1053 - mae: 0.2669 - val_loss: 0.1311 - val_mae: 0.3119\n",
            "Epoch 232/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1106 - mae: 0.2717 - val_loss: 0.1335 - val_mae: 0.3151\n",
            "Epoch 233/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1081 - mae: 0.2726 - val_loss: 0.1197 - val_mae: 0.2832\n",
            "Epoch 234/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.1060 - mae: 0.2682 - val_loss: 0.1186 - val_mae: 0.2917\n",
            "Epoch 235/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.1071 - mae: 0.2696 - val_loss: 0.1165 - val_mae: 0.2857\n",
            "Epoch 236/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.1033 - mae: 0.2678 - val_loss: 0.1615 - val_mae: 0.3050\n",
            "Epoch 237/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1178 - mae: 0.2749 - val_loss: 0.1167 - val_mae: 0.2870\n",
            "Epoch 238/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1066 - mae: 0.2682 - val_loss: 0.1207 - val_mae: 0.2955\n",
            "Epoch 239/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.1045 - mae: 0.2667 - val_loss: 0.1177 - val_mae: 0.2834\n",
            "Epoch 240/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1041 - mae: 0.2636 - val_loss: 0.1378 - val_mae: 0.3207\n",
            "Epoch 241/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.1104 - mae: 0.2749 - val_loss: 0.1182 - val_mae: 0.2910\n",
            "Epoch 242/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1109 - mae: 0.2770 - val_loss: 0.1164 - val_mae: 0.2846\n",
            "Epoch 243/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1063 - mae: 0.2637 - val_loss: 0.1219 - val_mae: 0.2974\n",
            "Epoch 244/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1072 - mae: 0.2689 - val_loss: 0.1207 - val_mae: 0.2956\n",
            "Epoch 245/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1092 - mae: 0.2748 - val_loss: 0.1202 - val_mae: 0.2832\n",
            "Epoch 246/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1079 - mae: 0.2717 - val_loss: 0.1186 - val_mae: 0.2833\n",
            "Epoch 247/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1045 - mae: 0.2665 - val_loss: 0.1171 - val_mae: 0.2888\n",
            "Epoch 248/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1034 - mae: 0.2639 - val_loss: 0.1215 - val_mae: 0.2969\n",
            "Epoch 249/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1088 - mae: 0.2734 - val_loss: 0.1259 - val_mae: 0.3037\n",
            "Epoch 250/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.1071 - mae: 0.2734 - val_loss: 0.1300 - val_mae: 0.3102\n",
            "Epoch 251/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1030 - mae: 0.2680 - val_loss: 0.1264 - val_mae: 0.3044\n",
            "Epoch 252/600\n",
            "150/150 [==============================] - 0s 244us/sample - loss: 0.1074 - mae: 0.2746 - val_loss: 0.1169 - val_mae: 0.2877\n",
            "Epoch 253/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1037 - mae: 0.2665 - val_loss: 0.1242 - val_mae: 0.2836\n",
            "Epoch 254/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1134 - mae: 0.2784 - val_loss: 0.1166 - val_mae: 0.2855\n",
            "Epoch 255/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.1035 - mae: 0.2663 - val_loss: 0.1185 - val_mae: 0.2914\n",
            "Epoch 256/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.1039 - mae: 0.2661 - val_loss: 0.1426 - val_mae: 0.2939\n",
            "Epoch 257/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1067 - mae: 0.2694 - val_loss: 0.1290 - val_mae: 0.2858\n",
            "Epoch 258/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.1044 - mae: 0.2648 - val_loss: 0.1358 - val_mae: 0.2902\n",
            "Epoch 259/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.1053 - mae: 0.2629 - val_loss: 0.1217 - val_mae: 0.2968\n",
            "Epoch 260/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1087 - mae: 0.2731 - val_loss: 0.1169 - val_mae: 0.2841\n",
            "Epoch 261/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.1079 - mae: 0.2701 - val_loss: 0.1309 - val_mae: 0.3115\n",
            "Epoch 262/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.1078 - mae: 0.2743 - val_loss: 0.1272 - val_mae: 0.3059\n",
            "Epoch 263/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1077 - mae: 0.2743 - val_loss: 0.1166 - val_mae: 0.2856\n",
            "Epoch 264/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.1036 - mae: 0.2680 - val_loss: 0.1211 - val_mae: 0.2959\n",
            "Epoch 265/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1110 - mae: 0.2754 - val_loss: 0.1167 - val_mae: 0.2865\n",
            "Epoch 266/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.1057 - mae: 0.2699 - val_loss: 0.1277 - val_mae: 0.2850\n",
            "Epoch 267/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.1064 - mae: 0.2689 - val_loss: 0.1237 - val_mae: 0.3003\n",
            "Epoch 268/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1057 - mae: 0.2658 - val_loss: 0.1406 - val_mae: 0.3243\n",
            "Epoch 269/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1089 - mae: 0.2715 - val_loss: 0.1175 - val_mae: 0.2895\n",
            "Epoch 270/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1075 - mae: 0.2725 - val_loss: 0.1258 - val_mae: 0.2839\n",
            "Epoch 271/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.1056 - mae: 0.2627 - val_loss: 0.1278 - val_mae: 0.3069\n",
            "Epoch 272/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1081 - mae: 0.2724 - val_loss: 0.1197 - val_mae: 0.2832\n",
            "Epoch 273/600\n",
            "150/150 [==============================] - 0s 245us/sample - loss: 0.1048 - mae: 0.2637 - val_loss: 0.1399 - val_mae: 0.3234\n",
            "Epoch 274/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.1119 - mae: 0.2779 - val_loss: 0.1326 - val_mae: 0.2883\n",
            "Epoch 275/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.1125 - mae: 0.2677 - val_loss: 0.1168 - val_mae: 0.2841\n",
            "Epoch 276/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.1036 - mae: 0.2631 - val_loss: 0.1227 - val_mae: 0.2988\n",
            "Epoch 277/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1076 - mae: 0.2711 - val_loss: 0.1173 - val_mae: 0.2887\n",
            "Epoch 278/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.1103 - mae: 0.2740 - val_loss: 0.1253 - val_mae: 0.2838\n",
            "Epoch 279/600\n",
            "150/150 [==============================] - 0s 276us/sample - loss: 0.1059 - mae: 0.2680 - val_loss: 0.1169 - val_mae: 0.2871\n",
            "Epoch 280/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1033 - mae: 0.2690 - val_loss: 0.1178 - val_mae: 0.2899\n",
            "Epoch 281/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1058 - mae: 0.2677 - val_loss: 0.1175 - val_mae: 0.2837\n",
            "Epoch 282/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.1058 - mae: 0.2698 - val_loss: 0.1188 - val_mae: 0.2918\n",
            "Epoch 283/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1076 - mae: 0.2719 - val_loss: 0.1168 - val_mae: 0.2867\n",
            "Epoch 284/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.1042 - mae: 0.2612 - val_loss: 0.1169 - val_mae: 0.2843\n",
            "Epoch 285/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.1065 - mae: 0.2669 - val_loss: 0.1408 - val_mae: 0.3250\n",
            "Epoch 286/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1054 - mae: 0.2681 - val_loss: 0.1172 - val_mae: 0.2881\n",
            "Epoch 287/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.1071 - mae: 0.2714 - val_loss: 0.1178 - val_mae: 0.2899\n",
            "Epoch 288/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.1056 - mae: 0.2690 - val_loss: 0.1311 - val_mae: 0.3118\n",
            "Epoch 289/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.1125 - mae: 0.2786 - val_loss: 0.1196 - val_mae: 0.2932\n",
            "Epoch 290/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1065 - mae: 0.2684 - val_loss: 0.1178 - val_mae: 0.2897\n",
            "Epoch 291/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1129 - mae: 0.2813 - val_loss: 0.1190 - val_mae: 0.2832\n",
            "Epoch 292/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.1041 - mae: 0.2632 - val_loss: 0.1176 - val_mae: 0.2892\n",
            "Epoch 293/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1043 - mae: 0.2655 - val_loss: 0.1394 - val_mae: 0.3230\n",
            "Epoch 294/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.1072 - mae: 0.2712 - val_loss: 0.1201 - val_mae: 0.2832\n",
            "Epoch 295/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.1097 - mae: 0.2674 - val_loss: 0.1319 - val_mae: 0.3129\n",
            "Epoch 296/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1037 - mae: 0.2664 - val_loss: 0.1239 - val_mae: 0.3007\n",
            "Epoch 297/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.1058 - mae: 0.2685 - val_loss: 0.1222 - val_mae: 0.2832\n",
            "Epoch 298/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.1095 - mae: 0.2706 - val_loss: 0.1312 - val_mae: 0.2873\n",
            "Epoch 299/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1072 - mae: 0.2648 - val_loss: 0.1171 - val_mae: 0.2880\n",
            "Epoch 300/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.1057 - mae: 0.2650 - val_loss: 0.1167 - val_mae: 0.2844\n",
            "Epoch 301/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.1108 - mae: 0.2753 - val_loss: 0.1230 - val_mae: 0.2992\n",
            "Epoch 302/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.1080 - mae: 0.2722 - val_loss: 0.1205 - val_mae: 0.2948\n",
            "Epoch 303/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.1046 - mae: 0.2657 - val_loss: 0.1198 - val_mae: 0.2935\n",
            "Epoch 304/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1042 - mae: 0.2721 - val_loss: 0.1252 - val_mae: 0.2837\n",
            "Epoch 305/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.1052 - mae: 0.2637 - val_loss: 0.1299 - val_mae: 0.3101\n",
            "Epoch 306/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.1091 - mae: 0.2717 - val_loss: 0.1216 - val_mae: 0.2969\n",
            "Epoch 307/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1055 - mae: 0.2729 - val_loss: 0.1239 - val_mae: 0.2836\n",
            "Epoch 308/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1065 - mae: 0.2677 - val_loss: 0.1285 - val_mae: 0.3079\n",
            "Epoch 309/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1040 - mae: 0.2689 - val_loss: 0.1405 - val_mae: 0.2929\n",
            "Epoch 310/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.1106 - mae: 0.2730 - val_loss: 0.1165 - val_mae: 0.2858\n",
            "Epoch 311/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.1108 - mae: 0.2780 - val_loss: 0.1168 - val_mae: 0.2841\n",
            "Epoch 312/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.1071 - mae: 0.2691 - val_loss: 0.1205 - val_mae: 0.2949\n",
            "Epoch 313/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.1048 - mae: 0.2650 - val_loss: 0.1271 - val_mae: 0.3057\n",
            "Epoch 314/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.1064 - mae: 0.2727 - val_loss: 0.1308 - val_mae: 0.2872\n",
            "Epoch 315/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.1087 - mae: 0.2691 - val_loss: 0.1242 - val_mae: 0.2837\n",
            "Epoch 316/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1060 - mae: 0.2654 - val_loss: 0.1175 - val_mae: 0.2836\n",
            "Epoch 317/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1042 - mae: 0.2650 - val_loss: 0.1202 - val_mae: 0.2832\n",
            "Epoch 318/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.1061 - mae: 0.2670 - val_loss: 0.1288 - val_mae: 0.3085\n",
            "Epoch 319/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1065 - mae: 0.2713 - val_loss: 0.1174 - val_mae: 0.2893\n",
            "Epoch 320/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1082 - mae: 0.2720 - val_loss: 0.1179 - val_mae: 0.2904\n",
            "Epoch 321/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1084 - mae: 0.2739 - val_loss: 0.1180 - val_mae: 0.2905\n",
            "Epoch 322/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1037 - mae: 0.2649 - val_loss: 0.1176 - val_mae: 0.2836\n",
            "Epoch 323/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1109 - mae: 0.2756 - val_loss: 0.1197 - val_mae: 0.2832\n",
            "Epoch 324/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.1060 - mae: 0.2681 - val_loss: 0.1252 - val_mae: 0.2838\n",
            "Epoch 325/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1083 - mae: 0.2694 - val_loss: 0.1169 - val_mae: 0.2840\n",
            "Epoch 326/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.1076 - mae: 0.2679 - val_loss: 0.1207 - val_mae: 0.2953\n",
            "Epoch 327/600\n",
            "150/150 [==============================] - 0s 219us/sample - loss: 0.1068 - mae: 0.2705 - val_loss: 0.1173 - val_mae: 0.2837\n",
            "Epoch 328/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.1091 - mae: 0.2713 - val_loss: 0.1165 - val_mae: 0.2852\n",
            "Epoch 329/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.1026 - mae: 0.2648 - val_loss: 0.1252 - val_mae: 0.3027\n",
            "Epoch 330/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1066 - mae: 0.2730 - val_loss: 0.1190 - val_mae: 0.2832\n",
            "Epoch 331/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1114 - mae: 0.2751 - val_loss: 0.1166 - val_mae: 0.2857\n",
            "Epoch 332/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1046 - mae: 0.2692 - val_loss: 0.1191 - val_mae: 0.2832\n",
            "Epoch 333/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.1068 - mae: 0.2664 - val_loss: 0.1166 - val_mae: 0.2844\n",
            "Epoch 334/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1086 - mae: 0.2720 - val_loss: 0.1234 - val_mae: 0.2999\n",
            "Epoch 335/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1085 - mae: 0.2753 - val_loss: 0.1284 - val_mae: 0.2854\n",
            "Epoch 336/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1050 - mae: 0.2636 - val_loss: 0.1166 - val_mae: 0.2852\n",
            "Epoch 337/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.1036 - mae: 0.2680 - val_loss: 0.1318 - val_mae: 0.2877\n",
            "Epoch 338/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1074 - mae: 0.2680 - val_loss: 0.1167 - val_mae: 0.2844\n",
            "Epoch 339/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1057 - mae: 0.2690 - val_loss: 0.1361 - val_mae: 0.2904\n",
            "Epoch 340/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.1069 - mae: 0.2718 - val_loss: 0.1172 - val_mae: 0.2840\n",
            "Epoch 341/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1080 - mae: 0.2721 - val_loss: 0.1168 - val_mae: 0.2842\n",
            "Epoch 342/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1046 - mae: 0.2670 - val_loss: 0.1202 - val_mae: 0.2832\n",
            "Epoch 343/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1040 - mae: 0.2687 - val_loss: 0.1175 - val_mae: 0.2891\n",
            "Epoch 344/600\n",
            "150/150 [==============================] - 0s 217us/sample - loss: 0.1065 - mae: 0.2699 - val_loss: 0.1189 - val_mae: 0.2832\n",
            "Epoch 345/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.1088 - mae: 0.2712 - val_loss: 0.1167 - val_mae: 0.2845\n",
            "Epoch 346/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1056 - mae: 0.2684 - val_loss: 0.1192 - val_mae: 0.2925\n",
            "Epoch 347/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1053 - mae: 0.2680 - val_loss: 0.1226 - val_mae: 0.2833\n",
            "Epoch 348/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1090 - mae: 0.2713 - val_loss: 0.1176 - val_mae: 0.2836\n",
            "Epoch 349/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.1071 - mae: 0.2749 - val_loss: 0.1181 - val_mae: 0.2834\n",
            "Epoch 350/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1079 - mae: 0.2697 - val_loss: 0.1222 - val_mae: 0.2832\n",
            "Epoch 351/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1059 - mae: 0.2665 - val_loss: 0.1291 - val_mae: 0.2858\n",
            "Epoch 352/600\n",
            "150/150 [==============================] - 0s 206us/sample - loss: 0.1055 - mae: 0.2646 - val_loss: 0.1168 - val_mae: 0.2843\n",
            "Epoch 353/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1083 - mae: 0.2756 - val_loss: 0.1175 - val_mae: 0.2837\n",
            "Epoch 354/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.1056 - mae: 0.2646 - val_loss: 0.1232 - val_mae: 0.2996\n",
            "Epoch 355/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1073 - mae: 0.2781 - val_loss: 0.1190 - val_mae: 0.2832\n",
            "Epoch 356/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1048 - mae: 0.2657 - val_loss: 0.1179 - val_mae: 0.2835\n",
            "Epoch 357/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1063 - mae: 0.2671 - val_loss: 0.1167 - val_mae: 0.2843\n",
            "Epoch 358/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1077 - mae: 0.2716 - val_loss: 0.1167 - val_mae: 0.2863\n",
            "Epoch 359/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.1014 - mae: 0.2617 - val_loss: 0.1397 - val_mae: 0.3231\n",
            "Epoch 360/600\n",
            "150/150 [==============================] - 0s 283us/sample - loss: 0.1110 - mae: 0.2745 - val_loss: 0.1285 - val_mae: 0.2855\n",
            "Epoch 361/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.1058 - mae: 0.2622 - val_loss: 0.1166 - val_mae: 0.2863\n",
            "Epoch 362/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1058 - mae: 0.2676 - val_loss: 0.1320 - val_mae: 0.2879\n",
            "Epoch 363/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1072 - mae: 0.2680 - val_loss: 0.1241 - val_mae: 0.3011\n",
            "Epoch 364/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.1070 - mae: 0.2727 - val_loss: 0.1216 - val_mae: 0.2968\n",
            "Epoch 365/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.1093 - mae: 0.2720 - val_loss: 0.1170 - val_mae: 0.2840\n",
            "Epoch 366/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.1057 - mae: 0.2704 - val_loss: 0.1166 - val_mae: 0.2843\n",
            "Epoch 367/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1079 - mae: 0.2670 - val_loss: 0.1209 - val_mae: 0.2832\n",
            "Epoch 368/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1053 - mae: 0.2676 - val_loss: 0.1312 - val_mae: 0.3120\n",
            "Epoch 369/600\n",
            "150/150 [==============================] - 0s 220us/sample - loss: 0.1062 - mae: 0.2743 - val_loss: 0.1249 - val_mae: 0.2838\n",
            "Epoch 370/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.1077 - mae: 0.2655 - val_loss: 0.1166 - val_mae: 0.2865\n",
            "Epoch 371/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1117 - mae: 0.2745 - val_loss: 0.1219 - val_mae: 0.2832\n",
            "Epoch 372/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1026 - mae: 0.2611 - val_loss: 0.1264 - val_mae: 0.3046\n",
            "Epoch 373/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.1091 - mae: 0.2700 - val_loss: 0.1184 - val_mae: 0.2913\n",
            "Epoch 374/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.1059 - mae: 0.2669 - val_loss: 0.1242 - val_mae: 0.2837\n",
            "Epoch 375/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.1048 - mae: 0.2597 - val_loss: 0.1244 - val_mae: 0.3015\n",
            "Epoch 376/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.1030 - mae: 0.2680 - val_loss: 0.1302 - val_mae: 0.2866\n",
            "Epoch 377/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.1049 - mae: 0.2632 - val_loss: 0.1379 - val_mae: 0.3209\n",
            "Epoch 378/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.1074 - mae: 0.2696 - val_loss: 0.1282 - val_mae: 0.3074\n",
            "Epoch 379/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1065 - mae: 0.2699 - val_loss: 0.1219 - val_mae: 0.2832\n",
            "Epoch 380/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1059 - mae: 0.2649 - val_loss: 0.1240 - val_mae: 0.3008\n",
            "Epoch 381/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1056 - mae: 0.2714 - val_loss: 0.1170 - val_mae: 0.2879\n",
            "Epoch 382/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1082 - mae: 0.2720 - val_loss: 0.1281 - val_mae: 0.3073\n",
            "Epoch 383/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1054 - mae: 0.2671 - val_loss: 0.1183 - val_mae: 0.2833\n",
            "Epoch 384/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1057 - mae: 0.2670 - val_loss: 0.1344 - val_mae: 0.2894\n",
            "Epoch 385/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1040 - mae: 0.2594 - val_loss: 0.1510 - val_mae: 0.3376\n",
            "Epoch 386/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.1082 - mae: 0.2755 - val_loss: 0.1275 - val_mae: 0.2849\n",
            "Epoch 387/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.1093 - mae: 0.2726 - val_loss: 0.1168 - val_mae: 0.2873\n",
            "Epoch 388/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1050 - mae: 0.2662 - val_loss: 0.1207 - val_mae: 0.2953\n",
            "Epoch 389/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.1062 - mae: 0.2719 - val_loss: 0.1199 - val_mae: 0.2832\n",
            "Epoch 390/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1063 - mae: 0.2624 - val_loss: 0.1189 - val_mae: 0.2921\n",
            "Epoch 391/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.1038 - mae: 0.2652 - val_loss: 0.1254 - val_mae: 0.3029\n",
            "Epoch 392/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1113 - mae: 0.2784 - val_loss: 0.1222 - val_mae: 0.2832\n",
            "Epoch 393/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.1069 - mae: 0.2674 - val_loss: 0.1245 - val_mae: 0.2836\n",
            "Epoch 394/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1078 - mae: 0.2683 - val_loss: 0.1302 - val_mae: 0.2867\n",
            "Epoch 395/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.1097 - mae: 0.2669 - val_loss: 0.1194 - val_mae: 0.2930\n",
            "Epoch 396/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.1130 - mae: 0.2798 - val_loss: 0.1179 - val_mae: 0.2902\n",
            "Epoch 397/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1043 - mae: 0.2693 - val_loss: 0.1165 - val_mae: 0.2846\n",
            "Epoch 398/600\n",
            "150/150 [==============================] - 0s 231us/sample - loss: 0.1048 - mae: 0.2674 - val_loss: 0.1282 - val_mae: 0.2853\n",
            "Epoch 399/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1076 - mae: 0.2662 - val_loss: 0.1274 - val_mae: 0.3061\n",
            "Epoch 400/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.1065 - mae: 0.2723 - val_loss: 0.1173 - val_mae: 0.2888\n",
            "Epoch 401/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1060 - mae: 0.2715 - val_loss: 0.1177 - val_mae: 0.2898\n",
            "Epoch 402/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1053 - mae: 0.2714 - val_loss: 0.1272 - val_mae: 0.2847\n",
            "Epoch 403/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.1072 - mae: 0.2698 - val_loss: 0.1177 - val_mae: 0.2898\n",
            "Epoch 404/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.1044 - mae: 0.2660 - val_loss: 0.1183 - val_mae: 0.2832\n",
            "Epoch 405/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.1031 - mae: 0.2668 - val_loss: 0.1402 - val_mae: 0.2925\n",
            "Epoch 406/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.1071 - mae: 0.2699 - val_loss: 0.1244 - val_mae: 0.3014\n",
            "Epoch 407/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.1064 - mae: 0.2724 - val_loss: 0.1372 - val_mae: 0.2909\n",
            "Epoch 408/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.1090 - mae: 0.2678 - val_loss: 0.1251 - val_mae: 0.3025\n",
            "Epoch 409/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1084 - mae: 0.2758 - val_loss: 0.1193 - val_mae: 0.2927\n",
            "Epoch 410/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.1051 - mae: 0.2692 - val_loss: 0.1176 - val_mae: 0.2899\n",
            "Epoch 411/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.1079 - mae: 0.2729 - val_loss: 0.1228 - val_mae: 0.2833\n",
            "Epoch 412/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.1033 - mae: 0.2633 - val_loss: 0.1178 - val_mae: 0.2903\n",
            "Epoch 413/600\n",
            "150/150 [==============================] - 0s 235us/sample - loss: 0.1047 - mae: 0.2651 - val_loss: 0.1203 - val_mae: 0.2832\n",
            "Epoch 414/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.1084 - mae: 0.2717 - val_loss: 0.1164 - val_mae: 0.2836\n",
            "Epoch 415/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1060 - mae: 0.2677 - val_loss: 0.1163 - val_mae: 0.2840\n",
            "Epoch 416/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1073 - mae: 0.2681 - val_loss: 0.1160 - val_mae: 0.2841\n",
            "Epoch 417/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.1047 - mae: 0.2658 - val_loss: 0.1174 - val_mae: 0.2829\n",
            "Epoch 418/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.1064 - mae: 0.2722 - val_loss: 0.1185 - val_mae: 0.2918\n",
            "Epoch 419/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1056 - mae: 0.2667 - val_loss: 0.1187 - val_mae: 0.2825\n",
            "Epoch 420/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1072 - mae: 0.2672 - val_loss: 0.1160 - val_mae: 0.2834\n",
            "Epoch 421/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.1058 - mae: 0.2679 - val_loss: 0.1289 - val_mae: 0.2859\n",
            "Epoch 422/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1039 - mae: 0.2591 - val_loss: 0.1157 - val_mae: 0.2847\n",
            "Epoch 423/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.1087 - mae: 0.2714 - val_loss: 0.1158 - val_mae: 0.2832\n",
            "Epoch 424/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.1056 - mae: 0.2647 - val_loss: 0.1161 - val_mae: 0.2864\n",
            "Epoch 425/600\n",
            "150/150 [==============================] - 0s 229us/sample - loss: 0.1065 - mae: 0.2666 - val_loss: 0.1178 - val_mae: 0.2823\n",
            "Epoch 426/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1073 - mae: 0.2698 - val_loss: 0.1186 - val_mae: 0.2918\n",
            "Epoch 427/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.1016 - mae: 0.2642 - val_loss: 0.1217 - val_mae: 0.2820\n",
            "Epoch 428/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0998 - mae: 0.2578 - val_loss: 0.1239 - val_mae: 0.3008\n",
            "Epoch 429/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1088 - mae: 0.2727 - val_loss: 0.1162 - val_mae: 0.2823\n",
            "Epoch 430/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.1042 - mae: 0.2655 - val_loss: 0.1205 - val_mae: 0.2954\n",
            "Epoch 431/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.1074 - mae: 0.2734 - val_loss: 0.1174 - val_mae: 0.2817\n",
            "Epoch 432/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.1069 - mae: 0.2685 - val_loss: 0.1156 - val_mae: 0.2830\n",
            "Epoch 433/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1051 - mae: 0.2665 - val_loss: 0.1218 - val_mae: 0.2977\n",
            "Epoch 434/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1069 - mae: 0.2727 - val_loss: 0.1153 - val_mae: 0.2840\n",
            "Epoch 435/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.1025 - mae: 0.2677 - val_loss: 0.1165 - val_mae: 0.2814\n",
            "Epoch 436/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.1071 - mae: 0.2720 - val_loss: 0.1155 - val_mae: 0.2818\n",
            "Epoch 437/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1047 - mae: 0.2675 - val_loss: 0.1171 - val_mae: 0.2812\n",
            "Epoch 438/600\n",
            "150/150 [==============================] - 0s 243us/sample - loss: 0.1018 - mae: 0.2627 - val_loss: 0.1190 - val_mae: 0.2926\n",
            "Epoch 439/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.1051 - mae: 0.2668 - val_loss: 0.1197 - val_mae: 0.2940\n",
            "Epoch 440/600\n",
            "150/150 [==============================] - 0s 206us/sample - loss: 0.1052 - mae: 0.2697 - val_loss: 0.1189 - val_mae: 0.2921\n",
            "Epoch 441/600\n",
            "150/150 [==============================] - 0s 256us/sample - loss: 0.1002 - mae: 0.2640 - val_loss: 0.1225 - val_mae: 0.2826\n",
            "Epoch 442/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.1058 - mae: 0.2694 - val_loss: 0.1176 - val_mae: 0.2904\n",
            "Epoch 443/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1098 - mae: 0.2734 - val_loss: 0.1231 - val_mae: 0.3000\n",
            "Epoch 444/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.1034 - mae: 0.2708 - val_loss: 0.1149 - val_mae: 0.2847\n",
            "Epoch 445/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.1019 - mae: 0.2677 - val_loss: 0.1157 - val_mae: 0.2802\n",
            "Epoch 446/600\n",
            "150/150 [==============================] - 0s 230us/sample - loss: 0.1055 - mae: 0.2688 - val_loss: 0.1144 - val_mae: 0.2830\n",
            "Epoch 447/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.1014 - mae: 0.2629 - val_loss: 0.1163 - val_mae: 0.2883\n",
            "Epoch 448/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.1026 - mae: 0.2640 - val_loss: 0.1155 - val_mae: 0.2803\n",
            "Epoch 449/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.1053 - mae: 0.2641 - val_loss: 0.1253 - val_mae: 0.2811\n",
            "Epoch 450/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1036 - mae: 0.2659 - val_loss: 0.1162 - val_mae: 0.2882\n",
            "Epoch 451/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.1002 - mae: 0.2618 - val_loss: 0.1501 - val_mae: 0.3387\n",
            "Epoch 452/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.1080 - mae: 0.2765 - val_loss: 0.1142 - val_mae: 0.2795\n",
            "Epoch 453/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.1048 - mae: 0.2663 - val_loss: 0.1160 - val_mae: 0.2849\n",
            "Epoch 454/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.1007 - mae: 0.2648 - val_loss: 0.1162 - val_mae: 0.2882\n",
            "Epoch 455/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1016 - mae: 0.2639 - val_loss: 0.1186 - val_mae: 0.2927\n",
            "Epoch 456/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.1038 - mae: 0.2661 - val_loss: 0.1146 - val_mae: 0.2852\n",
            "Epoch 457/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.1019 - mae: 0.2652 - val_loss: 0.1199 - val_mae: 0.2950\n",
            "Epoch 458/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.1040 - mae: 0.2672 - val_loss: 0.1165 - val_mae: 0.2882\n",
            "Epoch 459/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0990 - mae: 0.2580 - val_loss: 0.1291 - val_mae: 0.3099\n",
            "Epoch 460/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.1043 - mae: 0.2675 - val_loss: 0.1131 - val_mae: 0.2814\n",
            "Epoch 461/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.1006 - mae: 0.2591 - val_loss: 0.1242 - val_mae: 0.2801\n",
            "Epoch 462/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.1031 - mae: 0.2655 - val_loss: 0.1131 - val_mae: 0.2803\n",
            "Epoch 463/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.1022 - mae: 0.2665 - val_loss: 0.1190 - val_mae: 0.2764\n",
            "Epoch 464/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0998 - mae: 0.2583 - val_loss: 0.1224 - val_mae: 0.2994\n",
            "Epoch 465/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.1017 - mae: 0.2637 - val_loss: 0.1481 - val_mae: 0.3371\n",
            "Epoch 466/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.1087 - mae: 0.2737 - val_loss: 0.1125 - val_mae: 0.2775\n",
            "Epoch 467/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0983 - mae: 0.2559 - val_loss: 0.1120 - val_mae: 0.2773\n",
            "Epoch 468/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0993 - mae: 0.2612 - val_loss: 0.1165 - val_mae: 0.2765\n",
            "Epoch 469/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1029 - mae: 0.2630 - val_loss: 0.1123 - val_mae: 0.2787\n",
            "Epoch 470/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.1018 - mae: 0.2670 - val_loss: 0.1120 - val_mae: 0.2792\n",
            "Epoch 471/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.1000 - mae: 0.2588 - val_loss: 0.1150 - val_mae: 0.2757\n",
            "Epoch 472/600\n",
            "150/150 [==============================] - 0s 258us/sample - loss: 0.0979 - mae: 0.2556 - val_loss: 0.1413 - val_mae: 0.3298\n",
            "Epoch 473/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0995 - mae: 0.2630 - val_loss: 0.1290 - val_mae: 0.2822\n",
            "Epoch 474/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.1071 - mae: 0.2673 - val_loss: 0.1184 - val_mae: 0.2937\n",
            "Epoch 475/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0986 - mae: 0.2621 - val_loss: 0.1109 - val_mae: 0.2778\n",
            "Epoch 476/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0996 - mae: 0.2589 - val_loss: 0.1275 - val_mae: 0.3101\n",
            "Epoch 477/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0994 - mae: 0.2616 - val_loss: 0.1124 - val_mae: 0.2761\n",
            "Epoch 478/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.1012 - mae: 0.2607 - val_loss: 0.1121 - val_mae: 0.2817\n",
            "Epoch 479/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.1021 - mae: 0.2637 - val_loss: 0.1101 - val_mae: 0.2761\n",
            "Epoch 480/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0990 - mae: 0.2626 - val_loss: 0.1130 - val_mae: 0.2723\n",
            "Epoch 481/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0960 - mae: 0.2545 - val_loss: 0.1099 - val_mae: 0.2755\n",
            "Epoch 482/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.1025 - mae: 0.2602 - val_loss: 0.1097 - val_mae: 0.2757\n",
            "Epoch 483/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0962 - mae: 0.2574 - val_loss: 0.1152 - val_mae: 0.2740\n",
            "Epoch 484/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0945 - mae: 0.2522 - val_loss: 0.1104 - val_mae: 0.2732\n",
            "Epoch 485/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1020 - mae: 0.2654 - val_loss: 0.1093 - val_mae: 0.2751\n",
            "Epoch 486/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0999 - mae: 0.2584 - val_loss: 0.1195 - val_mae: 0.2966\n",
            "Epoch 487/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.1001 - mae: 0.2657 - val_loss: 0.1114 - val_mae: 0.2715\n",
            "Epoch 488/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0947 - mae: 0.2526 - val_loss: 0.1135 - val_mae: 0.2859\n",
            "Epoch 489/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0955 - mae: 0.2558 - val_loss: 0.1141 - val_mae: 0.2868\n",
            "Epoch 490/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0986 - mae: 0.2581 - val_loss: 0.1094 - val_mae: 0.2777\n",
            "Epoch 491/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0965 - mae: 0.2585 - val_loss: 0.1084 - val_mae: 0.2717\n",
            "Epoch 492/600\n",
            "150/150 [==============================] - 0s 261us/sample - loss: 0.0941 - mae: 0.2544 - val_loss: 0.1219 - val_mae: 0.2748\n",
            "Epoch 493/600\n",
            "150/150 [==============================] - 0s 219us/sample - loss: 0.0924 - mae: 0.2473 - val_loss: 0.1245 - val_mae: 0.2762\n",
            "Epoch 494/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0991 - mae: 0.2554 - val_loss: 0.1078 - val_mae: 0.2669\n",
            "Epoch 495/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0949 - mae: 0.2514 - val_loss: 0.1032 - val_mae: 0.2614\n",
            "Epoch 496/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0871 - mae: 0.2408 - val_loss: 0.1026 - val_mae: 0.2530\n",
            "Epoch 497/600\n",
            "150/150 [==============================] - 0s 227us/sample - loss: 0.0849 - mae: 0.2377 - val_loss: 0.0998 - val_mae: 0.2519\n",
            "Epoch 498/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0837 - mae: 0.2375 - val_loss: 0.1016 - val_mae: 0.2502\n",
            "Epoch 499/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0876 - mae: 0.2409 - val_loss: 0.1091 - val_mae: 0.2864\n",
            "Epoch 500/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0841 - mae: 0.2405 - val_loss: 0.0979 - val_mae: 0.2492\n",
            "Epoch 501/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0849 - mae: 0.2400 - val_loss: 0.0986 - val_mae: 0.2479\n",
            "Epoch 502/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0828 - mae: 0.2358 - val_loss: 0.0968 - val_mae: 0.2469\n",
            "Epoch 503/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0820 - mae: 0.2341 - val_loss: 0.1075 - val_mae: 0.2870\n",
            "Epoch 504/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0824 - mae: 0.2363 - val_loss: 0.1024 - val_mae: 0.2764\n",
            "Epoch 505/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0779 - mae: 0.2347 - val_loss: 0.0936 - val_mae: 0.2482\n",
            "Epoch 506/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0804 - mae: 0.2349 - val_loss: 0.0984 - val_mae: 0.2452\n",
            "Epoch 507/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0822 - mae: 0.2306 - val_loss: 0.0925 - val_mae: 0.2451\n",
            "Epoch 508/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0775 - mae: 0.2286 - val_loss: 0.0916 - val_mae: 0.2447\n",
            "Epoch 509/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0782 - mae: 0.2293 - val_loss: 0.0932 - val_mae: 0.2419\n",
            "Epoch 510/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0780 - mae: 0.2279 - val_loss: 0.0945 - val_mae: 0.2377\n",
            "Epoch 511/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0757 - mae: 0.2285 - val_loss: 0.1289 - val_mae: 0.2607\n",
            "Epoch 512/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0850 - mae: 0.2302 - val_loss: 0.0914 - val_mae: 0.2517\n",
            "Epoch 513/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0774 - mae: 0.2280 - val_loss: 0.0885 - val_mae: 0.2373\n",
            "Epoch 514/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0756 - mae: 0.2225 - val_loss: 0.0931 - val_mae: 0.2617\n",
            "Epoch 515/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0764 - mae: 0.2257 - val_loss: 0.0883 - val_mae: 0.2345\n",
            "Epoch 516/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0746 - mae: 0.2225 - val_loss: 0.0880 - val_mae: 0.2446\n",
            "Epoch 517/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0743 - mae: 0.2205 - val_loss: 0.1015 - val_mae: 0.2392\n",
            "Epoch 518/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0772 - mae: 0.2253 - val_loss: 0.0854 - val_mae: 0.2417\n",
            "Epoch 519/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0738 - mae: 0.2220 - val_loss: 0.0839 - val_mae: 0.2336\n",
            "Epoch 520/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0713 - mae: 0.2177 - val_loss: 0.0832 - val_mae: 0.2345\n",
            "Epoch 521/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0700 - mae: 0.2154 - val_loss: 0.0962 - val_mae: 0.2719\n",
            "Epoch 522/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0704 - mae: 0.2175 - val_loss: 0.0959 - val_mae: 0.2713\n",
            "Epoch 523/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0711 - mae: 0.2212 - val_loss: 0.0983 - val_mae: 0.2354\n",
            "Epoch 524/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0693 - mae: 0.2116 - val_loss: 0.1051 - val_mae: 0.2389\n",
            "Epoch 525/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0739 - mae: 0.2203 - val_loss: 0.0799 - val_mae: 0.2272\n",
            "Epoch 526/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0747 - mae: 0.2231 - val_loss: 0.0793 - val_mae: 0.2264\n",
            "Epoch 527/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0679 - mae: 0.2111 - val_loss: 0.0789 - val_mae: 0.2299\n",
            "Epoch 528/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0666 - mae: 0.2112 - val_loss: 0.0788 - val_mae: 0.2304\n",
            "Epoch 529/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0670 - mae: 0.2072 - val_loss: 0.0806 - val_mae: 0.2373\n",
            "Epoch 530/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0653 - mae: 0.2079 - val_loss: 0.0775 - val_mae: 0.2277\n",
            "Epoch 531/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0682 - mae: 0.2145 - val_loss: 0.0756 - val_mae: 0.2198\n",
            "Epoch 532/600\n",
            "150/150 [==============================] - 0s 227us/sample - loss: 0.0662 - mae: 0.2103 - val_loss: 0.0818 - val_mae: 0.2180\n",
            "Epoch 533/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0640 - mae: 0.2076 - val_loss: 0.0749 - val_mae: 0.2248\n",
            "Epoch 534/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0656 - mae: 0.2096 - val_loss: 0.0736 - val_mae: 0.2207\n",
            "Epoch 535/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0629 - mae: 0.2025 - val_loss: 0.0742 - val_mae: 0.2255\n",
            "Epoch 536/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0627 - mae: 0.2062 - val_loss: 0.0719 - val_mae: 0.2159\n",
            "Epoch 537/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0609 - mae: 0.2014 - val_loss: 0.0872 - val_mae: 0.2187\n",
            "Epoch 538/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0643 - mae: 0.2059 - val_loss: 0.0904 - val_mae: 0.2205\n",
            "Epoch 539/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0615 - mae: 0.1982 - val_loss: 0.0726 - val_mae: 0.2146\n",
            "Epoch 540/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0596 - mae: 0.1959 - val_loss: 0.0738 - val_mae: 0.2271\n",
            "Epoch 541/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0577 - mae: 0.1980 - val_loss: 0.0733 - val_mae: 0.2089\n",
            "Epoch 542/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0565 - mae: 0.1935 - val_loss: 0.0746 - val_mae: 0.2052\n",
            "Epoch 543/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0588 - mae: 0.1960 - val_loss: 0.0761 - val_mae: 0.2393\n",
            "Epoch 544/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0578 - mae: 0.1950 - val_loss: 0.0720 - val_mae: 0.2302\n",
            "Epoch 545/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0571 - mae: 0.1924 - val_loss: 0.0665 - val_mae: 0.2120\n",
            "Epoch 546/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0537 - mae: 0.1899 - val_loss: 0.0713 - val_mae: 0.2238\n",
            "Epoch 547/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0576 - mae: 0.1923 - val_loss: 0.0742 - val_mae: 0.2329\n",
            "Epoch 548/600\n",
            "150/150 [==============================] - 0s 237us/sample - loss: 0.0562 - mae: 0.1929 - val_loss: 0.0695 - val_mae: 0.2224\n",
            "Epoch 549/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0545 - mae: 0.1893 - val_loss: 0.0641 - val_mae: 0.2126\n",
            "Epoch 550/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0534 - mae: 0.1886 - val_loss: 0.0620 - val_mae: 0.2005\n",
            "Epoch 551/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0545 - mae: 0.1859 - val_loss: 0.0639 - val_mae: 0.1944\n",
            "Epoch 552/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0516 - mae: 0.1817 - val_loss: 0.0632 - val_mae: 0.2087\n",
            "Epoch 553/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0538 - mae: 0.1880 - val_loss: 0.0624 - val_mae: 0.2089\n",
            "Epoch 554/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0527 - mae: 0.1817 - val_loss: 0.0593 - val_mae: 0.1993\n",
            "Epoch 555/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0544 - mae: 0.1863 - val_loss: 0.0596 - val_mae: 0.2048\n",
            "Epoch 556/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0485 - mae: 0.1778 - val_loss: 0.0614 - val_mae: 0.1884\n",
            "Epoch 557/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0507 - mae: 0.1800 - val_loss: 0.0628 - val_mae: 0.1863\n",
            "Epoch 558/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0493 - mae: 0.1745 - val_loss: 0.0629 - val_mae: 0.1852\n",
            "Epoch 559/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0499 - mae: 0.1786 - val_loss: 0.0580 - val_mae: 0.1861\n",
            "Epoch 560/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0479 - mae: 0.1739 - val_loss: 0.0555 - val_mae: 0.1886\n",
            "Epoch 561/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0487 - mae: 0.1757 - val_loss: 0.0632 - val_mae: 0.2211\n",
            "Epoch 562/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0478 - mae: 0.1779 - val_loss: 0.0585 - val_mae: 0.2096\n",
            "Epoch 563/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0488 - mae: 0.1748 - val_loss: 0.0539 - val_mae: 0.1925\n",
            "Epoch 564/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0443 - mae: 0.1675 - val_loss: 0.0554 - val_mae: 0.1960\n",
            "Epoch 565/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0471 - mae: 0.1739 - val_loss: 0.0535 - val_mae: 0.1937\n",
            "Epoch 566/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0425 - mae: 0.1664 - val_loss: 0.0755 - val_mae: 0.1907\n",
            "Epoch 567/600\n",
            "150/150 [==============================] - 0s 233us/sample - loss: 0.0460 - mae: 0.1644 - val_loss: 0.0516 - val_mae: 0.1892\n",
            "Epoch 568/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0437 - mae: 0.1653 - val_loss: 0.0576 - val_mae: 0.1744\n",
            "Epoch 569/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0420 - mae: 0.1599 - val_loss: 0.0624 - val_mae: 0.2189\n",
            "Epoch 570/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0408 - mae: 0.1609 - val_loss: 0.0616 - val_mae: 0.2171\n",
            "Epoch 571/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0412 - mae: 0.1635 - val_loss: 0.0749 - val_mae: 0.2360\n",
            "Epoch 572/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0410 - mae: 0.1627 - val_loss: 0.0552 - val_mae: 0.1698\n",
            "Epoch 573/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0403 - mae: 0.1561 - val_loss: 0.0558 - val_mae: 0.1698\n",
            "Epoch 574/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0423 - mae: 0.1597 - val_loss: 0.0593 - val_mae: 0.1712\n",
            "Epoch 575/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0402 - mae: 0.1555 - val_loss: 0.0464 - val_mae: 0.1701\n",
            "Epoch 576/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0367 - mae: 0.1495 - val_loss: 0.0458 - val_mae: 0.1705\n",
            "Epoch 577/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0375 - mae: 0.1498 - val_loss: 0.0633 - val_mae: 0.1759\n",
            "Epoch 578/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0402 - mae: 0.1536 - val_loss: 0.0446 - val_mae: 0.1677\n",
            "Epoch 579/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0381 - mae: 0.1530 - val_loss: 0.0466 - val_mae: 0.1623\n",
            "Epoch 580/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0363 - mae: 0.1489 - val_loss: 0.0568 - val_mae: 0.1682\n",
            "Epoch 581/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0382 - mae: 0.1523 - val_loss: 0.0508 - val_mae: 0.1952\n",
            "Epoch 582/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0350 - mae: 0.1459 - val_loss: 0.0420 - val_mae: 0.1677\n",
            "Epoch 583/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0364 - mae: 0.1511 - val_loss: 0.0444 - val_mae: 0.1571\n",
            "Epoch 584/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0330 - mae: 0.1426 - val_loss: 0.0423 - val_mae: 0.1729\n",
            "Epoch 585/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0341 - mae: 0.1489 - val_loss: 0.0425 - val_mae: 0.1729\n",
            "Epoch 586/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0340 - mae: 0.1460 - val_loss: 0.0434 - val_mae: 0.1785\n",
            "Epoch 587/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0344 - mae: 0.1402 - val_loss: 0.0416 - val_mae: 0.1645\n",
            "Epoch 588/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0347 - mae: 0.1431 - val_loss: 0.0387 - val_mae: 0.1579\n",
            "Epoch 589/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0346 - mae: 0.1435 - val_loss: 0.0393 - val_mae: 0.1528\n",
            "Epoch 590/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0323 - mae: 0.1379 - val_loss: 0.0431 - val_mae: 0.1585\n",
            "Epoch 591/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0284 - mae: 0.1302 - val_loss: 0.0428 - val_mae: 0.1526\n",
            "Epoch 592/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0334 - mae: 0.1383 - val_loss: 0.0428 - val_mae: 0.1757\n",
            "Epoch 593/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0304 - mae: 0.1358 - val_loss: 0.0384 - val_mae: 0.1561\n",
            "Epoch 594/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0304 - mae: 0.1367 - val_loss: 0.0366 - val_mae: 0.1605\n",
            "Epoch 595/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0302 - mae: 0.1351 - val_loss: 0.0369 - val_mae: 0.1458\n",
            "Epoch 596/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0320 - mae: 0.1353 - val_loss: 0.0407 - val_mae: 0.1484\n",
            "Epoch 597/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0291 - mae: 0.1278 - val_loss: 0.0343 - val_mae: 0.1492\n",
            "Epoch 598/600\n",
            "150/150 [==============================] - 0s 255us/sample - loss: 0.0278 - mae: 0.1304 - val_loss: 0.0354 - val_mae: 0.1586\n",
            "Epoch 599/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0293 - mae: 0.1299 - val_loss: 0.0394 - val_mae: 0.1704\n",
            "Epoch 600/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0280 - mae: 0.1305 - val_loss: 0.0338 - val_mae: 0.1416\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kM-SPHofJ06I",
        "outputId": "0cbc2782-34c4-4606-c883-080d91558b8b"
      },
      "source": [
        "#Toy Problem Y=sin(x) for 250 samples period of -pi to 0\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 250\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=-(math.pi), high=0,size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "#plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_2.summary()\n",
        "history_2 = model_2.fit(x_train, y_train, epochs=600, batch_size=16, validation_data=(x_validate, y_validate))\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_2.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_54 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 150 samples, validate on 50 samples\n",
            "Epoch 1/600\n",
            "150/150 [==============================] - 0s 1ms/sample - loss: 0.2004 - mae: 0.3908 - val_loss: 0.1661 - val_mae: 0.3400\n",
            "Epoch 2/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1884 - mae: 0.3711 - val_loss: 0.1522 - val_mae: 0.3284\n",
            "Epoch 3/600\n",
            "150/150 [==============================] - 0s 113us/sample - loss: 0.1717 - mae: 0.3507 - val_loss: 0.1512 - val_mae: 0.3465\n",
            "Epoch 4/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.1658 - mae: 0.3518 - val_loss: 0.1324 - val_mae: 0.3147\n",
            "Epoch 5/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.1546 - mae: 0.3373 - val_loss: 0.1244 - val_mae: 0.2997\n",
            "Epoch 6/600\n",
            "150/150 [==============================] - 0s 113us/sample - loss: 0.1433 - mae: 0.3213 - val_loss: 0.1285 - val_mae: 0.3160\n",
            "Epoch 7/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1368 - mae: 0.3189 - val_loss: 0.1088 - val_mae: 0.2826\n",
            "Epoch 8/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.1297 - mae: 0.3061 - val_loss: 0.1041 - val_mae: 0.2796\n",
            "Epoch 9/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.1232 - mae: 0.3025 - val_loss: 0.1000 - val_mae: 0.2576\n",
            "Epoch 10/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.1161 - mae: 0.2863 - val_loss: 0.0913 - val_mae: 0.2589\n",
            "Epoch 11/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.1084 - mae: 0.2757 - val_loss: 0.0898 - val_mae: 0.2622\n",
            "Epoch 12/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.1028 - mae: 0.2755 - val_loss: 0.0811 - val_mae: 0.2368\n",
            "Epoch 13/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0969 - mae: 0.2611 - val_loss: 0.0801 - val_mae: 0.2473\n",
            "Epoch 14/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0913 - mae: 0.2561 - val_loss: 0.0771 - val_mae: 0.2428\n",
            "Epoch 15/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0861 - mae: 0.2476 - val_loss: 0.0672 - val_mae: 0.2252\n",
            "Epoch 16/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0819 - mae: 0.2403 - val_loss: 0.0625 - val_mae: 0.2168\n",
            "Epoch 17/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0775 - mae: 0.2346 - val_loss: 0.0586 - val_mae: 0.2087\n",
            "Epoch 18/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.0728 - mae: 0.2259 - val_loss: 0.0551 - val_mae: 0.2019\n",
            "Epoch 19/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0687 - mae: 0.2234 - val_loss: 0.0555 - val_mae: 0.1913\n",
            "Epoch 20/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0653 - mae: 0.2139 - val_loss: 0.0511 - val_mae: 0.1973\n",
            "Epoch 21/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0626 - mae: 0.2105 - val_loss: 0.0469 - val_mae: 0.1829\n",
            "Epoch 22/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0579 - mae: 0.2001 - val_loss: 0.0436 - val_mae: 0.1819\n",
            "Epoch 23/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0548 - mae: 0.1969 - val_loss: 0.0424 - val_mae: 0.1793\n",
            "Epoch 24/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0530 - mae: 0.1940 - val_loss: 0.0370 - val_mae: 0.1659\n",
            "Epoch 25/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0478 - mae: 0.1823 - val_loss: 0.0394 - val_mae: 0.1725\n",
            "Epoch 26/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0453 - mae: 0.1753 - val_loss: 0.0418 - val_mae: 0.1744\n",
            "Epoch 27/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0441 - mae: 0.1741 - val_loss: 0.0339 - val_mae: 0.1490\n",
            "Epoch 28/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0419 - mae: 0.1694 - val_loss: 0.0287 - val_mae: 0.1444\n",
            "Epoch 29/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0383 - mae: 0.1589 - val_loss: 0.0309 - val_mae: 0.1520\n",
            "Epoch 30/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0368 - mae: 0.1571 - val_loss: 0.0285 - val_mae: 0.1452\n",
            "Epoch 31/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0361 - mae: 0.1552 - val_loss: 0.0351 - val_mae: 0.1561\n",
            "Epoch 32/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0347 - mae: 0.1537 - val_loss: 0.0228 - val_mae: 0.1284\n",
            "Epoch 33/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0326 - mae: 0.1472 - val_loss: 0.0215 - val_mae: 0.1252\n",
            "Epoch 34/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0305 - mae: 0.1420 - val_loss: 0.0204 - val_mae: 0.1199\n",
            "Epoch 35/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.0292 - mae: 0.1376 - val_loss: 0.0281 - val_mae: 0.1384\n",
            "Epoch 36/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0297 - mae: 0.1397 - val_loss: 0.0183 - val_mae: 0.1129\n",
            "Epoch 37/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0282 - mae: 0.1367 - val_loss: 0.0182 - val_mae: 0.1107\n",
            "Epoch 38/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0272 - mae: 0.1335 - val_loss: 0.0187 - val_mae: 0.1129\n",
            "Epoch 39/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0250 - mae: 0.1280 - val_loss: 0.0175 - val_mae: 0.1089\n",
            "Epoch 40/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0256 - mae: 0.1275 - val_loss: 0.0156 - val_mae: 0.1037\n",
            "Epoch 41/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0246 - mae: 0.1261 - val_loss: 0.0177 - val_mae: 0.1075\n",
            "Epoch 42/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0235 - mae: 0.1226 - val_loss: 0.0148 - val_mae: 0.0987\n",
            "Epoch 43/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0234 - mae: 0.1233 - val_loss: 0.0138 - val_mae: 0.0969\n",
            "Epoch 44/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0212 - mae: 0.1174 - val_loss: 0.0155 - val_mae: 0.0995\n",
            "Epoch 45/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0207 - mae: 0.1137 - val_loss: 0.0132 - val_mae: 0.0924\n",
            "Epoch 46/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0207 - mae: 0.1137 - val_loss: 0.0141 - val_mae: 0.0953\n",
            "Epoch 47/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0214 - mae: 0.1169 - val_loss: 0.0134 - val_mae: 0.0929\n",
            "Epoch 48/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0191 - mae: 0.1121 - val_loss: 0.0117 - val_mae: 0.0860\n",
            "Epoch 49/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0193 - mae: 0.1141 - val_loss: 0.0144 - val_mae: 0.0968\n",
            "Epoch 50/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0189 - mae: 0.1094 - val_loss: 0.0113 - val_mae: 0.0834\n",
            "Epoch 51/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0186 - mae: 0.1099 - val_loss: 0.0107 - val_mae: 0.0807\n",
            "Epoch 52/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0171 - mae: 0.1061 - val_loss: 0.0105 - val_mae: 0.0795\n",
            "Epoch 53/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0168 - mae: 0.1048 - val_loss: 0.0112 - val_mae: 0.0846\n",
            "Epoch 54/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0170 - mae: 0.1053 - val_loss: 0.0103 - val_mae: 0.0787\n",
            "Epoch 55/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0175 - mae: 0.1060 - val_loss: 0.0121 - val_mae: 0.0886\n",
            "Epoch 56/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0163 - mae: 0.1037 - val_loss: 0.0101 - val_mae: 0.0789\n",
            "Epoch 57/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0155 - mae: 0.1002 - val_loss: 0.0103 - val_mae: 0.0807\n",
            "Epoch 58/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0155 - mae: 0.1007 - val_loss: 0.0104 - val_mae: 0.0811\n",
            "Epoch 59/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0167 - mae: 0.1049 - val_loss: 0.0126 - val_mae: 0.0912\n",
            "Epoch 60/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0154 - mae: 0.1001 - val_loss: 0.0116 - val_mae: 0.0869\n",
            "Epoch 61/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0159 - mae: 0.1009 - val_loss: 0.0094 - val_mae: 0.0758\n",
            "Epoch 62/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0141 - mae: 0.0969 - val_loss: 0.0092 - val_mae: 0.0754\n",
            "Epoch 63/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0141 - mae: 0.0952 - val_loss: 0.0099 - val_mae: 0.0791\n",
            "Epoch 64/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0141 - mae: 0.0967 - val_loss: 0.0089 - val_mae: 0.0752\n",
            "Epoch 65/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0138 - mae: 0.0950 - val_loss: 0.0144 - val_mae: 0.0986\n",
            "Epoch 66/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0150 - mae: 0.0977 - val_loss: 0.0097 - val_mae: 0.0791\n",
            "Epoch 67/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0135 - mae: 0.0929 - val_loss: 0.0187 - val_mae: 0.1119\n",
            "Epoch 68/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0137 - mae: 0.0943 - val_loss: 0.0095 - val_mae: 0.0789\n",
            "Epoch 69/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0132 - mae: 0.0931 - val_loss: 0.0087 - val_mae: 0.0760\n",
            "Epoch 70/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0131 - mae: 0.0894 - val_loss: 0.0095 - val_mae: 0.0776\n",
            "Epoch 71/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0134 - mae: 0.0922 - val_loss: 0.0163 - val_mae: 0.1034\n",
            "Epoch 72/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0131 - mae: 0.0908 - val_loss: 0.0133 - val_mae: 0.0924\n",
            "Epoch 73/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0127 - mae: 0.0903 - val_loss: 0.0088 - val_mae: 0.0761\n",
            "Epoch 74/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0124 - mae: 0.0909 - val_loss: 0.0084 - val_mae: 0.0753\n",
            "Epoch 75/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0127 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1231\n",
            "Epoch 76/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0135 - mae: 0.0926 - val_loss: 0.0090 - val_mae: 0.0781\n",
            "Epoch 77/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0128 - mae: 0.0901 - val_loss: 0.0103 - val_mae: 0.0816\n",
            "Epoch 78/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0119 - mae: 0.0874 - val_loss: 0.0082 - val_mae: 0.0754\n",
            "Epoch 79/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0117 - mae: 0.0873 - val_loss: 0.0185 - val_mae: 0.1114\n",
            "Epoch 80/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0146 - mae: 0.0952 - val_loss: 0.0126 - val_mae: 0.0895\n",
            "Epoch 81/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0123 - mae: 0.0876 - val_loss: 0.0088 - val_mae: 0.0769\n",
            "Epoch 82/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0119 - mae: 0.0856 - val_loss: 0.0119 - val_mae: 0.0878\n",
            "Epoch 83/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0128 - mae: 0.0893 - val_loss: 0.0088 - val_mae: 0.0776\n",
            "Epoch 84/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0125 - mae: 0.0875 - val_loss: 0.0098 - val_mae: 0.0805\n",
            "Epoch 85/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0126 - mae: 0.0916 - val_loss: 0.0102 - val_mae: 0.0828\n",
            "Epoch 86/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0121 - mae: 0.0863 - val_loss: 0.0107 - val_mae: 0.0841\n",
            "Epoch 87/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0120 - mae: 0.0864 - val_loss: 0.0123 - val_mae: 0.0911\n",
            "Epoch 88/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.0130 - mae: 0.0882 - val_loss: 0.0116 - val_mae: 0.0874\n",
            "Epoch 89/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0117 - mae: 0.0843 - val_loss: 0.0094 - val_mae: 0.0799\n",
            "Epoch 90/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0113 - mae: 0.0847 - val_loss: 0.0158 - val_mae: 0.1012\n",
            "Epoch 91/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0129 - mae: 0.0899 - val_loss: 0.0096 - val_mae: 0.0807\n",
            "Epoch 92/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0119 - mae: 0.0872 - val_loss: 0.0089 - val_mae: 0.0780\n",
            "Epoch 93/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.0122 - mae: 0.0878 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 94/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.0123 - mae: 0.0876 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 95/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0117 - mae: 0.0856 - val_loss: 0.0087 - val_mae: 0.0771\n",
            "Epoch 96/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0115 - mae: 0.0855 - val_loss: 0.0087 - val_mae: 0.0776\n",
            "Epoch 97/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0124 - mae: 0.0874 - val_loss: 0.0123 - val_mae: 0.0900\n",
            "Epoch 98/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0121 - mae: 0.0859 - val_loss: 0.0094 - val_mae: 0.0803\n",
            "Epoch 99/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0115 - mae: 0.0825 - val_loss: 0.0087 - val_mae: 0.0774\n",
            "Epoch 100/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0107 - mae: 0.0817 - val_loss: 0.0133 - val_mae: 0.0940\n",
            "Epoch 101/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0084 - val_mae: 0.0759\n",
            "Epoch 102/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0109 - mae: 0.0834 - val_loss: 0.0088 - val_mae: 0.0769\n",
            "Epoch 103/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0127 - mae: 0.0891 - val_loss: 0.0092 - val_mae: 0.0791\n",
            "Epoch 104/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0119 - mae: 0.0850 - val_loss: 0.0123 - val_mae: 0.0901\n",
            "Epoch 105/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0120 - mae: 0.0866 - val_loss: 0.0089 - val_mae: 0.0772\n",
            "Epoch 106/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0110 - mae: 0.0830 - val_loss: 0.0110 - val_mae: 0.0857\n",
            "Epoch 107/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0122 - mae: 0.0874 - val_loss: 0.0088 - val_mae: 0.0771\n",
            "Epoch 108/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0118 - mae: 0.0845 - val_loss: 0.0108 - val_mae: 0.0846\n",
            "Epoch 109/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0119 - mae: 0.0845 - val_loss: 0.0197 - val_mae: 0.1129\n",
            "Epoch 110/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0090 - val_mae: 0.0789\n",
            "Epoch 111/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0126 - mae: 0.0898 - val_loss: 0.0112 - val_mae: 0.0869\n",
            "Epoch 112/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0112 - mae: 0.0821 - val_loss: 0.0087 - val_mae: 0.0777\n",
            "Epoch 113/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0116 - mae: 0.0844 - val_loss: 0.0092 - val_mae: 0.0799\n",
            "Epoch 114/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0110 - mae: 0.0828 - val_loss: 0.0086 - val_mae: 0.0777\n",
            "Epoch 115/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0097 - val_mae: 0.0815\n",
            "Epoch 116/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0121 - mae: 0.0870 - val_loss: 0.0090 - val_mae: 0.0787\n",
            "Epoch 117/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0120 - mae: 0.0870 - val_loss: 0.0085 - val_mae: 0.0771\n",
            "Epoch 118/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0113 - mae: 0.0842 - val_loss: 0.0086 - val_mae: 0.0771\n",
            "Epoch 119/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0121 - mae: 0.0868 - val_loss: 0.0110 - val_mae: 0.0866\n",
            "Epoch 120/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0087 - val_mae: 0.0765\n",
            "Epoch 121/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0119 - mae: 0.0865 - val_loss: 0.0134 - val_mae: 0.0941\n",
            "Epoch 122/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0090 - val_mae: 0.0785\n",
            "Epoch 123/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0116 - mae: 0.0824 - val_loss: 0.0218 - val_mae: 0.1188\n",
            "Epoch 124/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0115 - mae: 0.0844 - val_loss: 0.0209 - val_mae: 0.1164\n",
            "Epoch 125/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0112 - mae: 0.0831 - val_loss: 0.0097 - val_mae: 0.0810\n",
            "Epoch 126/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0122 - mae: 0.0872 - val_loss: 0.0092 - val_mae: 0.0788\n",
            "Epoch 127/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0107 - mae: 0.0806 - val_loss: 0.0197 - val_mae: 0.1135\n",
            "Epoch 128/600\n",
            "150/150 [==============================] - 0s 117us/sample - loss: 0.0123 - mae: 0.0870 - val_loss: 0.0089 - val_mae: 0.0769\n",
            "Epoch 129/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0115 - mae: 0.0834 - val_loss: 0.0112 - val_mae: 0.0869\n",
            "Epoch 130/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0125 - val_mae: 0.0914\n",
            "Epoch 131/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0118 - mae: 0.0855 - val_loss: 0.0089 - val_mae: 0.0782\n",
            "Epoch 132/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0146 - val_mae: 0.0980\n",
            "Epoch 133/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0109 - val_mae: 0.0860\n",
            "Epoch 134/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0087 - val_mae: 0.0778\n",
            "Epoch 135/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0108 - mae: 0.0814 - val_loss: 0.0146 - val_mae: 0.0990\n",
            "Epoch 136/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0120 - mae: 0.0858 - val_loss: 0.0092 - val_mae: 0.0795\n",
            "Epoch 137/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0112 - mae: 0.0840 - val_loss: 0.0088 - val_mae: 0.0778\n",
            "Epoch 138/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.0115 - mae: 0.0810 - val_loss: 0.0089 - val_mae: 0.0776\n",
            "Epoch 139/600\n",
            "150/150 [==============================] - 0s 208us/sample - loss: 0.0115 - mae: 0.0835 - val_loss: 0.0128 - val_mae: 0.0923\n",
            "Epoch 140/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0113 - mae: 0.0840 - val_loss: 0.0109 - val_mae: 0.0854\n",
            "Epoch 141/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0108 - mae: 0.0809 - val_loss: 0.0089 - val_mae: 0.0775\n",
            "Epoch 142/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0131 - mae: 0.0896 - val_loss: 0.0089 - val_mae: 0.0782\n",
            "Epoch 143/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0110 - mae: 0.0812 - val_loss: 0.0090 - val_mae: 0.0785\n",
            "Epoch 144/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0101 - mae: 0.0785 - val_loss: 0.0106 - val_mae: 0.0850\n",
            "Epoch 145/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0112 - mae: 0.0841 - val_loss: 0.0088 - val_mae: 0.0780\n",
            "Epoch 146/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0107 - mae: 0.0818 - val_loss: 0.0096 - val_mae: 0.0815\n",
            "Epoch 147/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0112 - mae: 0.0818 - val_loss: 0.0089 - val_mae: 0.0774\n",
            "Epoch 148/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0118 - mae: 0.0856 - val_loss: 0.0089 - val_mae: 0.0786\n",
            "Epoch 149/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0112 - val_mae: 0.0874\n",
            "Epoch 150/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0111 - mae: 0.0820 - val_loss: 0.0105 - val_mae: 0.0846\n",
            "Epoch 151/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0107 - mae: 0.0811 - val_loss: 0.0098 - val_mae: 0.0826\n",
            "Epoch 152/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0100 - val_mae: 0.0830\n",
            "Epoch 153/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0111 - mae: 0.0822 - val_loss: 0.0114 - val_mae: 0.0879\n",
            "Epoch 154/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0108 - mae: 0.0804 - val_loss: 0.0139 - val_mae: 0.0966\n",
            "Epoch 155/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0117 - mae: 0.0837 - val_loss: 0.0120 - val_mae: 0.0896\n",
            "Epoch 156/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0103 - val_mae: 0.0838\n",
            "Epoch 157/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0112 - mae: 0.0825 - val_loss: 0.0182 - val_mae: 0.1094\n",
            "Epoch 158/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0112 - mae: 0.0808 - val_loss: 0.0091 - val_mae: 0.0797\n",
            "Epoch 159/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0110 - mae: 0.0837 - val_loss: 0.0140 - val_mae: 0.0955\n",
            "Epoch 160/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0119 - mae: 0.0846 - val_loss: 0.0116 - val_mae: 0.0879\n",
            "Epoch 161/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0108 - mae: 0.0828 - val_loss: 0.0093 - val_mae: 0.0797\n",
            "Epoch 162/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0108 - mae: 0.0802 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 163/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0118 - mae: 0.0852 - val_loss: 0.0100 - val_mae: 0.0826\n",
            "Epoch 164/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0112 - mae: 0.0821 - val_loss: 0.0103 - val_mae: 0.0844\n",
            "Epoch 165/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0112 - mae: 0.0838 - val_loss: 0.0094 - val_mae: 0.0807\n",
            "Epoch 166/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0114 - mae: 0.0838 - val_loss: 0.0087 - val_mae: 0.0768\n",
            "Epoch 167/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0117 - mae: 0.0848 - val_loss: 0.0096 - val_mae: 0.0813\n",
            "Epoch 168/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0115 - mae: 0.0839 - val_loss: 0.0139 - val_mae: 0.0958\n",
            "Epoch 169/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0106 - mae: 0.0798 - val_loss: 0.0116 - val_mae: 0.0889\n",
            "Epoch 170/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0116 - mae: 0.0851 - val_loss: 0.0089 - val_mae: 0.0785\n",
            "Epoch 171/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0112 - mae: 0.0850 - val_loss: 0.0138 - val_mae: 0.0953\n",
            "Epoch 172/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0092 - val_mae: 0.0794\n",
            "Epoch 173/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0109 - mae: 0.0822 - val_loss: 0.0109 - val_mae: 0.0852\n",
            "Epoch 174/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0115 - mae: 0.0849 - val_loss: 0.0122 - val_mae: 0.0902\n",
            "Epoch 175/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0105 - mae: 0.0798 - val_loss: 0.0093 - val_mae: 0.0805\n",
            "Epoch 176/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0120 - mae: 0.0838 - val_loss: 0.0180 - val_mae: 0.1083\n",
            "Epoch 177/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0110 - mae: 0.0835 - val_loss: 0.0219 - val_mae: 0.1194\n",
            "Epoch 178/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0134 - mae: 0.0873 - val_loss: 0.0089 - val_mae: 0.0787\n",
            "Epoch 179/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0104 - mae: 0.0789 - val_loss: 0.0174 - val_mae: 0.1068\n",
            "Epoch 180/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0113 - mae: 0.0845 - val_loss: 0.0202 - val_mae: 0.1153\n",
            "Epoch 181/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0115 - mae: 0.0841 - val_loss: 0.0091 - val_mae: 0.0792\n",
            "Epoch 182/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0109 - mae: 0.0807 - val_loss: 0.0167 - val_mae: 0.1047\n",
            "Epoch 183/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0111 - mae: 0.0834 - val_loss: 0.0111 - val_mae: 0.0867\n",
            "Epoch 184/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0113 - mae: 0.0838 - val_loss: 0.0083 - val_mae: 0.0763\n",
            "Epoch 185/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0123 - mae: 0.0862 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 186/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0088 - val_mae: 0.0773\n",
            "Epoch 187/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0110 - mae: 0.0804 - val_loss: 0.0097 - val_mae: 0.0816\n",
            "Epoch 188/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0110 - mae: 0.0831 - val_loss: 0.0093 - val_mae: 0.0803\n",
            "Epoch 189/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0107 - mae: 0.0812 - val_loss: 0.0090 - val_mae: 0.0776\n",
            "Epoch 190/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0111 - mae: 0.0816 - val_loss: 0.0178 - val_mae: 0.1082\n",
            "Epoch 191/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0115 - mae: 0.0845 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 192/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0110 - mae: 0.0814 - val_loss: 0.0120 - val_mae: 0.0896\n",
            "Epoch 193/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0118 - mae: 0.0840 - val_loss: 0.0088 - val_mae: 0.0787\n",
            "Epoch 194/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0119 - mae: 0.0854 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 195/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0110 - mae: 0.0822 - val_loss: 0.0114 - val_mae: 0.0875\n",
            "Epoch 196/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0107 - mae: 0.0816 - val_loss: 0.0154 - val_mae: 0.0999\n",
            "Epoch 197/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0113 - mae: 0.0830 - val_loss: 0.0131 - val_mae: 0.0942\n",
            "Epoch 198/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0090 - val_mae: 0.0784\n",
            "Epoch 199/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0105 - mae: 0.0817 - val_loss: 0.0132 - val_mae: 0.0927\n",
            "Epoch 200/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0120 - mae: 0.0834 - val_loss: 0.0152 - val_mae: 0.0991\n",
            "Epoch 201/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0104 - mae: 0.0819 - val_loss: 0.0086 - val_mae: 0.0775\n",
            "Epoch 202/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0109 - mae: 0.0816 - val_loss: 0.0105 - val_mae: 0.0850\n",
            "Epoch 203/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0116 - mae: 0.0858 - val_loss: 0.0091 - val_mae: 0.0799\n",
            "Epoch 204/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0113 - mae: 0.0834 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 205/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0110 - mae: 0.0839 - val_loss: 0.0085 - val_mae: 0.0769\n",
            "Epoch 206/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0111 - mae: 0.0830 - val_loss: 0.0102 - val_mae: 0.0833\n",
            "Epoch 207/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0103 - val_mae: 0.0834\n",
            "Epoch 208/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0111 - mae: 0.0827 - val_loss: 0.0086 - val_mae: 0.0773\n",
            "Epoch 209/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0091 - val_mae: 0.0795\n",
            "Epoch 210/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0114 - mae: 0.0835 - val_loss: 0.0094 - val_mae: 0.0807\n",
            "Epoch 211/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.0103 - mae: 0.0811 - val_loss: 0.0091 - val_mae: 0.0789\n",
            "Epoch 212/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0106 - mae: 0.0799 - val_loss: 0.0088 - val_mae: 0.0785\n",
            "Epoch 213/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0115 - mae: 0.0847 - val_loss: 0.0096 - val_mae: 0.0810\n",
            "Epoch 214/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0116 - mae: 0.0841 - val_loss: 0.0131 - val_mae: 0.0926\n",
            "Epoch 215/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0101 - mae: 0.0784 - val_loss: 0.0101 - val_mae: 0.0837\n",
            "Epoch 216/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0118 - mae: 0.0846 - val_loss: 0.0105 - val_mae: 0.0849\n",
            "Epoch 217/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0107 - mae: 0.0821 - val_loss: 0.0102 - val_mae: 0.0835\n",
            "Epoch 218/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0089 - val_mae: 0.0782\n",
            "Epoch 219/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0115 - mae: 0.0840 - val_loss: 0.0121 - val_mae: 0.0908\n",
            "Epoch 220/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0100 - val_mae: 0.0827\n",
            "Epoch 221/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0087 - val_mae: 0.0779\n",
            "Epoch 222/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0123 - mae: 0.0874 - val_loss: 0.0087 - val_mae: 0.0781\n",
            "Epoch 223/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0090 - val_mae: 0.0786\n",
            "Epoch 224/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0107 - mae: 0.0805 - val_loss: 0.0169 - val_mae: 0.1070\n",
            "Epoch 225/600\n",
            "150/150 [==============================] - 0s 247us/sample - loss: 0.0120 - mae: 0.0841 - val_loss: 0.0092 - val_mae: 0.0787\n",
            "Epoch 226/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0109 - val_mae: 0.0859\n",
            "Epoch 227/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0107 - mae: 0.0800 - val_loss: 0.0089 - val_mae: 0.0785\n",
            "Epoch 228/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0107 - mae: 0.0810 - val_loss: 0.0165 - val_mae: 0.1035\n",
            "Epoch 229/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0097 - val_mae: 0.0815\n",
            "Epoch 230/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0102 - mae: 0.0787 - val_loss: 0.0115 - val_mae: 0.0877\n",
            "Epoch 231/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0116 - mae: 0.0838 - val_loss: 0.0131 - val_mae: 0.0937\n",
            "Epoch 232/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0118 - mae: 0.0838 - val_loss: 0.0089 - val_mae: 0.0781\n",
            "Epoch 233/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0101 - mae: 0.0788 - val_loss: 0.0090 - val_mae: 0.0788\n",
            "Epoch 234/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0117 - mae: 0.0859 - val_loss: 0.0160 - val_mae: 0.1018\n",
            "Epoch 235/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0110 - val_mae: 0.0865\n",
            "Epoch 236/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0113 - mae: 0.0816 - val_loss: 0.0137 - val_mae: 0.0944\n",
            "Epoch 237/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0103 - mae: 0.0789 - val_loss: 0.0094 - val_mae: 0.0805\n",
            "Epoch 238/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0123 - mae: 0.0859 - val_loss: 0.0127 - val_mae: 0.0932\n",
            "Epoch 239/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0117 - mae: 0.0838 - val_loss: 0.0101 - val_mae: 0.0837\n",
            "Epoch 240/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0108 - mae: 0.0810 - val_loss: 0.0126 - val_mae: 0.0913\n",
            "Epoch 241/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0097 - val_mae: 0.0809\n",
            "Epoch 242/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0129 - mae: 0.0851 - val_loss: 0.0094 - val_mae: 0.0805\n",
            "Epoch 243/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0094 - val_mae: 0.0803\n",
            "Epoch 244/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0136 - val_mae: 0.0964\n",
            "Epoch 245/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0118 - mae: 0.0834 - val_loss: 0.0100 - val_mae: 0.0831\n",
            "Epoch 246/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0104 - mae: 0.0799 - val_loss: 0.0089 - val_mae: 0.0789\n",
            "Epoch 247/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0110 - mae: 0.0805 - val_loss: 0.0149 - val_mae: 0.0984\n",
            "Epoch 248/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0114 - mae: 0.0833 - val_loss: 0.0102 - val_mae: 0.0839\n",
            "Epoch 249/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0110 - mae: 0.0807 - val_loss: 0.0092 - val_mae: 0.0801\n",
            "Epoch 250/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0112 - val_mae: 0.0873\n",
            "Epoch 251/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0110 - mae: 0.0832 - val_loss: 0.0106 - val_mae: 0.0850\n",
            "Epoch 252/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0122 - mae: 0.0866 - val_loss: 0.0092 - val_mae: 0.0801\n",
            "Epoch 253/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0108 - mae: 0.0824 - val_loss: 0.0103 - val_mae: 0.0841\n",
            "Epoch 254/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0106 - mae: 0.0805 - val_loss: 0.0133 - val_mae: 0.0933\n",
            "Epoch 255/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0108 - mae: 0.0805 - val_loss: 0.0144 - val_mae: 0.0965\n",
            "Epoch 256/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0108 - mae: 0.0834 - val_loss: 0.0091 - val_mae: 0.0797\n",
            "Epoch 257/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0116 - mae: 0.0839 - val_loss: 0.0092 - val_mae: 0.0802\n",
            "Epoch 258/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0110 - mae: 0.0809 - val_loss: 0.0125 - val_mae: 0.0913\n",
            "Epoch 259/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0114 - mae: 0.0849 - val_loss: 0.0112 - val_mae: 0.0877\n",
            "Epoch 260/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0106 - mae: 0.0810 - val_loss: 0.0128 - val_mae: 0.0920\n",
            "Epoch 261/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0146 - val_mae: 0.0994\n",
            "Epoch 262/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0115 - mae: 0.0838 - val_loss: 0.0088 - val_mae: 0.0774\n",
            "Epoch 263/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0094 - val_mae: 0.0813\n",
            "Epoch 264/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0111 - mae: 0.0830 - val_loss: 0.0107 - val_mae: 0.0851\n",
            "Epoch 265/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0128 - val_mae: 0.0918\n",
            "Epoch 266/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0097 - val_mae: 0.0816\n",
            "Epoch 267/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0102 - mae: 0.0787 - val_loss: 0.0094 - val_mae: 0.0807\n",
            "Epoch 268/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0110 - mae: 0.0809 - val_loss: 0.0094 - val_mae: 0.0806\n",
            "Epoch 269/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0114 - mae: 0.0827 - val_loss: 0.0143 - val_mae: 0.0963\n",
            "Epoch 270/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0103 - mae: 0.0788 - val_loss: 0.0169 - val_mae: 0.1048\n",
            "Epoch 271/600\n",
            "150/150 [==============================] - 0s 239us/sample - loss: 0.0118 - mae: 0.0829 - val_loss: 0.0146 - val_mae: 0.0972\n",
            "Epoch 272/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0113 - mae: 0.0828 - val_loss: 0.0097 - val_mae: 0.0816\n",
            "Epoch 273/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0101 - mae: 0.0804 - val_loss: 0.0110 - val_mae: 0.0864\n",
            "Epoch 274/600\n",
            "150/150 [==============================] - 0s 220us/sample - loss: 0.0102 - mae: 0.0781 - val_loss: 0.0120 - val_mae: 0.0897\n",
            "Epoch 275/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0100 - val_mae: 0.0823\n",
            "Epoch 276/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0115 - mae: 0.0828 - val_loss: 0.0119 - val_mae: 0.0894\n",
            "Epoch 277/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0111 - mae: 0.0829 - val_loss: 0.0097 - val_mae: 0.0811\n",
            "Epoch 278/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0101 - val_mae: 0.0830\n",
            "Epoch 279/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0116 - mae: 0.0830 - val_loss: 0.0098 - val_mae: 0.0816\n",
            "Epoch 280/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0106 - mae: 0.0805 - val_loss: 0.0093 - val_mae: 0.0796\n",
            "Epoch 281/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0103 - mae: 0.0792 - val_loss: 0.0121 - val_mae: 0.0897\n",
            "Epoch 282/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0092 - val_mae: 0.0793\n",
            "Epoch 283/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0115 - mae: 0.0831 - val_loss: 0.0099 - val_mae: 0.0818\n",
            "Epoch 284/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0113 - mae: 0.0820 - val_loss: 0.0120 - val_mae: 0.0890\n",
            "Epoch 285/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0102 - mae: 0.0787 - val_loss: 0.0094 - val_mae: 0.0805\n",
            "Epoch 286/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0102 - mae: 0.0785 - val_loss: 0.0096 - val_mae: 0.0802\n",
            "Epoch 287/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0119 - mae: 0.0853 - val_loss: 0.0095 - val_mae: 0.0812\n",
            "Epoch 288/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0110 - mae: 0.0833 - val_loss: 0.0098 - val_mae: 0.0821\n",
            "Epoch 289/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0103 - mae: 0.0793 - val_loss: 0.0171 - val_mae: 0.1043\n",
            "Epoch 290/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0117 - mae: 0.0814 - val_loss: 0.0100 - val_mae: 0.0826\n",
            "Epoch 291/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0110 - mae: 0.0823 - val_loss: 0.0098 - val_mae: 0.0815\n",
            "Epoch 292/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0110 - mae: 0.0803 - val_loss: 0.0094 - val_mae: 0.0800\n",
            "Epoch 293/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0106 - mae: 0.0795 - val_loss: 0.0112 - val_mae: 0.0870\n",
            "Epoch 294/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 295/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0111 - mae: 0.0808 - val_loss: 0.0114 - val_mae: 0.0875\n",
            "Epoch 296/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0113 - mae: 0.0829 - val_loss: 0.0094 - val_mae: 0.0796\n",
            "Epoch 297/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0103 - mae: 0.0779 - val_loss: 0.0201 - val_mae: 0.1140\n",
            "Epoch 298/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0119 - mae: 0.0848 - val_loss: 0.0115 - val_mae: 0.0884\n",
            "Epoch 299/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0103 - mae: 0.0784 - val_loss: 0.0146 - val_mae: 0.0994\n",
            "Epoch 300/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0121 - mae: 0.0859 - val_loss: 0.0097 - val_mae: 0.0820\n",
            "Epoch 301/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0107 - mae: 0.0815 - val_loss: 0.0095 - val_mae: 0.0811\n",
            "Epoch 302/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0107 - mae: 0.0805 - val_loss: 0.0109 - val_mae: 0.0860\n",
            "Epoch 303/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0114 - mae: 0.0825 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 304/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0101 - mae: 0.0764 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 305/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0117 - mae: 0.0830 - val_loss: 0.0114 - val_mae: 0.0884\n",
            "Epoch 306/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0102 - mae: 0.0800 - val_loss: 0.0118 - val_mae: 0.0893\n",
            "Epoch 307/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0139 - val_mae: 0.0950\n",
            "Epoch 308/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0098 - val_mae: 0.0818\n",
            "Epoch 309/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0105 - mae: 0.0786 - val_loss: 0.0136 - val_mae: 0.0942\n",
            "Epoch 310/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0104 - mae: 0.0828 - val_loss: 0.0098 - val_mae: 0.0815\n",
            "Epoch 311/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0125 - mae: 0.0872 - val_loss: 0.0095 - val_mae: 0.0808\n",
            "Epoch 312/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0137 - val_mae: 0.0963\n",
            "Epoch 313/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0112 - mae: 0.0826 - val_loss: 0.0096 - val_mae: 0.0810\n",
            "Epoch 314/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0129 - val_mae: 0.0922\n",
            "Epoch 315/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0112 - mae: 0.0816 - val_loss: 0.0129 - val_mae: 0.0925\n",
            "Epoch 316/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0109 - mae: 0.0827 - val_loss: 0.0093 - val_mae: 0.0803\n",
            "Epoch 317/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0113 - mae: 0.0829 - val_loss: 0.0102 - val_mae: 0.0833\n",
            "Epoch 318/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0108 - val_mae: 0.0864\n",
            "Epoch 319/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0108 - mae: 0.0808 - val_loss: 0.0172 - val_mae: 0.1058\n",
            "Epoch 320/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0111 - mae: 0.0837 - val_loss: 0.0124 - val_mae: 0.0911\n",
            "Epoch 321/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0103 - mae: 0.0797 - val_loss: 0.0093 - val_mae: 0.0805\n",
            "Epoch 322/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0116 - mae: 0.0821 - val_loss: 0.0106 - val_mae: 0.0854\n",
            "Epoch 323/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0104 - mae: 0.0793 - val_loss: 0.0091 - val_mae: 0.0785\n",
            "Epoch 324/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0113 - mae: 0.0827 - val_loss: 0.0092 - val_mae: 0.0798\n",
            "Epoch 325/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0115 - mae: 0.0835 - val_loss: 0.0098 - val_mae: 0.0822\n",
            "Epoch 326/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0105 - mae: 0.0784 - val_loss: 0.0215 - val_mae: 0.1183\n",
            "Epoch 327/600\n",
            "150/150 [==============================] - 0s 208us/sample - loss: 0.0118 - mae: 0.0842 - val_loss: 0.0112 - val_mae: 0.0874\n",
            "Epoch 328/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0105 - mae: 0.0809 - val_loss: 0.0092 - val_mae: 0.0797\n",
            "Epoch 329/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0119 - mae: 0.0854 - val_loss: 0.0096 - val_mae: 0.0812\n",
            "Epoch 330/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0107 - mae: 0.0795 - val_loss: 0.0133 - val_mae: 0.0935\n",
            "Epoch 331/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0111 - mae: 0.0832 - val_loss: 0.0096 - val_mae: 0.0821\n",
            "Epoch 332/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0103 - mae: 0.0803 - val_loss: 0.0099 - val_mae: 0.0832\n",
            "Epoch 333/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0107 - mae: 0.0819 - val_loss: 0.0096 - val_mae: 0.0817\n",
            "Epoch 334/600\n",
            "150/150 [==============================] - 0s 220us/sample - loss: 0.0109 - mae: 0.0828 - val_loss: 0.0104 - val_mae: 0.0834\n",
            "Epoch 335/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0103 - mae: 0.0782 - val_loss: 0.0119 - val_mae: 0.0893\n",
            "Epoch 336/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0112 - mae: 0.0827 - val_loss: 0.0090 - val_mae: 0.0790\n",
            "Epoch 337/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0109 - mae: 0.0819 - val_loss: 0.0092 - val_mae: 0.0799\n",
            "Epoch 338/600\n",
            "150/150 [==============================] - 0s 217us/sample - loss: 0.0113 - mae: 0.0831 - val_loss: 0.0095 - val_mae: 0.0797\n",
            "Epoch 339/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0117 - mae: 0.0839 - val_loss: 0.0150 - val_mae: 0.0981\n",
            "Epoch 340/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0107 - mae: 0.0828 - val_loss: 0.0152 - val_mae: 0.0990\n",
            "Epoch 341/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0110 - mae: 0.0826 - val_loss: 0.0095 - val_mae: 0.0802\n",
            "Epoch 342/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0105 - mae: 0.0805 - val_loss: 0.0094 - val_mae: 0.0796\n",
            "Epoch 343/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0109 - mae: 0.0825 - val_loss: 0.0149 - val_mae: 0.0979\n",
            "Epoch 344/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0109 - mae: 0.0814 - val_loss: 0.0099 - val_mae: 0.0825\n",
            "Epoch 345/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0099 - val_mae: 0.0822\n",
            "Epoch 346/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0104 - mae: 0.0785 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 347/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0117 - mae: 0.0839 - val_loss: 0.0094 - val_mae: 0.0808\n",
            "Epoch 348/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0145 - val_mae: 0.0972\n",
            "Epoch 349/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0104 - mae: 0.0806 - val_loss: 0.0117 - val_mae: 0.0892\n",
            "Epoch 350/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0116 - mae: 0.0837 - val_loss: 0.0119 - val_mae: 0.0896\n",
            "Epoch 351/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.0117 - mae: 0.0841 - val_loss: 0.0096 - val_mae: 0.0814\n",
            "Epoch 352/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0103 - mae: 0.0799 - val_loss: 0.0095 - val_mae: 0.0814\n",
            "Epoch 353/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0092 - val_mae: 0.0806\n",
            "Epoch 354/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0116 - mae: 0.0842 - val_loss: 0.0095 - val_mae: 0.0806\n",
            "Epoch 355/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0095 - val_mae: 0.0814\n",
            "Epoch 356/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0104 - mae: 0.0779 - val_loss: 0.0100 - val_mae: 0.0835\n",
            "Epoch 357/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0102 - mae: 0.0786 - val_loss: 0.0118 - val_mae: 0.0895\n",
            "Epoch 358/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0107 - mae: 0.0830 - val_loss: 0.0110 - val_mae: 0.0860\n",
            "Epoch 359/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0114 - mae: 0.0832 - val_loss: 0.0100 - val_mae: 0.0826\n",
            "Epoch 360/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0099 - mae: 0.0781 - val_loss: 0.0114 - val_mae: 0.0882\n",
            "Epoch 361/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0117 - mae: 0.0835 - val_loss: 0.0133 - val_mae: 0.0939\n",
            "Epoch 362/600\n",
            "150/150 [==============================] - 0s 247us/sample - loss: 0.0102 - mae: 0.0805 - val_loss: 0.0105 - val_mae: 0.0853\n",
            "Epoch 363/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0118 - val_mae: 0.0896\n",
            "Epoch 364/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0105 - mae: 0.0789 - val_loss: 0.0293 - val_mae: 0.1371\n",
            "Epoch 365/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0122 - mae: 0.0830 - val_loss: 0.0094 - val_mae: 0.0811\n",
            "Epoch 366/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0097 - val_mae: 0.0826\n",
            "Epoch 367/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0112 - mae: 0.0824 - val_loss: 0.0141 - val_mae: 0.0966\n",
            "Epoch 368/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0106 - mae: 0.0794 - val_loss: 0.0136 - val_mae: 0.0965\n",
            "Epoch 369/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0108 - mae: 0.0818 - val_loss: 0.0104 - val_mae: 0.0851\n",
            "Epoch 370/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0107 - mae: 0.0809 - val_loss: 0.0096 - val_mae: 0.0814\n",
            "Epoch 371/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0113 - mae: 0.0838 - val_loss: 0.0093 - val_mae: 0.0804\n",
            "Epoch 372/600\n",
            "150/150 [==============================] - 0s 270us/sample - loss: 0.0111 - mae: 0.0832 - val_loss: 0.0124 - val_mae: 0.0922\n",
            "Epoch 373/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0122 - mae: 0.0846 - val_loss: 0.0118 - val_mae: 0.0901\n",
            "Epoch 374/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0103 - mae: 0.0794 - val_loss: 0.0103 - val_mae: 0.0844\n",
            "Epoch 375/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0118 - mae: 0.0858 - val_loss: 0.0103 - val_mae: 0.0835\n",
            "Epoch 376/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0116 - mae: 0.0835 - val_loss: 0.0129 - val_mae: 0.0932\n",
            "Epoch 377/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0114 - mae: 0.0830 - val_loss: 0.0101 - val_mae: 0.0832\n",
            "Epoch 378/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0112 - mae: 0.0816 - val_loss: 0.0114 - val_mae: 0.0893\n",
            "Epoch 379/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0107 - mae: 0.0829 - val_loss: 0.0109 - val_mae: 0.0868\n",
            "Epoch 380/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0109 - mae: 0.0801 - val_loss: 0.0180 - val_mae: 0.1076\n",
            "Epoch 381/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0111 - mae: 0.0820 - val_loss: 0.0107 - val_mae: 0.0859\n",
            "Epoch 382/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0138 - val_mae: 0.0959\n",
            "Epoch 383/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0108 - mae: 0.0827 - val_loss: 0.0119 - val_mae: 0.0907\n",
            "Epoch 384/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0105 - mae: 0.0798 - val_loss: 0.0121 - val_mae: 0.0911\n",
            "Epoch 385/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0110 - val_mae: 0.0874\n",
            "Epoch 386/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0098 - mae: 0.0780 - val_loss: 0.0094 - val_mae: 0.0808\n",
            "Epoch 387/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0129 - val_mae: 0.0935\n",
            "Epoch 388/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0109 - mae: 0.0839 - val_loss: 0.0102 - val_mae: 0.0843\n",
            "Epoch 389/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0104 - mae: 0.0792 - val_loss: 0.0101 - val_mae: 0.0829\n",
            "Epoch 390/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0113 - mae: 0.0832 - val_loss: 0.0145 - val_mae: 0.0976\n",
            "Epoch 391/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0120 - val_mae: 0.0908\n",
            "Epoch 392/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0110 - mae: 0.0825 - val_loss: 0.0113 - val_mae: 0.0889\n",
            "Epoch 393/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0103 - mae: 0.0788 - val_loss: 0.0168 - val_mae: 0.1045\n",
            "Epoch 394/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0117 - mae: 0.0842 - val_loss: 0.0098 - val_mae: 0.0825\n",
            "Epoch 395/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0103 - mae: 0.0796 - val_loss: 0.0140 - val_mae: 0.0972\n",
            "Epoch 396/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0106 - mae: 0.0793 - val_loss: 0.0152 - val_mae: 0.1012\n",
            "Epoch 397/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0114 - mae: 0.0825 - val_loss: 0.0100 - val_mae: 0.0831\n",
            "Epoch 398/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0125 - val_mae: 0.0920\n",
            "Epoch 399/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0106 - mae: 0.0829 - val_loss: 0.0106 - val_mae: 0.0848\n",
            "Epoch 400/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0108 - mae: 0.0822 - val_loss: 0.0097 - val_mae: 0.0822\n",
            "Epoch 401/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0106 - mae: 0.0817 - val_loss: 0.0131 - val_mae: 0.0947\n",
            "Epoch 402/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0125 - mae: 0.0894 - val_loss: 0.0093 - val_mae: 0.0806\n",
            "Epoch 403/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0095 - val_mae: 0.0816\n",
            "Epoch 404/600\n",
            "150/150 [==============================] - 0s 245us/sample - loss: 0.0104 - mae: 0.0788 - val_loss: 0.0186 - val_mae: 0.1092\n",
            "Epoch 405/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0117 - mae: 0.0856 - val_loss: 0.0117 - val_mae: 0.0897\n",
            "Epoch 406/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0107 - mae: 0.0805 - val_loss: 0.0095 - val_mae: 0.0814\n",
            "Epoch 407/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0102 - mae: 0.0775 - val_loss: 0.0120 - val_mae: 0.0907\n",
            "Epoch 408/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.0115 - mae: 0.0859 - val_loss: 0.0135 - val_mae: 0.0957\n",
            "Epoch 409/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0104 - val_mae: 0.0838\n",
            "Epoch 410/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0126 - val_mae: 0.0925\n",
            "Epoch 411/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0106 - mae: 0.0798 - val_loss: 0.0096 - val_mae: 0.0819\n",
            "Epoch 412/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0113 - val_mae: 0.0883\n",
            "Epoch 413/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0107 - mae: 0.0821 - val_loss: 0.0098 - val_mae: 0.0822\n",
            "Epoch 414/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0112 - mae: 0.0836 - val_loss: 0.0099 - val_mae: 0.0832\n",
            "Epoch 415/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0103 - mae: 0.0807 - val_loss: 0.0094 - val_mae: 0.0807\n",
            "Epoch 416/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0107 - mae: 0.0798 - val_loss: 0.0115 - val_mae: 0.0894\n",
            "Epoch 417/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0108 - mae: 0.0822 - val_loss: 0.0090 - val_mae: 0.0795\n",
            "Epoch 418/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0124 - mae: 0.0862 - val_loss: 0.0098 - val_mae: 0.0825\n",
            "Epoch 419/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0143 - val_mae: 0.0971\n",
            "Epoch 420/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0106 - val_mae: 0.0855\n",
            "Epoch 421/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0110 - val_mae: 0.0874\n",
            "Epoch 422/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0106 - mae: 0.0792 - val_loss: 0.0118 - val_mae: 0.0904\n",
            "Epoch 423/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0107 - mae: 0.0825 - val_loss: 0.0106 - val_mae: 0.0862\n",
            "Epoch 424/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0107 - mae: 0.0792 - val_loss: 0.0103 - val_mae: 0.0838\n",
            "Epoch 425/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0110 - mae: 0.0842 - val_loss: 0.0130 - val_mae: 0.0934\n",
            "Epoch 426/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0096 - val_mae: 0.0819\n",
            "Epoch 427/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0100 - val_mae: 0.0829\n",
            "Epoch 428/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0115 - mae: 0.0834 - val_loss: 0.0098 - val_mae: 0.0823\n",
            "Epoch 429/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0113 - mae: 0.0835 - val_loss: 0.0097 - val_mae: 0.0821\n",
            "Epoch 430/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0104 - mae: 0.0796 - val_loss: 0.0094 - val_mae: 0.0812\n",
            "Epoch 431/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0111 - mae: 0.0826 - val_loss: 0.0096 - val_mae: 0.0813\n",
            "Epoch 432/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0138 - val_mae: 0.0956\n",
            "Epoch 433/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0117 - mae: 0.0829 - val_loss: 0.0100 - val_mae: 0.0839\n",
            "Epoch 434/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0098 - mae: 0.0782 - val_loss: 0.0116 - val_mae: 0.0884\n",
            "Epoch 435/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0118 - mae: 0.0867 - val_loss: 0.0100 - val_mae: 0.0833\n",
            "Epoch 436/600\n",
            "150/150 [==============================] - 0s 247us/sample - loss: 0.0116 - mae: 0.0840 - val_loss: 0.0096 - val_mae: 0.0815\n",
            "Epoch 437/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0103 - mae: 0.0795 - val_loss: 0.0094 - val_mae: 0.0813\n",
            "Epoch 438/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0094 - mae: 0.0764 - val_loss: 0.0097 - val_mae: 0.0822\n",
            "Epoch 439/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0102 - mae: 0.0784 - val_loss: 0.0111 - val_mae: 0.0875\n",
            "Epoch 440/600\n",
            "150/150 [==============================] - 0s 230us/sample - loss: 0.0112 - mae: 0.0833 - val_loss: 0.0101 - val_mae: 0.0834\n",
            "Epoch 441/600\n",
            "150/150 [==============================] - 0s 236us/sample - loss: 0.0111 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0877\n",
            "Epoch 442/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0093 - val_mae: 0.0811\n",
            "Epoch 443/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0104 - mae: 0.0798 - val_loss: 0.0107 - val_mae: 0.0868\n",
            "Epoch 444/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0106 - mae: 0.0811 - val_loss: 0.0096 - val_mae: 0.0824\n",
            "Epoch 445/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0106 - mae: 0.0814 - val_loss: 0.0138 - val_mae: 0.0955\n",
            "Epoch 446/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0113 - mae: 0.0844 - val_loss: 0.0107 - val_mae: 0.0858\n",
            "Epoch 447/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0095 - val_mae: 0.0816\n",
            "Epoch 448/600\n",
            "150/150 [==============================] - 0s 230us/sample - loss: 0.0105 - mae: 0.0824 - val_loss: 0.0132 - val_mae: 0.0941\n",
            "Epoch 449/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0103 - mae: 0.0795 - val_loss: 0.0102 - val_mae: 0.0836\n",
            "Epoch 450/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0115 - mae: 0.0842 - val_loss: 0.0109 - val_mae: 0.0868\n",
            "Epoch 451/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0100 - val_mae: 0.0836\n",
            "Epoch 452/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0112 - mae: 0.0817 - val_loss: 0.0136 - val_mae: 0.0949\n",
            "Epoch 453/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0103 - mae: 0.0796 - val_loss: 0.0096 - val_mae: 0.0810\n",
            "Epoch 454/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0101 - mae: 0.0821 - val_loss: 0.0195 - val_mae: 0.1119\n",
            "Epoch 455/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0111 - mae: 0.0829 - val_loss: 0.0123 - val_mae: 0.0914\n",
            "Epoch 456/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0115 - mae: 0.0834 - val_loss: 0.0098 - val_mae: 0.0822\n",
            "Epoch 457/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0103 - mae: 0.0802 - val_loss: 0.0121 - val_mae: 0.0910\n",
            "Epoch 458/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0113 - mae: 0.0835 - val_loss: 0.0099 - val_mae: 0.0829\n",
            "Epoch 459/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0095 - mae: 0.0771 - val_loss: 0.0118 - val_mae: 0.0891\n",
            "Epoch 460/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0131 - mae: 0.0895 - val_loss: 0.0102 - val_mae: 0.0836\n",
            "Epoch 461/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0108 - mae: 0.0817 - val_loss: 0.0111 - val_mae: 0.0876\n",
            "Epoch 462/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0116 - mae: 0.0843 - val_loss: 0.0105 - val_mae: 0.0859\n",
            "Epoch 463/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0123 - val_mae: 0.0917\n",
            "Epoch 464/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0109 - mae: 0.0824 - val_loss: 0.0097 - val_mae: 0.0813\n",
            "Epoch 465/600\n",
            "150/150 [==============================] - 0s 220us/sample - loss: 0.0099 - mae: 0.0773 - val_loss: 0.0101 - val_mae: 0.0833\n",
            "Epoch 466/600\n",
            "150/150 [==============================] - 0s 235us/sample - loss: 0.0103 - mae: 0.0802 - val_loss: 0.0112 - val_mae: 0.0878\n",
            "Epoch 467/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0115 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0851\n",
            "Epoch 468/600\n",
            "150/150 [==============================] - 0s 219us/sample - loss: 0.0104 - mae: 0.0799 - val_loss: 0.0095 - val_mae: 0.0817\n",
            "Epoch 469/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0097 - val_mae: 0.0829\n",
            "Epoch 470/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0108 - mae: 0.0828 - val_loss: 0.0215 - val_mae: 0.1179\n",
            "Epoch 471/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0114 - mae: 0.0832 - val_loss: 0.0141 - val_mae: 0.0963\n",
            "Epoch 472/600\n",
            "150/150 [==============================] - 0s 238us/sample - loss: 0.0105 - mae: 0.0818 - val_loss: 0.0113 - val_mae: 0.0882\n",
            "Epoch 473/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0107 - mae: 0.0811 - val_loss: 0.0098 - val_mae: 0.0830\n",
            "Epoch 474/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0108 - mae: 0.0823 - val_loss: 0.0093 - val_mae: 0.0808\n",
            "Epoch 475/600\n",
            "150/150 [==============================] - 0s 224us/sample - loss: 0.0114 - mae: 0.0829 - val_loss: 0.0095 - val_mae: 0.0821\n",
            "Epoch 476/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0103 - mae: 0.0803 - val_loss: 0.0110 - val_mae: 0.0874\n",
            "Epoch 477/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0119 - mae: 0.0847 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 478/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0107 - mae: 0.0798 - val_loss: 0.0095 - val_mae: 0.0818\n",
            "Epoch 479/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0107 - mae: 0.0793 - val_loss: 0.0106 - val_mae: 0.0859\n",
            "Epoch 480/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0109 - mae: 0.0813 - val_loss: 0.0096 - val_mae: 0.0812\n",
            "Epoch 481/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0108 - mae: 0.0803 - val_loss: 0.0096 - val_mae: 0.0818\n",
            "Epoch 482/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0108 - mae: 0.0806 - val_loss: 0.0101 - val_mae: 0.0843\n",
            "Epoch 483/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0106 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0848\n",
            "Epoch 484/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0109 - mae: 0.0804 - val_loss: 0.0095 - val_mae: 0.0815\n",
            "Epoch 485/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0104 - mae: 0.0793 - val_loss: 0.0103 - val_mae: 0.0849\n",
            "Epoch 486/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0122 - val_mae: 0.0916\n",
            "Epoch 487/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0109 - mae: 0.0795 - val_loss: 0.0102 - val_mae: 0.0842\n",
            "Epoch 488/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0115 - mae: 0.0842 - val_loss: 0.0131 - val_mae: 0.0940\n",
            "Epoch 489/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0108 - mae: 0.0805 - val_loss: 0.0104 - val_mae: 0.0851\n",
            "Epoch 490/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0111 - mae: 0.0826 - val_loss: 0.0114 - val_mae: 0.0890\n",
            "Epoch 491/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0104 - mae: 0.0810 - val_loss: 0.0144 - val_mae: 0.0975\n",
            "Epoch 492/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0108 - mae: 0.0802 - val_loss: 0.0118 - val_mae: 0.0903\n",
            "Epoch 493/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0101 - mae: 0.0789 - val_loss: 0.0103 - val_mae: 0.0849\n",
            "Epoch 494/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0122 - mae: 0.0860 - val_loss: 0.0095 - val_mae: 0.0816\n",
            "Epoch 495/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0102 - mae: 0.0786 - val_loss: 0.0121 - val_mae: 0.0909\n",
            "Epoch 496/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.0109 - mae: 0.0821 - val_loss: 0.0227 - val_mae: 0.1209\n",
            "Epoch 497/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.0116 - mae: 0.0836 - val_loss: 0.0113 - val_mae: 0.0881\n",
            "Epoch 498/600\n",
            "150/150 [==============================] - 0s 224us/sample - loss: 0.0103 - mae: 0.0804 - val_loss: 0.0109 - val_mae: 0.0870\n",
            "Epoch 499/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0132 - val_mae: 0.0943\n",
            "Epoch 500/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0120 - val_mae: 0.0910\n",
            "Epoch 501/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0111 - mae: 0.0800 - val_loss: 0.0116 - val_mae: 0.0895\n",
            "Epoch 502/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0115 - mae: 0.0851 - val_loss: 0.0108 - val_mae: 0.0867\n",
            "Epoch 503/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0100 - mae: 0.0781 - val_loss: 0.0119 - val_mae: 0.0899\n",
            "Epoch 504/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0112 - mae: 0.0811 - val_loss: 0.0097 - val_mae: 0.0819\n",
            "Epoch 505/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0105 - mae: 0.0814 - val_loss: 0.0111 - val_mae: 0.0875\n",
            "Epoch 506/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0098 - mae: 0.0798 - val_loss: 0.0122 - val_mae: 0.0916\n",
            "Epoch 507/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0103 - mae: 0.0799 - val_loss: 0.0111 - val_mae: 0.0875\n",
            "Epoch 508/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0103 - mae: 0.0824 - val_loss: 0.0104 - val_mae: 0.0853\n",
            "Epoch 509/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0110 - mae: 0.0852 - val_loss: 0.0097 - val_mae: 0.0825\n",
            "Epoch 510/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0098 - val_mae: 0.0828\n",
            "Epoch 511/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0110 - mae: 0.0815 - val_loss: 0.0165 - val_mae: 0.1038\n",
            "Epoch 512/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0113 - mae: 0.0822 - val_loss: 0.0108 - val_mae: 0.0868\n",
            "Epoch 513/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0110 - mae: 0.0800 - val_loss: 0.0093 - val_mae: 0.0809\n",
            "Epoch 514/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0094 - val_mae: 0.0813\n",
            "Epoch 515/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0112 - mae: 0.0822 - val_loss: 0.0099 - val_mae: 0.0825\n",
            "Epoch 516/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0103 - mae: 0.0813 - val_loss: 0.0102 - val_mae: 0.0846\n",
            "Epoch 517/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0101 - mae: 0.0788 - val_loss: 0.0109 - val_mae: 0.0874\n",
            "Epoch 518/600\n",
            "150/150 [==============================] - 0s 220us/sample - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0097 - val_mae: 0.0828\n",
            "Epoch 519/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0116 - mae: 0.0826 - val_loss: 0.0119 - val_mae: 0.0906\n",
            "Epoch 520/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0101 - mae: 0.0807 - val_loss: 0.0094 - val_mae: 0.0814\n",
            "Epoch 521/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0141 - val_mae: 0.0977\n",
            "Epoch 522/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0112 - mae: 0.0839 - val_loss: 0.0095 - val_mae: 0.0818\n",
            "Epoch 523/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0109 - mae: 0.0811 - val_loss: 0.0092 - val_mae: 0.0805\n",
            "Epoch 524/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0103 - mae: 0.0809 - val_loss: 0.0095 - val_mae: 0.0817\n",
            "Epoch 525/600\n",
            "150/150 [==============================] - 0s 218us/sample - loss: 0.0104 - mae: 0.0803 - val_loss: 0.0130 - val_mae: 0.0936\n",
            "Epoch 526/600\n",
            "150/150 [==============================] - 0s 244us/sample - loss: 0.0114 - mae: 0.0852 - val_loss: 0.0115 - val_mae: 0.0887\n",
            "Epoch 527/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0134 - val_mae: 0.0954\n",
            "Epoch 528/600\n",
            "150/150 [==============================] - 0s 250us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0169 - val_mae: 0.1077\n",
            "Epoch 529/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0113 - mae: 0.0856 - val_loss: 0.0127 - val_mae: 0.0930\n",
            "Epoch 530/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0097 - val_mae: 0.0823\n",
            "Epoch 531/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0108 - mae: 0.0813 - val_loss: 0.0097 - val_mae: 0.0824\n",
            "Epoch 532/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0093 - val_mae: 0.0809\n",
            "Epoch 533/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0103 - mae: 0.0797 - val_loss: 0.0106 - val_mae: 0.0862\n",
            "Epoch 534/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0115 - mae: 0.0817 - val_loss: 0.0174 - val_mae: 0.1064\n",
            "Epoch 535/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0112 - mae: 0.0835 - val_loss: 0.0110 - val_mae: 0.0878\n",
            "Epoch 536/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0106 - mae: 0.0804 - val_loss: 0.0235 - val_mae: 0.1231\n",
            "Epoch 537/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0128 - mae: 0.0856 - val_loss: 0.0108 - val_mae: 0.0873\n",
            "Epoch 538/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0108 - mae: 0.0818 - val_loss: 0.0102 - val_mae: 0.0850\n",
            "Epoch 539/600\n",
            "150/150 [==============================] - 0s 235us/sample - loss: 0.0099 - mae: 0.0776 - val_loss: 0.0107 - val_mae: 0.0863\n",
            "Epoch 540/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0096 - val_mae: 0.0818\n",
            "Epoch 541/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0100 - mae: 0.0777 - val_loss: 0.0097 - val_mae: 0.0822\n",
            "Epoch 542/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0103 - mae: 0.0813 - val_loss: 0.0116 - val_mae: 0.0899\n",
            "Epoch 543/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0118 - mae: 0.0852 - val_loss: 0.0116 - val_mae: 0.0896\n",
            "Epoch 544/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0113 - mae: 0.0836 - val_loss: 0.0097 - val_mae: 0.0830\n",
            "Epoch 545/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0100 - mae: 0.0792 - val_loss: 0.0126 - val_mae: 0.0926\n",
            "Epoch 546/600\n",
            "150/150 [==============================] - 0s 230us/sample - loss: 0.0108 - mae: 0.0825 - val_loss: 0.0110 - val_mae: 0.0879\n",
            "Epoch 547/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0102 - mae: 0.0810 - val_loss: 0.0096 - val_mae: 0.0824\n",
            "Epoch 548/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0104 - mae: 0.0805 - val_loss: 0.0110 - val_mae: 0.0877\n",
            "Epoch 549/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0112 - mae: 0.0824 - val_loss: 0.0097 - val_mae: 0.0821\n",
            "Epoch 550/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0100 - val_mae: 0.0832\n",
            "Epoch 551/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0105 - mae: 0.0801 - val_loss: 0.0181 - val_mae: 0.1083\n",
            "Epoch 552/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0108 - mae: 0.0809 - val_loss: 0.0120 - val_mae: 0.0909\n",
            "Epoch 553/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0102 - mae: 0.0798 - val_loss: 0.0109 - val_mae: 0.0872\n",
            "Epoch 554/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0103 - mae: 0.0806 - val_loss: 0.0108 - val_mae: 0.0863\n",
            "Epoch 555/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0100 - mae: 0.0759 - val_loss: 0.0207 - val_mae: 0.1162\n",
            "Epoch 556/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0122 - mae: 0.0873 - val_loss: 0.0106 - val_mae: 0.0856\n",
            "Epoch 557/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0099 - mae: 0.0790 - val_loss: 0.0226 - val_mae: 0.1204\n",
            "Epoch 558/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0113 - mae: 0.0827 - val_loss: 0.0100 - val_mae: 0.0831\n",
            "Epoch 559/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0095 - mae: 0.0764 - val_loss: 0.0099 - val_mae: 0.0837\n",
            "Epoch 560/600\n",
            "150/150 [==============================] - 0s 257us/sample - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0115 - val_mae: 0.0897\n",
            "Epoch 561/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0104 - mae: 0.0819 - val_loss: 0.0177 - val_mae: 0.1092\n",
            "Epoch 562/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0118 - mae: 0.0861 - val_loss: 0.0095 - val_mae: 0.0817\n",
            "Epoch 563/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0114 - mae: 0.0855 - val_loss: 0.0095 - val_mae: 0.0816\n",
            "Epoch 564/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0103 - mae: 0.0808 - val_loss: 0.0095 - val_mae: 0.0818\n",
            "Epoch 565/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0111 - mae: 0.0820 - val_loss: 0.0101 - val_mae: 0.0839\n",
            "Epoch 566/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0115 - mae: 0.0857 - val_loss: 0.0106 - val_mae: 0.0865\n",
            "Epoch 567/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0104 - mae: 0.0810 - val_loss: 0.0099 - val_mae: 0.0823\n",
            "Epoch 568/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0103 - mae: 0.0801 - val_loss: 0.0109 - val_mae: 0.0874\n",
            "Epoch 569/600\n",
            "150/150 [==============================] - 0s 258us/sample - loss: 0.0109 - mae: 0.0831 - val_loss: 0.0096 - val_mae: 0.0818\n",
            "Epoch 570/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0101 - mae: 0.0795 - val_loss: 0.0106 - val_mae: 0.0843\n",
            "Epoch 571/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0117 - mae: 0.0825 - val_loss: 0.0108 - val_mae: 0.0859\n",
            "Epoch 572/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0096 - mae: 0.0790 - val_loss: 0.0143 - val_mae: 0.0974\n",
            "Epoch 573/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0113 - mae: 0.0830 - val_loss: 0.0152 - val_mae: 0.0998\n",
            "Epoch 574/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0106 - mae: 0.0811 - val_loss: 0.0192 - val_mae: 0.1115\n",
            "Epoch 575/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0109 - mae: 0.0837 - val_loss: 0.0137 - val_mae: 0.0955\n",
            "Epoch 576/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0097 - mae: 0.0795 - val_loss: 0.0106 - val_mae: 0.0863\n",
            "Epoch 577/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0109 - mae: 0.0805 - val_loss: 0.0144 - val_mae: 0.0978\n",
            "Epoch 578/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0102 - mae: 0.0775 - val_loss: 0.0122 - val_mae: 0.0919\n",
            "Epoch 579/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0101 - mae: 0.0806 - val_loss: 0.0133 - val_mae: 0.0947\n",
            "Epoch 580/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0123 - val_mae: 0.0919\n",
            "Epoch 581/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0113 - mae: 0.0830 - val_loss: 0.0096 - val_mae: 0.0821\n",
            "Epoch 582/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 583/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0106 - mae: 0.0810 - val_loss: 0.0093 - val_mae: 0.0812\n",
            "Epoch 584/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0101 - mae: 0.0791 - val_loss: 0.0097 - val_mae: 0.0826\n",
            "Epoch 585/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0099 - mae: 0.0794 - val_loss: 0.0109 - val_mae: 0.0874\n",
            "Epoch 586/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0119 - mae: 0.0847 - val_loss: 0.0115 - val_mae: 0.0896\n",
            "Epoch 587/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0104 - mae: 0.0817 - val_loss: 0.0101 - val_mae: 0.0841\n",
            "Epoch 588/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0105 - mae: 0.0808 - val_loss: 0.0115 - val_mae: 0.0896\n",
            "Epoch 589/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0103 - mae: 0.0805 - val_loss: 0.0097 - val_mae: 0.0826\n",
            "Epoch 590/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0105 - mae: 0.0794 - val_loss: 0.0099 - val_mae: 0.0825\n",
            "Epoch 591/600\n",
            "150/150 [==============================] - 0s 268us/sample - loss: 0.0108 - mae: 0.0821 - val_loss: 0.0100 - val_mae: 0.0841\n",
            "Epoch 592/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0102 - mae: 0.0790 - val_loss: 0.0102 - val_mae: 0.0852\n",
            "Epoch 593/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0096 - val_mae: 0.0817\n",
            "Epoch 594/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0102 - mae: 0.0802 - val_loss: 0.0103 - val_mae: 0.0843\n",
            "Epoch 595/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0160 - val_mae: 0.1021\n",
            "Epoch 596/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0115 - mae: 0.0856 - val_loss: 0.0110 - val_mae: 0.0881\n",
            "Epoch 597/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0097 - val_mae: 0.0825\n",
            "Epoch 598/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0101 - mae: 0.0801 - val_loss: 0.0108 - val_mae: 0.0871\n",
            "Epoch 599/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0103 - mae: 0.0800 - val_loss: 0.0107 - val_mae: 0.0868\n",
            "Epoch 600/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0110 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0874\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ev5yRMi6Kf9k",
        "outputId": "604aec17-96f5-4fd4-9589-411ecd338fff"
      },
      "source": [
        "#Toy Problem Y=sin(x) 250 samples of period 0 to pi\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 250\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=0, high=math.pi,size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "#plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_2.summary()\n",
        "history_2 = model_2.fit(x_train, y_train, epochs=600, batch_size=16, validation_data=(x_validate, y_validate))\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_2.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_51 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 150 samples, validate on 50 samples\n",
            "Epoch 1/600\n",
            "150/150 [==============================] - 0s 1ms/sample - loss: 0.4463 - mae: 0.4357 - val_loss: 0.3047 - val_mae: 0.4034\n",
            "Epoch 2/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.3034 - mae: 0.4056 - val_loss: 0.2455 - val_mae: 0.3965\n",
            "Epoch 3/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.2545 - mae: 0.3953 - val_loss: 0.2198 - val_mae: 0.3869\n",
            "Epoch 4/600\n",
            "150/150 [==============================] - 0s 107us/sample - loss: 0.2310 - mae: 0.3879 - val_loss: 0.2044 - val_mae: 0.3775\n",
            "Epoch 5/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.2134 - mae: 0.3738 - val_loss: 0.1909 - val_mae: 0.3695\n",
            "Epoch 6/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.2004 - mae: 0.3669 - val_loss: 0.1806 - val_mae: 0.3609\n",
            "Epoch 7/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.1874 - mae: 0.3542 - val_loss: 0.1722 - val_mae: 0.3555\n",
            "Epoch 8/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.1764 - mae: 0.3506 - val_loss: 0.1632 - val_mae: 0.3429\n",
            "Epoch 9/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.1677 - mae: 0.3352 - val_loss: 0.1561 - val_mae: 0.3345\n",
            "Epoch 10/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.1591 - mae: 0.3236 - val_loss: 0.1490 - val_mae: 0.3294\n",
            "Epoch 11/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1517 - mae: 0.3168 - val_loss: 0.1427 - val_mae: 0.3216\n",
            "Epoch 12/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.1439 - mae: 0.3068 - val_loss: 0.1365 - val_mae: 0.3149\n",
            "Epoch 13/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1380 - mae: 0.2990 - val_loss: 0.1324 - val_mae: 0.3109\n",
            "Epoch 14/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.1318 - mae: 0.2938 - val_loss: 0.1270 - val_mae: 0.3037\n",
            "Epoch 15/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.1273 - mae: 0.2841 - val_loss: 0.1227 - val_mae: 0.2990\n",
            "Epoch 16/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.1229 - mae: 0.2803 - val_loss: 0.1185 - val_mae: 0.2933\n",
            "Epoch 17/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1191 - mae: 0.2745 - val_loss: 0.1155 - val_mae: 0.2899\n",
            "Epoch 18/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.1142 - mae: 0.2723 - val_loss: 0.1117 - val_mae: 0.2847\n",
            "Epoch 19/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.1097 - mae: 0.2649 - val_loss: 0.1075 - val_mae: 0.2787\n",
            "Epoch 20/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.1075 - mae: 0.2616 - val_loss: 0.1039 - val_mae: 0.2735\n",
            "Epoch 21/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.1018 - mae: 0.2537 - val_loss: 0.1003 - val_mae: 0.2677\n",
            "Epoch 22/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0993 - mae: 0.2498 - val_loss: 0.0988 - val_mae: 0.2650\n",
            "Epoch 23/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0959 - mae: 0.2470 - val_loss: 0.0978 - val_mae: 0.2642\n",
            "Epoch 24/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0941 - mae: 0.2479 - val_loss: 0.0928 - val_mae: 0.2566\n",
            "Epoch 25/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0911 - mae: 0.2389 - val_loss: 0.0900 - val_mae: 0.2522\n",
            "Epoch 26/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0880 - mae: 0.2334 - val_loss: 0.0901 - val_mae: 0.2524\n",
            "Epoch 27/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0859 - mae: 0.2356 - val_loss: 0.0871 - val_mae: 0.2481\n",
            "Epoch 28/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0835 - mae: 0.2301 - val_loss: 0.0839 - val_mae: 0.2432\n",
            "Epoch 29/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0810 - mae: 0.2275 - val_loss: 0.0801 - val_mae: 0.2361\n",
            "Epoch 30/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0788 - mae: 0.2172 - val_loss: 0.0809 - val_mae: 0.2377\n",
            "Epoch 31/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0767 - mae: 0.2190 - val_loss: 0.0772 - val_mae: 0.2321\n",
            "Epoch 32/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0751 - mae: 0.2179 - val_loss: 0.0733 - val_mae: 0.2248\n",
            "Epoch 33/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0724 - mae: 0.2103 - val_loss: 0.0709 - val_mae: 0.2207\n",
            "Epoch 34/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0712 - mae: 0.2074 - val_loss: 0.0699 - val_mae: 0.2191\n",
            "Epoch 35/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0679 - mae: 0.2062 - val_loss: 0.0677 - val_mae: 0.2151\n",
            "Epoch 36/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0663 - mae: 0.2016 - val_loss: 0.0652 - val_mae: 0.2103\n",
            "Epoch 37/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0643 - mae: 0.1964 - val_loss: 0.0636 - val_mae: 0.2072\n",
            "Epoch 38/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0633 - mae: 0.1964 - val_loss: 0.0609 - val_mae: 0.2014\n",
            "Epoch 39/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0607 - mae: 0.1922 - val_loss: 0.0595 - val_mae: 0.1975\n",
            "Epoch 40/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0599 - mae: 0.1874 - val_loss: 0.0574 - val_mae: 0.1945\n",
            "Epoch 41/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0577 - mae: 0.1861 - val_loss: 0.0560 - val_mae: 0.1922\n",
            "Epoch 42/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0564 - mae: 0.1837 - val_loss: 0.0555 - val_mae: 0.1902\n",
            "Epoch 43/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0542 - mae: 0.1828 - val_loss: 0.0521 - val_mae: 0.1842\n",
            "Epoch 44/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0519 - mae: 0.1743 - val_loss: 0.0512 - val_mae: 0.1821\n",
            "Epoch 45/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0509 - mae: 0.1749 - val_loss: 0.0489 - val_mae: 0.1779\n",
            "Epoch 46/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0500 - mae: 0.1734 - val_loss: 0.0475 - val_mae: 0.1737\n",
            "Epoch 47/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0491 - mae: 0.1668 - val_loss: 0.0465 - val_mae: 0.1722\n",
            "Epoch 48/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0472 - mae: 0.1667 - val_loss: 0.0440 - val_mae: 0.1669\n",
            "Epoch 49/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0450 - mae: 0.1630 - val_loss: 0.0436 - val_mae: 0.1646\n",
            "Epoch 50/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0444 - mae: 0.1572 - val_loss: 0.0429 - val_mae: 0.1644\n",
            "Epoch 51/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0429 - mae: 0.1608 - val_loss: 0.0403 - val_mae: 0.1578\n",
            "Epoch 52/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0433 - mae: 0.1567 - val_loss: 0.0388 - val_mae: 0.1539\n",
            "Epoch 53/600\n",
            "150/150 [==============================] - 0s 116us/sample - loss: 0.0413 - mae: 0.1541 - val_loss: 0.0381 - val_mae: 0.1526\n",
            "Epoch 54/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0396 - mae: 0.1525 - val_loss: 0.0372 - val_mae: 0.1503\n",
            "Epoch 55/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0388 - mae: 0.1489 - val_loss: 0.0362 - val_mae: 0.1478\n",
            "Epoch 56/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0376 - mae: 0.1487 - val_loss: 0.0346 - val_mae: 0.1440\n",
            "Epoch 57/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0361 - mae: 0.1465 - val_loss: 0.0334 - val_mae: 0.1410\n",
            "Epoch 58/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0351 - mae: 0.1413 - val_loss: 0.0350 - val_mae: 0.1533\n",
            "Epoch 59/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0354 - mae: 0.1459 - val_loss: 0.0310 - val_mae: 0.1357\n",
            "Epoch 60/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0333 - mae: 0.1395 - val_loss: 0.0305 - val_mae: 0.1350\n",
            "Epoch 61/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0335 - mae: 0.1384 - val_loss: 0.0298 - val_mae: 0.1339\n",
            "Epoch 62/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0315 - mae: 0.1372 - val_loss: 0.0289 - val_mae: 0.1296\n",
            "Epoch 63/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0315 - mae: 0.1366 - val_loss: 0.0277 - val_mae: 0.1254\n",
            "Epoch 64/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0308 - mae: 0.1339 - val_loss: 0.0268 - val_mae: 0.1237\n",
            "Epoch 65/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0294 - mae: 0.1316 - val_loss: 0.0260 - val_mae: 0.1225\n",
            "Epoch 66/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0290 - mae: 0.1311 - val_loss: 0.0254 - val_mae: 0.1215\n",
            "Epoch 67/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.0284 - mae: 0.1303 - val_loss: 0.0253 - val_mae: 0.1222\n",
            "Epoch 68/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.0276 - mae: 0.1291 - val_loss: 0.0264 - val_mae: 0.1324\n",
            "Epoch 69/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0268 - mae: 0.1276 - val_loss: 0.0271 - val_mae: 0.1359\n",
            "Epoch 70/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0267 - mae: 0.1281 - val_loss: 0.0249 - val_mae: 0.1284\n",
            "Epoch 71/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0259 - mae: 0.1264 - val_loss: 0.0233 - val_mae: 0.1123\n",
            "Epoch 72/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0254 - mae: 0.1233 - val_loss: 0.0226 - val_mae: 0.1189\n",
            "Epoch 73/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0246 - mae: 0.1214 - val_loss: 0.0212 - val_mae: 0.1090\n",
            "Epoch 74/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0235 - mae: 0.1176 - val_loss: 0.0214 - val_mae: 0.1154\n",
            "Epoch 75/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0225 - mae: 0.1179 - val_loss: 0.0244 - val_mae: 0.1140\n",
            "Epoch 76/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0232 - mae: 0.1173 - val_loss: 0.0206 - val_mae: 0.1068\n",
            "Epoch 77/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.0227 - mae: 0.1167 - val_loss: 0.0201 - val_mae: 0.1116\n",
            "Epoch 78/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0220 - mae: 0.1159 - val_loss: 0.0197 - val_mae: 0.1045\n",
            "Epoch 79/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0207 - mae: 0.1103 - val_loss: 0.0194 - val_mae: 0.1078\n",
            "Epoch 80/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0210 - mae: 0.1118 - val_loss: 0.0202 - val_mae: 0.1138\n",
            "Epoch 81/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0205 - mae: 0.1109 - val_loss: 0.0197 - val_mae: 0.1128\n",
            "Epoch 82/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0201 - mae: 0.1102 - val_loss: 0.0193 - val_mae: 0.1057\n",
            "Epoch 83/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0203 - mae: 0.1091 - val_loss: 0.0185 - val_mae: 0.1063\n",
            "Epoch 84/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0188 - mae: 0.1044 - val_loss: 0.0205 - val_mae: 0.1169\n",
            "Epoch 85/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0197 - mae: 0.1097 - val_loss: 0.0181 - val_mae: 0.1025\n",
            "Epoch 86/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0188 - mae: 0.1064 - val_loss: 0.0179 - val_mae: 0.1053\n",
            "Epoch 87/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0191 - mae: 0.1077 - val_loss: 0.0188 - val_mae: 0.1108\n",
            "Epoch 88/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0185 - mae: 0.1061 - val_loss: 0.0195 - val_mae: 0.1135\n",
            "Epoch 89/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0178 - mae: 0.1053 - val_loss: 0.0173 - val_mae: 0.1037\n",
            "Epoch 90/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0178 - mae: 0.1029 - val_loss: 0.0189 - val_mae: 0.1114\n",
            "Epoch 91/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0180 - mae: 0.1044 - val_loss: 0.0170 - val_mae: 0.1025\n",
            "Epoch 92/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0171 - mae: 0.1025 - val_loss: 0.0157 - val_mae: 0.0970\n",
            "Epoch 93/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0171 - mae: 0.1013 - val_loss: 0.0195 - val_mae: 0.1133\n",
            "Epoch 94/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0173 - mae: 0.1030 - val_loss: 0.0193 - val_mae: 0.1127\n",
            "Epoch 95/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0170 - mae: 0.1024 - val_loss: 0.0163 - val_mae: 0.1005\n",
            "Epoch 96/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0153 - val_mae: 0.0955\n",
            "Epoch 97/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0171 - mae: 0.1018 - val_loss: 0.0152 - val_mae: 0.0967\n",
            "Epoch 98/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0161 - mae: 0.0983 - val_loss: 0.0150 - val_mae: 0.0970\n",
            "Epoch 99/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0159 - mae: 0.0999 - val_loss: 0.0149 - val_mae: 0.0960\n",
            "Epoch 100/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0161 - mae: 0.0997 - val_loss: 0.0173 - val_mae: 0.1063\n",
            "Epoch 101/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0160 - mae: 0.0984 - val_loss: 0.0145 - val_mae: 0.0951\n",
            "Epoch 102/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0161 - mae: 0.0997 - val_loss: 0.0152 - val_mae: 0.0984\n",
            "Epoch 103/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0154 - mae: 0.0976 - val_loss: 0.0178 - val_mae: 0.1085\n",
            "Epoch 104/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0158 - mae: 0.0984 - val_loss: 0.0150 - val_mae: 0.0978\n",
            "Epoch 105/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0154 - mae: 0.0975 - val_loss: 0.0139 - val_mae: 0.0937\n",
            "Epoch 106/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0152 - mae: 0.0965 - val_loss: 0.0139 - val_mae: 0.0934\n",
            "Epoch 107/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0154 - mae: 0.0966 - val_loss: 0.0143 - val_mae: 0.0955\n",
            "Epoch 108/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0151 - mae: 0.0966 - val_loss: 0.0136 - val_mae: 0.0929\n",
            "Epoch 109/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.0148 - mae: 0.0962 - val_loss: 0.0159 - val_mae: 0.1008\n",
            "Epoch 110/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0155 - mae: 0.0986 - val_loss: 0.0138 - val_mae: 0.0939\n",
            "Epoch 111/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0148 - mae: 0.0956 - val_loss: 0.0138 - val_mae: 0.0935\n",
            "Epoch 112/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0145 - mae: 0.0941 - val_loss: 0.0138 - val_mae: 0.0943\n",
            "Epoch 113/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.0150 - mae: 0.0960 - val_loss: 0.0137 - val_mae: 0.0928\n",
            "Epoch 114/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0144 - mae: 0.0939 - val_loss: 0.0137 - val_mae: 0.0940\n",
            "Epoch 115/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0143 - mae: 0.0932 - val_loss: 0.0132 - val_mae: 0.0922\n",
            "Epoch 116/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0141 - mae: 0.0934 - val_loss: 0.0135 - val_mae: 0.0932\n",
            "Epoch 117/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0147 - mae: 0.0953 - val_loss: 0.0135 - val_mae: 0.0933\n",
            "Epoch 118/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0138 - mae: 0.0920 - val_loss: 0.0134 - val_mae: 0.0926\n",
            "Epoch 119/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0143 - mae: 0.0942 - val_loss: 0.0129 - val_mae: 0.0913\n",
            "Epoch 120/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0140 - mae: 0.0922 - val_loss: 0.0135 - val_mae: 0.0928\n",
            "Epoch 121/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0138 - mae: 0.0920 - val_loss: 0.0147 - val_mae: 0.0979\n",
            "Epoch 122/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0139 - mae: 0.0932 - val_loss: 0.0156 - val_mae: 0.0997\n",
            "Epoch 123/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0146 - mae: 0.0957 - val_loss: 0.0141 - val_mae: 0.0960\n",
            "Epoch 124/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0134 - mae: 0.0920 - val_loss: 0.0143 - val_mae: 0.0968\n",
            "Epoch 125/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0135 - mae: 0.0915 - val_loss: 0.0127 - val_mae: 0.0918\n",
            "Epoch 126/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0133 - mae: 0.0911 - val_loss: 0.0141 - val_mae: 0.0954\n",
            "Epoch 127/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0130 - mae: 0.0897 - val_loss: 0.0161 - val_mae: 0.1027\n",
            "Epoch 128/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0133 - mae: 0.0907 - val_loss: 0.0144 - val_mae: 0.0966\n",
            "Epoch 129/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0132 - mae: 0.0890 - val_loss: 0.0136 - val_mae: 0.0951\n",
            "Epoch 130/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0128 - mae: 0.0887 - val_loss: 0.0129 - val_mae: 0.0933\n",
            "Epoch 131/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0134 - mae: 0.0911 - val_loss: 0.0129 - val_mae: 0.0924\n",
            "Epoch 132/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0127 - mae: 0.0880 - val_loss: 0.0135 - val_mae: 0.0954\n",
            "Epoch 133/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0126 - mae: 0.0879 - val_loss: 0.0135 - val_mae: 0.0948\n",
            "Epoch 134/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0130 - mae: 0.0894 - val_loss: 0.0141 - val_mae: 0.0970\n",
            "Epoch 135/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0127 - mae: 0.0875 - val_loss: 0.0158 - val_mae: 0.1026\n",
            "Epoch 136/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0130 - mae: 0.0889 - val_loss: 0.0127 - val_mae: 0.0923\n",
            "Epoch 137/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0125 - mae: 0.0874 - val_loss: 0.0142 - val_mae: 0.0967\n",
            "Epoch 138/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0127 - mae: 0.0870 - val_loss: 0.0155 - val_mae: 0.1001\n",
            "Epoch 139/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0129 - mae: 0.0887 - val_loss: 0.0134 - val_mae: 0.0953\n",
            "Epoch 140/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0124 - mae: 0.0880 - val_loss: 0.0123 - val_mae: 0.0903\n",
            "Epoch 141/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0121 - mae: 0.0860 - val_loss: 0.0183 - val_mae: 0.1081\n",
            "Epoch 142/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0131 - mae: 0.0895 - val_loss: 0.0128 - val_mae: 0.0933\n",
            "Epoch 143/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0126 - mae: 0.0884 - val_loss: 0.0128 - val_mae: 0.0930\n",
            "Epoch 144/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0118 - mae: 0.0850 - val_loss: 0.0133 - val_mae: 0.0951\n",
            "Epoch 145/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0123 - mae: 0.0876 - val_loss: 0.0125 - val_mae: 0.0915\n",
            "Epoch 146/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0124 - mae: 0.0895 - val_loss: 0.0118 - val_mae: 0.0908\n",
            "Epoch 147/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0119 - mae: 0.0850 - val_loss: 0.0127 - val_mae: 0.0926\n",
            "Epoch 148/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0123 - mae: 0.0874 - val_loss: 0.0119 - val_mae: 0.0902\n",
            "Epoch 149/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0128 - mae: 0.0889 - val_loss: 0.0124 - val_mae: 0.0926\n",
            "Epoch 150/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0120 - mae: 0.0863 - val_loss: 0.0129 - val_mae: 0.0931\n",
            "Epoch 151/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0117 - mae: 0.0847 - val_loss: 0.0139 - val_mae: 0.0971\n",
            "Epoch 152/600\n",
            "150/150 [==============================] - 0s 208us/sample - loss: 0.0122 - mae: 0.0856 - val_loss: 0.0120 - val_mae: 0.0914\n",
            "Epoch 153/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0116 - mae: 0.0841 - val_loss: 0.0124 - val_mae: 0.0917\n",
            "Epoch 154/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0116 - mae: 0.0847 - val_loss: 0.0135 - val_mae: 0.0957\n",
            "Epoch 155/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0121 - mae: 0.0865 - val_loss: 0.0135 - val_mae: 0.0953\n",
            "Epoch 156/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0117 - mae: 0.0843 - val_loss: 0.0128 - val_mae: 0.0939\n",
            "Epoch 157/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0120 - mae: 0.0857 - val_loss: 0.0131 - val_mae: 0.0945\n",
            "Epoch 158/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0121 - mae: 0.0866 - val_loss: 0.0120 - val_mae: 0.0915\n",
            "Epoch 159/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0117 - mae: 0.0847 - val_loss: 0.0124 - val_mae: 0.0921\n",
            "Epoch 160/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0118 - mae: 0.0845 - val_loss: 0.0119 - val_mae: 0.0899\n",
            "Epoch 161/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0121 - mae: 0.0880 - val_loss: 0.0121 - val_mae: 0.0901\n",
            "Epoch 162/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0117 - mae: 0.0849 - val_loss: 0.0128 - val_mae: 0.0918\n",
            "Epoch 163/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0116 - mae: 0.0844 - val_loss: 0.0127 - val_mae: 0.0927\n",
            "Epoch 164/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0117 - mae: 0.0843 - val_loss: 0.0115 - val_mae: 0.0885\n",
            "Epoch 165/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0114 - mae: 0.0834 - val_loss: 0.0115 - val_mae: 0.0897\n",
            "Epoch 166/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0118 - val_mae: 0.0892\n",
            "Epoch 167/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0113 - mae: 0.0832 - val_loss: 0.0137 - val_mae: 0.0964\n",
            "Epoch 168/600\n",
            "150/150 [==============================] - 0s 227us/sample - loss: 0.0119 - mae: 0.0854 - val_loss: 0.0125 - val_mae: 0.0930\n",
            "Epoch 169/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0116 - val_mae: 0.0898\n",
            "Epoch 170/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0115 - val_mae: 0.0894\n",
            "Epoch 171/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0114 - mae: 0.0834 - val_loss: 0.0112 - val_mae: 0.0879\n",
            "Epoch 172/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0115 - mae: 0.0835 - val_loss: 0.0112 - val_mae: 0.0870\n",
            "Epoch 173/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0115 - mae: 0.0836 - val_loss: 0.0119 - val_mae: 0.0894\n",
            "Epoch 174/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0115 - mae: 0.0843 - val_loss: 0.0149 - val_mae: 0.0973\n",
            "Epoch 175/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0115 - mae: 0.0858 - val_loss: 0.0111 - val_mae: 0.0870\n",
            "Epoch 176/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0111 - mae: 0.0822 - val_loss: 0.0137 - val_mae: 0.0965\n",
            "Epoch 177/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0115 - mae: 0.0852 - val_loss: 0.0142 - val_mae: 0.0984\n",
            "Epoch 178/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0116 - mae: 0.0842 - val_loss: 0.0129 - val_mae: 0.0941\n",
            "Epoch 179/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0113 - mae: 0.0847 - val_loss: 0.0130 - val_mae: 0.0946\n",
            "Epoch 180/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0113 - mae: 0.0847 - val_loss: 0.0151 - val_mae: 0.1012\n",
            "Epoch 181/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0117 - mae: 0.0853 - val_loss: 0.0115 - val_mae: 0.0896\n",
            "Epoch 182/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0113 - mae: 0.0836 - val_loss: 0.0119 - val_mae: 0.0910\n",
            "Epoch 183/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0131 - val_mae: 0.0926\n",
            "Epoch 184/600\n",
            "150/150 [==============================] - 0s 229us/sample - loss: 0.0114 - mae: 0.0835 - val_loss: 0.0124 - val_mae: 0.0928\n",
            "Epoch 185/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0115 - val_mae: 0.0882\n",
            "Epoch 186/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0116 - mae: 0.0827 - val_loss: 0.0113 - val_mae: 0.0875\n",
            "Epoch 187/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.0113 - mae: 0.0836 - val_loss: 0.0107 - val_mae: 0.0859\n",
            "Epoch 188/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0111 - mae: 0.0814 - val_loss: 0.0129 - val_mae: 0.0932\n",
            "Epoch 189/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0115 - mae: 0.0850 - val_loss: 0.0127 - val_mae: 0.0909\n",
            "Epoch 190/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0114 - mae: 0.0828 - val_loss: 0.0122 - val_mae: 0.0911\n",
            "Epoch 191/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0112 - mae: 0.0836 - val_loss: 0.0108 - val_mae: 0.0865\n",
            "Epoch 192/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0110 - mae: 0.0797 - val_loss: 0.0127 - val_mae: 0.0931\n",
            "Epoch 193/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0117 - mae: 0.0851 - val_loss: 0.0107 - val_mae: 0.0865\n",
            "Epoch 194/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0117 - mae: 0.0837 - val_loss: 0.0109 - val_mae: 0.0865\n",
            "Epoch 195/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0114 - mae: 0.0848 - val_loss: 0.0119 - val_mae: 0.0889\n",
            "Epoch 196/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0113 - mae: 0.0836 - val_loss: 0.0118 - val_mae: 0.0908\n",
            "Epoch 197/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0111 - mae: 0.0818 - val_loss: 0.0140 - val_mae: 0.0966\n",
            "Epoch 198/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0110 - mae: 0.0817 - val_loss: 0.0121 - val_mae: 0.0896\n",
            "Epoch 199/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0108 - mae: 0.0818 - val_loss: 0.0133 - val_mae: 0.0921\n",
            "Epoch 200/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0112 - mae: 0.0835 - val_loss: 0.0114 - val_mae: 0.0881\n",
            "Epoch 201/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0109 - mae: 0.0821 - val_loss: 0.0109 - val_mae: 0.0874\n",
            "Epoch 202/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0116 - mae: 0.0844 - val_loss: 0.0109 - val_mae: 0.0864\n",
            "Epoch 203/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0115 - val_mae: 0.0898\n",
            "Epoch 204/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0120 - val_mae: 0.0898\n",
            "Epoch 205/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0107 - val_mae: 0.0865\n",
            "Epoch 206/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0108 - mae: 0.0811 - val_loss: 0.0173 - val_mae: 0.1064\n",
            "Epoch 207/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0112 - mae: 0.0820 - val_loss: 0.0127 - val_mae: 0.0928\n",
            "Epoch 208/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0109 - mae: 0.0817 - val_loss: 0.0112 - val_mae: 0.0877\n",
            "Epoch 209/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0109 - mae: 0.0809 - val_loss: 0.0112 - val_mae: 0.0882\n",
            "Epoch 210/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0126 - val_mae: 0.0910\n",
            "Epoch 211/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0109 - mae: 0.0832 - val_loss: 0.0124 - val_mae: 0.0919\n",
            "Epoch 212/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0109 - mae: 0.0820 - val_loss: 0.0111 - val_mae: 0.0870\n",
            "Epoch 213/600\n",
            "150/150 [==============================] - 0s 249us/sample - loss: 0.0108 - mae: 0.0823 - val_loss: 0.0133 - val_mae: 0.0944\n",
            "Epoch 214/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0115 - mae: 0.0826 - val_loss: 0.0119 - val_mae: 0.0901\n",
            "Epoch 215/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0106 - mae: 0.0809 - val_loss: 0.0127 - val_mae: 0.0941\n",
            "Epoch 216/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0112 - mae: 0.0826 - val_loss: 0.0114 - val_mae: 0.0885\n",
            "Epoch 217/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0112 - mae: 0.0833 - val_loss: 0.0127 - val_mae: 0.0923\n",
            "Epoch 218/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0107 - mae: 0.0827 - val_loss: 0.0119 - val_mae: 0.0903\n",
            "Epoch 219/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0109 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0875\n",
            "Epoch 220/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0109 - mae: 0.0813 - val_loss: 0.0125 - val_mae: 0.0928\n",
            "Epoch 221/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0112 - val_mae: 0.0893\n",
            "Epoch 222/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0113 - mae: 0.0841 - val_loss: 0.0111 - val_mae: 0.0888\n",
            "Epoch 223/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0128 - val_mae: 0.0925\n",
            "Epoch 224/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0109 - mae: 0.0824 - val_loss: 0.0116 - val_mae: 0.0886\n",
            "Epoch 225/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0135 - val_mae: 0.0935\n",
            "Epoch 226/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0109 - mae: 0.0819 - val_loss: 0.0121 - val_mae: 0.0893\n",
            "Epoch 227/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0106 - mae: 0.0816 - val_loss: 0.0113 - val_mae: 0.0876\n",
            "Epoch 228/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0109 - mae: 0.0811 - val_loss: 0.0116 - val_mae: 0.0891\n",
            "Epoch 229/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0108 - mae: 0.0819 - val_loss: 0.0116 - val_mae: 0.0886\n",
            "Epoch 230/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0106 - mae: 0.0812 - val_loss: 0.0129 - val_mae: 0.0913\n",
            "Epoch 231/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0113 - mae: 0.0817 - val_loss: 0.0150 - val_mae: 0.0988\n",
            "Epoch 232/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0111 - mae: 0.0832 - val_loss: 0.0137 - val_mae: 0.0944\n",
            "Epoch 233/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0103 - mae: 0.0788 - val_loss: 0.0104 - val_mae: 0.0861\n",
            "Epoch 234/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0109 - mae: 0.0826 - val_loss: 0.0126 - val_mae: 0.0917\n",
            "Epoch 235/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0114 - val_mae: 0.0888\n",
            "Epoch 236/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0103 - mae: 0.0782 - val_loss: 0.0139 - val_mae: 0.0976\n",
            "Epoch 237/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0111 - val_mae: 0.0871\n",
            "Epoch 238/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0108 - mae: 0.0831 - val_loss: 0.0122 - val_mae: 0.0912\n",
            "Epoch 239/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0110 - mae: 0.0838 - val_loss: 0.0119 - val_mae: 0.0889\n",
            "Epoch 240/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0108 - mae: 0.0826 - val_loss: 0.0115 - val_mae: 0.0885\n",
            "Epoch 241/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0103 - mae: 0.0791 - val_loss: 0.0145 - val_mae: 0.0965\n",
            "Epoch 242/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0113 - mae: 0.0836 - val_loss: 0.0108 - val_mae: 0.0862\n",
            "Epoch 243/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0109 - mae: 0.0831 - val_loss: 0.0108 - val_mae: 0.0857\n",
            "Epoch 244/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0105 - mae: 0.0823 - val_loss: 0.0106 - val_mae: 0.0865\n",
            "Epoch 245/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.0113 - mae: 0.0833 - val_loss: 0.0107 - val_mae: 0.0867\n",
            "Epoch 246/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0103 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0862\n",
            "Epoch 247/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0118 - val_mae: 0.0899\n",
            "Epoch 248/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0106 - mae: 0.0823 - val_loss: 0.0105 - val_mae: 0.0850\n",
            "Epoch 249/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0106 - val_mae: 0.0854\n",
            "Epoch 250/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0107 - mae: 0.0818 - val_loss: 0.0136 - val_mae: 0.0939\n",
            "Epoch 251/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0104 - mae: 0.0813 - val_loss: 0.0133 - val_mae: 0.0933\n",
            "Epoch 252/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0108 - mae: 0.0837 - val_loss: 0.0108 - val_mae: 0.0854\n",
            "Epoch 253/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0106 - mae: 0.0828 - val_loss: 0.0111 - val_mae: 0.0887\n",
            "Epoch 254/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0136 - val_mae: 0.0929\n",
            "Epoch 255/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0107 - mae: 0.0817 - val_loss: 0.0119 - val_mae: 0.0905\n",
            "Epoch 256/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0106 - mae: 0.0833 - val_loss: 0.0109 - val_mae: 0.0865\n",
            "Epoch 257/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0106 - mae: 0.0826 - val_loss: 0.0109 - val_mae: 0.0881\n",
            "Epoch 258/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0107 - mae: 0.0809 - val_loss: 0.0109 - val_mae: 0.0878\n",
            "Epoch 259/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0146 - val_mae: 0.0978\n",
            "Epoch 260/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0108 - mae: 0.0825 - val_loss: 0.0116 - val_mae: 0.0898\n",
            "Epoch 261/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0103 - mae: 0.0803 - val_loss: 0.0110 - val_mae: 0.0880\n",
            "Epoch 262/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0109 - mae: 0.0823 - val_loss: 0.0114 - val_mae: 0.0873\n",
            "Epoch 263/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0106 - mae: 0.0810 - val_loss: 0.0123 - val_mae: 0.0907\n",
            "Epoch 264/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0109 - mae: 0.0828 - val_loss: 0.0139 - val_mae: 0.0950\n",
            "Epoch 265/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0116 - val_mae: 0.0891\n",
            "Epoch 266/600\n",
            "150/150 [==============================] - 0s 255us/sample - loss: 0.0106 - mae: 0.0816 - val_loss: 0.0105 - val_mae: 0.0857\n",
            "Epoch 267/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0104 - mae: 0.0803 - val_loss: 0.0109 - val_mae: 0.0867\n",
            "Epoch 268/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0108 - mae: 0.0811 - val_loss: 0.0118 - val_mae: 0.0883\n",
            "Epoch 269/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0112 - mae: 0.0843 - val_loss: 0.0110 - val_mae: 0.0888\n",
            "Epoch 270/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0106 - mae: 0.0811 - val_loss: 0.0118 - val_mae: 0.0898\n",
            "Epoch 271/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0106 - mae: 0.0801 - val_loss: 0.0128 - val_mae: 0.0913\n",
            "Epoch 272/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0108 - mae: 0.0816 - val_loss: 0.0109 - val_mae: 0.0877\n",
            "Epoch 273/600\n",
            "150/150 [==============================] - 0s 236us/sample - loss: 0.0106 - mae: 0.0825 - val_loss: 0.0107 - val_mae: 0.0861\n",
            "Epoch 274/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0104 - mae: 0.0790 - val_loss: 0.0132 - val_mae: 0.0954\n",
            "Epoch 275/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0111 - mae: 0.0839 - val_loss: 0.0114 - val_mae: 0.0886\n",
            "Epoch 276/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0107 - mae: 0.0819 - val_loss: 0.0138 - val_mae: 0.0947\n",
            "Epoch 277/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0106 - mae: 0.0821 - val_loss: 0.0127 - val_mae: 0.0912\n",
            "Epoch 278/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0107 - mae: 0.0810 - val_loss: 0.0113 - val_mae: 0.0896\n",
            "Epoch 279/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0114 - mae: 0.0840 - val_loss: 0.0129 - val_mae: 0.0912\n",
            "Epoch 280/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0106 - val_mae: 0.0860\n",
            "Epoch 281/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0103 - mae: 0.0805 - val_loss: 0.0112 - val_mae: 0.0894\n",
            "Epoch 282/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0103 - mae: 0.0802 - val_loss: 0.0113 - val_mae: 0.0877\n",
            "Epoch 283/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0110 - mae: 0.0830 - val_loss: 0.0133 - val_mae: 0.0925\n",
            "Epoch 284/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0114 - val_mae: 0.0878\n",
            "Epoch 285/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0108 - val_mae: 0.0858\n",
            "Epoch 286/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0103 - mae: 0.0802 - val_loss: 0.0125 - val_mae: 0.0903\n",
            "Epoch 287/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0112 - mae: 0.0839 - val_loss: 0.0103 - val_mae: 0.0855\n",
            "Epoch 288/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0107 - mae: 0.0815 - val_loss: 0.0116 - val_mae: 0.0882\n",
            "Epoch 289/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0106 - mae: 0.0810 - val_loss: 0.0133 - val_mae: 0.0932\n",
            "Epoch 290/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0107 - mae: 0.0817 - val_loss: 0.0110 - val_mae: 0.0865\n",
            "Epoch 291/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0107 - mae: 0.0812 - val_loss: 0.0118 - val_mae: 0.0896\n",
            "Epoch 292/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0103 - mae: 0.0791 - val_loss: 0.0108 - val_mae: 0.0873\n",
            "Epoch 293/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0102 - mae: 0.0794 - val_loss: 0.0126 - val_mae: 0.0907\n",
            "Epoch 294/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0111 - mae: 0.0833 - val_loss: 0.0111 - val_mae: 0.0863\n",
            "Epoch 295/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0102 - mae: 0.0788 - val_loss: 0.0132 - val_mae: 0.0927\n",
            "Epoch 296/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0107 - mae: 0.0810 - val_loss: 0.0135 - val_mae: 0.0941\n",
            "Epoch 297/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0107 - mae: 0.0816 - val_loss: 0.0121 - val_mae: 0.0911\n",
            "Epoch 298/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0108 - mae: 0.0821 - val_loss: 0.0110 - val_mae: 0.0888\n",
            "Epoch 299/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0105 - mae: 0.0802 - val_loss: 0.0122 - val_mae: 0.0912\n",
            "Epoch 300/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0135 - val_mae: 0.0941\n",
            "Epoch 301/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0107 - val_mae: 0.0865\n",
            "Epoch 302/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0104 - mae: 0.0795 - val_loss: 0.0132 - val_mae: 0.0929\n",
            "Epoch 303/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0105 - mae: 0.0784 - val_loss: 0.0106 - val_mae: 0.0861\n",
            "Epoch 304/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0101 - mae: 0.0788 - val_loss: 0.0108 - val_mae: 0.0868\n",
            "Epoch 305/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0105 - mae: 0.0799 - val_loss: 0.0110 - val_mae: 0.0875\n",
            "Epoch 306/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0101 - mae: 0.0789 - val_loss: 0.0117 - val_mae: 0.0905\n",
            "Epoch 307/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0106 - mae: 0.0808 - val_loss: 0.0113 - val_mae: 0.0891\n",
            "Epoch 308/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0107 - mae: 0.0820 - val_loss: 0.0111 - val_mae: 0.0878\n",
            "Epoch 309/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0104 - mae: 0.0797 - val_loss: 0.0113 - val_mae: 0.0890\n",
            "Epoch 310/600\n",
            "150/150 [==============================] - 0s 208us/sample - loss: 0.0106 - mae: 0.0817 - val_loss: 0.0119 - val_mae: 0.0897\n",
            "Epoch 311/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0112 - val_mae: 0.0876\n",
            "Epoch 312/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0104 - mae: 0.0814 - val_loss: 0.0121 - val_mae: 0.0913\n",
            "Epoch 313/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0104 - mae: 0.0807 - val_loss: 0.0117 - val_mae: 0.0889\n",
            "Epoch 314/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0103 - mae: 0.0806 - val_loss: 0.0115 - val_mae: 0.0895\n",
            "Epoch 315/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0109 - mae: 0.0815 - val_loss: 0.0120 - val_mae: 0.0894\n",
            "Epoch 316/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0102 - mae: 0.0802 - val_loss: 0.0105 - val_mae: 0.0862\n",
            "Epoch 317/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0105 - mae: 0.0792 - val_loss: 0.0120 - val_mae: 0.0895\n",
            "Epoch 318/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0106 - mae: 0.0803 - val_loss: 0.0109 - val_mae: 0.0867\n",
            "Epoch 319/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0129 - val_mae: 0.0929\n",
            "Epoch 320/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0109 - mae: 0.0841 - val_loss: 0.0113 - val_mae: 0.0879\n",
            "Epoch 321/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0102 - mae: 0.0803 - val_loss: 0.0107 - val_mae: 0.0874\n",
            "Epoch 322/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0105 - mae: 0.0804 - val_loss: 0.0110 - val_mae: 0.0873\n",
            "Epoch 323/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0102 - mae: 0.0792 - val_loss: 0.0108 - val_mae: 0.0864\n",
            "Epoch 324/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0105 - mae: 0.0811 - val_loss: 0.0108 - val_mae: 0.0872\n",
            "Epoch 325/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0109 - mae: 0.0806 - val_loss: 0.0111 - val_mae: 0.0870\n",
            "Epoch 326/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0101 - mae: 0.0790 - val_loss: 0.0133 - val_mae: 0.0938\n",
            "Epoch 327/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0113 - val_mae: 0.0897\n",
            "Epoch 328/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0109 - val_mae: 0.0871\n",
            "Epoch 329/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0106 - mae: 0.0804 - val_loss: 0.0125 - val_mae: 0.0915\n",
            "Epoch 330/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0106 - mae: 0.0800 - val_loss: 0.0124 - val_mae: 0.0926\n",
            "Epoch 331/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0105 - mae: 0.0817 - val_loss: 0.0105 - val_mae: 0.0854\n",
            "Epoch 332/600\n",
            "150/150 [==============================] - 0s 265us/sample - loss: 0.0100 - mae: 0.0807 - val_loss: 0.0122 - val_mae: 0.0922\n",
            "Epoch 333/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0108 - val_mae: 0.0872\n",
            "Epoch 334/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0101 - mae: 0.0799 - val_loss: 0.0153 - val_mae: 0.1009\n",
            "Epoch 335/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0144 - val_mae: 0.0990\n",
            "Epoch 336/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0105 - mae: 0.0829 - val_loss: 0.0105 - val_mae: 0.0856\n",
            "Epoch 337/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0103 - mae: 0.0804 - val_loss: 0.0125 - val_mae: 0.0904\n",
            "Epoch 338/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0101 - mae: 0.0788 - val_loss: 0.0148 - val_mae: 0.0988\n",
            "Epoch 339/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0105 - mae: 0.0825 - val_loss: 0.0118 - val_mae: 0.0901\n",
            "Epoch 340/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0107 - mae: 0.0834 - val_loss: 0.0118 - val_mae: 0.0900\n",
            "Epoch 341/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0102 - mae: 0.0807 - val_loss: 0.0138 - val_mae: 0.0951\n",
            "Epoch 342/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0104 - mae: 0.0806 - val_loss: 0.0121 - val_mae: 0.0900\n",
            "Epoch 343/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0103 - mae: 0.0807 - val_loss: 0.0110 - val_mae: 0.0873\n",
            "Epoch 344/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0105 - mae: 0.0823 - val_loss: 0.0109 - val_mae: 0.0867\n",
            "Epoch 345/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.0105 - mae: 0.0806 - val_loss: 0.0116 - val_mae: 0.0886\n",
            "Epoch 346/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0106 - mae: 0.0814 - val_loss: 0.0108 - val_mae: 0.0879\n",
            "Epoch 347/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0105 - mae: 0.0801 - val_loss: 0.0108 - val_mae: 0.0861\n",
            "Epoch 348/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0105 - mae: 0.0816 - val_loss: 0.0120 - val_mae: 0.0905\n",
            "Epoch 349/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0107 - mae: 0.0827 - val_loss: 0.0116 - val_mae: 0.0900\n",
            "Epoch 350/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0105 - mae: 0.0816 - val_loss: 0.0115 - val_mae: 0.0885\n",
            "Epoch 351/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0103 - mae: 0.0815 - val_loss: 0.0115 - val_mae: 0.0889\n",
            "Epoch 352/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0105 - mae: 0.0821 - val_loss: 0.0112 - val_mae: 0.0871\n",
            "Epoch 353/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0108 - val_mae: 0.0875\n",
            "Epoch 354/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.0107 - mae: 0.0804 - val_loss: 0.0106 - val_mae: 0.0854\n",
            "Epoch 355/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0100 - mae: 0.0776 - val_loss: 0.0115 - val_mae: 0.0899\n",
            "Epoch 356/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.0105 - mae: 0.0805 - val_loss: 0.0112 - val_mae: 0.0868\n",
            "Epoch 357/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0100 - mae: 0.0806 - val_loss: 0.0109 - val_mae: 0.0861\n",
            "Epoch 358/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0142 - val_mae: 0.0965\n",
            "Epoch 359/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0109 - mae: 0.0814 - val_loss: 0.0121 - val_mae: 0.0892\n",
            "Epoch 360/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0104 - mae: 0.0815 - val_loss: 0.0125 - val_mae: 0.0921\n",
            "Epoch 361/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0103 - mae: 0.0790 - val_loss: 0.0115 - val_mae: 0.0886\n",
            "Epoch 362/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0101 - mae: 0.0789 - val_loss: 0.0118 - val_mae: 0.0888\n",
            "Epoch 363/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0101 - mae: 0.0777 - val_loss: 0.0115 - val_mae: 0.0891\n",
            "Epoch 364/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0106 - mae: 0.0811 - val_loss: 0.0133 - val_mae: 0.0943\n",
            "Epoch 365/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0104 - mae: 0.0835 - val_loss: 0.0105 - val_mae: 0.0862\n",
            "Epoch 366/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0105 - mae: 0.0804 - val_loss: 0.0105 - val_mae: 0.0857\n",
            "Epoch 367/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0105 - mae: 0.0802 - val_loss: 0.0119 - val_mae: 0.0909\n",
            "Epoch 368/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0103 - mae: 0.0804 - val_loss: 0.0110 - val_mae: 0.0864\n",
            "Epoch 369/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0104 - mae: 0.0803 - val_loss: 0.0109 - val_mae: 0.0872\n",
            "Epoch 370/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0116 - val_mae: 0.0879\n",
            "Epoch 371/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0102 - mae: 0.0796 - val_loss: 0.0116 - val_mae: 0.0877\n",
            "Epoch 372/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0102 - mae: 0.0798 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 373/600\n",
            "150/150 [==============================] - 0s 247us/sample - loss: 0.0105 - mae: 0.0808 - val_loss: 0.0108 - val_mae: 0.0877\n",
            "Epoch 374/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0104 - mae: 0.0807 - val_loss: 0.0109 - val_mae: 0.0876\n",
            "Epoch 375/600\n",
            "150/150 [==============================] - 0s 241us/sample - loss: 0.0104 - mae: 0.0818 - val_loss: 0.0152 - val_mae: 0.0998\n",
            "Epoch 376/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0112 - mae: 0.0835 - val_loss: 0.0114 - val_mae: 0.0891\n",
            "Epoch 377/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0108 - mae: 0.0830 - val_loss: 0.0129 - val_mae: 0.0920\n",
            "Epoch 378/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0099 - mae: 0.0787 - val_loss: 0.0101 - val_mae: 0.0838\n",
            "Epoch 379/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0104 - mae: 0.0813 - val_loss: 0.0110 - val_mae: 0.0872\n",
            "Epoch 380/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0104 - mae: 0.0817 - val_loss: 0.0115 - val_mae: 0.0889\n",
            "Epoch 381/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0100 - mae: 0.0802 - val_loss: 0.0107 - val_mae: 0.0863\n",
            "Epoch 382/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0105 - mae: 0.0800 - val_loss: 0.0113 - val_mae: 0.0892\n",
            "Epoch 383/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0108 - val_mae: 0.0872\n",
            "Epoch 384/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0103 - mae: 0.0790 - val_loss: 0.0108 - val_mae: 0.0863\n",
            "Epoch 385/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0103 - mae: 0.0810 - val_loss: 0.0110 - val_mae: 0.0870\n",
            "Epoch 386/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0102 - mae: 0.0796 - val_loss: 0.0105 - val_mae: 0.0856\n",
            "Epoch 387/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0103 - mae: 0.0795 - val_loss: 0.0116 - val_mae: 0.0900\n",
            "Epoch 388/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0101 - mae: 0.0814 - val_loss: 0.0117 - val_mae: 0.0880\n",
            "Epoch 389/600\n",
            "150/150 [==============================] - 0s 217us/sample - loss: 0.0100 - mae: 0.0781 - val_loss: 0.0170 - val_mae: 0.1060\n",
            "Epoch 390/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0106 - mae: 0.0802 - val_loss: 0.0117 - val_mae: 0.0899\n",
            "Epoch 391/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0104 - mae: 0.0796 - val_loss: 0.0110 - val_mae: 0.0877\n",
            "Epoch 392/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0875\n",
            "Epoch 393/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0096 - mae: 0.0774 - val_loss: 0.0164 - val_mae: 0.1058\n",
            "Epoch 394/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0106 - mae: 0.0818 - val_loss: 0.0106 - val_mae: 0.0859\n",
            "Epoch 395/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0102 - mae: 0.0798 - val_loss: 0.0105 - val_mae: 0.0844\n",
            "Epoch 396/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0104 - mae: 0.0798 - val_loss: 0.0123 - val_mae: 0.0909\n",
            "Epoch 397/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0103 - mae: 0.0797 - val_loss: 0.0110 - val_mae: 0.0869\n",
            "Epoch 398/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0102 - mae: 0.0811 - val_loss: 0.0116 - val_mae: 0.0887\n",
            "Epoch 399/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0102 - mae: 0.0794 - val_loss: 0.0112 - val_mae: 0.0866\n",
            "Epoch 400/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0105 - mae: 0.0813 - val_loss: 0.0119 - val_mae: 0.0885\n",
            "Epoch 401/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0102 - mae: 0.0805 - val_loss: 0.0109 - val_mae: 0.0861\n",
            "Epoch 402/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0108 - mae: 0.0844 - val_loss: 0.0102 - val_mae: 0.0844\n",
            "Epoch 403/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0106 - mae: 0.0814 - val_loss: 0.0114 - val_mae: 0.0877\n",
            "Epoch 404/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0100 - mae: 0.0789 - val_loss: 0.0116 - val_mae: 0.0897\n",
            "Epoch 405/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0103 - mae: 0.0812 - val_loss: 0.0109 - val_mae: 0.0862\n",
            "Epoch 406/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0104 - mae: 0.0807 - val_loss: 0.0127 - val_mae: 0.0912\n",
            "Epoch 407/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0113 - val_mae: 0.0877\n",
            "Epoch 408/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0108 - mae: 0.0842 - val_loss: 0.0121 - val_mae: 0.0899\n",
            "Epoch 409/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0106 - mae: 0.0825 - val_loss: 0.0137 - val_mae: 0.0942\n",
            "Epoch 410/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0109 - val_mae: 0.0881\n",
            "Epoch 411/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0106 - mae: 0.0816 - val_loss: 0.0110 - val_mae: 0.0869\n",
            "Epoch 412/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0104 - mae: 0.0822 - val_loss: 0.0113 - val_mae: 0.0873\n",
            "Epoch 413/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0101 - mae: 0.0795 - val_loss: 0.0105 - val_mae: 0.0858\n",
            "Epoch 414/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0105 - mae: 0.0809 - val_loss: 0.0110 - val_mae: 0.0858\n",
            "Epoch 415/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0100 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0849\n",
            "Epoch 416/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0106 - mae: 0.0809 - val_loss: 0.0110 - val_mae: 0.0878\n",
            "Epoch 417/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0101 - val_mae: 0.0831\n",
            "Epoch 418/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0112 - val_mae: 0.0866\n",
            "Epoch 419/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0107 - mae: 0.0818 - val_loss: 0.0119 - val_mae: 0.0901\n",
            "Epoch 420/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0101 - mae: 0.0796 - val_loss: 0.0111 - val_mae: 0.0864\n",
            "Epoch 421/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0102 - mae: 0.0802 - val_loss: 0.0111 - val_mae: 0.0886\n",
            "Epoch 422/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0101 - mae: 0.0793 - val_loss: 0.0104 - val_mae: 0.0857\n",
            "Epoch 423/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0111 - val_mae: 0.0888\n",
            "Epoch 424/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0102 - mae: 0.0801 - val_loss: 0.0172 - val_mae: 0.1067\n",
            "Epoch 425/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0108 - mae: 0.0819 - val_loss: 0.0119 - val_mae: 0.0894\n",
            "Epoch 426/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0101 - mae: 0.0794 - val_loss: 0.0105 - val_mae: 0.0863\n",
            "Epoch 427/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0101 - mae: 0.0791 - val_loss: 0.0136 - val_mae: 0.0937\n",
            "Epoch 428/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0107 - mae: 0.0816 - val_loss: 0.0110 - val_mae: 0.0870\n",
            "Epoch 429/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0104 - mae: 0.0807 - val_loss: 0.0133 - val_mae: 0.0930\n",
            "Epoch 430/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0102 - mae: 0.0792 - val_loss: 0.0105 - val_mae: 0.0861\n",
            "Epoch 431/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0103 - mae: 0.0804 - val_loss: 0.0107 - val_mae: 0.0853\n",
            "Epoch 432/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0102 - mae: 0.0789 - val_loss: 0.0112 - val_mae: 0.0882\n",
            "Epoch 433/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0105 - mae: 0.0813 - val_loss: 0.0105 - val_mae: 0.0866\n",
            "Epoch 434/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0099 - mae: 0.0791 - val_loss: 0.0139 - val_mae: 0.0952\n",
            "Epoch 435/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0109 - mae: 0.0847 - val_loss: 0.0120 - val_mae: 0.0886\n",
            "Epoch 436/600\n",
            "150/150 [==============================] - 0s 250us/sample - loss: 0.0105 - mae: 0.0813 - val_loss: 0.0113 - val_mae: 0.0860\n",
            "Epoch 437/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0100 - mae: 0.0802 - val_loss: 0.0118 - val_mae: 0.0875\n",
            "Epoch 438/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0102 - mae: 0.0788 - val_loss: 0.0111 - val_mae: 0.0881\n",
            "Epoch 439/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0103 - mae: 0.0789 - val_loss: 0.0128 - val_mae: 0.0920\n",
            "Epoch 440/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0138 - val_mae: 0.0950\n",
            "Epoch 441/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0105 - mae: 0.0805 - val_loss: 0.0103 - val_mae: 0.0838\n",
            "Epoch 442/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0101 - mae: 0.0801 - val_loss: 0.0108 - val_mae: 0.0864\n",
            "Epoch 443/600\n",
            "150/150 [==============================] - 0s 242us/sample - loss: 0.0103 - mae: 0.0808 - val_loss: 0.0104 - val_mae: 0.0841\n",
            "Epoch 444/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0101 - mae: 0.0807 - val_loss: 0.0106 - val_mae: 0.0852\n",
            "Epoch 445/600\n",
            "150/150 [==============================] - 0s 255us/sample - loss: 0.0108 - mae: 0.0819 - val_loss: 0.0113 - val_mae: 0.0882\n",
            "Epoch 446/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0104 - mae: 0.0820 - val_loss: 0.0109 - val_mae: 0.0864\n",
            "Epoch 447/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0101 - mae: 0.0796 - val_loss: 0.0107 - val_mae: 0.0862\n",
            "Epoch 448/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0104 - mae: 0.0815 - val_loss: 0.0110 - val_mae: 0.0877\n",
            "Epoch 449/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0103 - mae: 0.0810 - val_loss: 0.0114 - val_mae: 0.0878\n",
            "Epoch 450/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0103 - mae: 0.0808 - val_loss: 0.0118 - val_mae: 0.0884\n",
            "Epoch 451/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0101 - mae: 0.0787 - val_loss: 0.0111 - val_mae: 0.0858\n",
            "Epoch 452/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0114 - val_mae: 0.0882\n",
            "Epoch 453/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0100 - mae: 0.0793 - val_loss: 0.0134 - val_mae: 0.0932\n",
            "Epoch 454/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0105 - mae: 0.0829 - val_loss: 0.0129 - val_mae: 0.0919\n",
            "Epoch 455/600\n",
            "150/150 [==============================] - 0s 252us/sample - loss: 0.0101 - mae: 0.0805 - val_loss: 0.0122 - val_mae: 0.0897\n",
            "Epoch 456/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0105 - mae: 0.0811 - val_loss: 0.0106 - val_mae: 0.0858\n",
            "Epoch 457/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0100 - mae: 0.0791 - val_loss: 0.0119 - val_mae: 0.0886\n",
            "Epoch 458/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0109 - mae: 0.0832 - val_loss: 0.0108 - val_mae: 0.0869\n",
            "Epoch 459/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0094 - mae: 0.0768 - val_loss: 0.0147 - val_mae: 0.0985\n",
            "Epoch 460/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0110 - mae: 0.0825 - val_loss: 0.0128 - val_mae: 0.0910\n",
            "Epoch 461/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0137 - val_mae: 0.0950\n",
            "Epoch 462/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0106 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0870\n",
            "Epoch 463/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0101 - mae: 0.0790 - val_loss: 0.0107 - val_mae: 0.0865\n",
            "Epoch 464/600\n",
            "150/150 [==============================] - 0s 243us/sample - loss: 0.0099 - mae: 0.0789 - val_loss: 0.0133 - val_mae: 0.0928\n",
            "Epoch 465/600\n",
            "150/150 [==============================] - 0s 282us/sample - loss: 0.0104 - mae: 0.0801 - val_loss: 0.0122 - val_mae: 0.0892\n",
            "Epoch 466/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0098 - mae: 0.0785 - val_loss: 0.0127 - val_mae: 0.0909\n",
            "Epoch 467/600\n",
            "150/150 [==============================] - 0s 232us/sample - loss: 0.0106 - mae: 0.0805 - val_loss: 0.0137 - val_mae: 0.0944\n",
            "Epoch 468/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0102 - mae: 0.0821 - val_loss: 0.0103 - val_mae: 0.0855\n",
            "Epoch 469/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0106 - mae: 0.0821 - val_loss: 0.0108 - val_mae: 0.0861\n",
            "Epoch 470/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0104 - mae: 0.0799 - val_loss: 0.0120 - val_mae: 0.0905\n",
            "Epoch 471/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0099 - mae: 0.0783 - val_loss: 0.0115 - val_mae: 0.0892\n",
            "Epoch 472/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0117 - val_mae: 0.0877\n",
            "Epoch 473/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0100 - mae: 0.0779 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 474/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0109 - mae: 0.0827 - val_loss: 0.0105 - val_mae: 0.0856\n",
            "Epoch 475/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0102 - mae: 0.0797 - val_loss: 0.0101 - val_mae: 0.0833\n",
            "Epoch 476/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0101 - mae: 0.0805 - val_loss: 0.0125 - val_mae: 0.0906\n",
            "Epoch 477/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0108 - mae: 0.0833 - val_loss: 0.0125 - val_mae: 0.0909\n",
            "Epoch 478/600\n",
            "150/150 [==============================] - 0s 204us/sample - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0099 - val_mae: 0.0830\n",
            "Epoch 479/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0109 - val_mae: 0.0856\n",
            "Epoch 480/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0113 - val_mae: 0.0857\n",
            "Epoch 481/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0101 - mae: 0.0795 - val_loss: 0.0106 - val_mae: 0.0848\n",
            "Epoch 482/600\n",
            "150/150 [==============================] - 0s 224us/sample - loss: 0.0102 - mae: 0.0799 - val_loss: 0.0104 - val_mae: 0.0838\n",
            "Epoch 483/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0102 - mae: 0.0786 - val_loss: 0.0107 - val_mae: 0.0855\n",
            "Epoch 484/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0102 - mae: 0.0790 - val_loss: 0.0112 - val_mae: 0.0869\n",
            "Epoch 485/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0102 - mae: 0.0799 - val_loss: 0.0110 - val_mae: 0.0869\n",
            "Epoch 486/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0099 - mae: 0.0794 - val_loss: 0.0126 - val_mae: 0.0924\n",
            "Epoch 487/600\n",
            "150/150 [==============================] - 0s 233us/sample - loss: 0.0102 - mae: 0.0796 - val_loss: 0.0146 - val_mae: 0.0980\n",
            "Epoch 488/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0100 - mae: 0.0803 - val_loss: 0.0112 - val_mae: 0.0876\n",
            "Epoch 489/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0100 - mae: 0.0777 - val_loss: 0.0122 - val_mae: 0.0898\n",
            "Epoch 490/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0103 - mae: 0.0810 - val_loss: 0.0111 - val_mae: 0.0885\n",
            "Epoch 491/600\n",
            "150/150 [==============================] - 0s 218us/sample - loss: 0.0108 - mae: 0.0827 - val_loss: 0.0122 - val_mae: 0.0920\n",
            "Epoch 492/600\n",
            "150/150 [==============================] - 0s 225us/sample - loss: 0.0101 - mae: 0.0778 - val_loss: 0.0118 - val_mae: 0.0899\n",
            "Epoch 493/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0099 - mae: 0.0793 - val_loss: 0.0107 - val_mae: 0.0870\n",
            "Epoch 494/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0103 - mae: 0.0800 - val_loss: 0.0106 - val_mae: 0.0859\n",
            "Epoch 495/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0104 - mae: 0.0796 - val_loss: 0.0117 - val_mae: 0.0879\n",
            "Epoch 496/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0103 - mae: 0.0812 - val_loss: 0.0131 - val_mae: 0.0937\n",
            "Epoch 497/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0105 - mae: 0.0822 - val_loss: 0.0150 - val_mae: 0.0989\n",
            "Epoch 498/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0101 - mae: 0.0793 - val_loss: 0.0110 - val_mae: 0.0876\n",
            "Epoch 499/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0099 - mae: 0.0782 - val_loss: 0.0113 - val_mae: 0.0887\n",
            "Epoch 500/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0105 - mae: 0.0822 - val_loss: 0.0106 - val_mae: 0.0852\n",
            "Epoch 501/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0096 - mae: 0.0757 - val_loss: 0.0114 - val_mae: 0.0888\n",
            "Epoch 502/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0107 - mae: 0.0831 - val_loss: 0.0111 - val_mae: 0.0877\n",
            "Epoch 503/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0101 - mae: 0.0797 - val_loss: 0.0109 - val_mae: 0.0848\n",
            "Epoch 504/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0101 - mae: 0.0791 - val_loss: 0.0132 - val_mae: 0.0934\n",
            "Epoch 505/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0105 - mae: 0.0827 - val_loss: 0.0119 - val_mae: 0.0884\n",
            "Epoch 506/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0099 - mae: 0.0807 - val_loss: 0.0105 - val_mae: 0.0852\n",
            "Epoch 507/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0101 - mae: 0.0783 - val_loss: 0.0124 - val_mae: 0.0902\n",
            "Epoch 508/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0100 - mae: 0.0809 - val_loss: 0.0103 - val_mae: 0.0840\n",
            "Epoch 509/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0101 - mae: 0.0803 - val_loss: 0.0125 - val_mae: 0.0908\n",
            "Epoch 510/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0103 - mae: 0.0815 - val_loss: 0.0112 - val_mae: 0.0873\n",
            "Epoch 511/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0101 - mae: 0.0797 - val_loss: 0.0124 - val_mae: 0.0922\n",
            "Epoch 512/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0108 - mae: 0.0826 - val_loss: 0.0102 - val_mae: 0.0838\n",
            "Epoch 513/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0100 - mae: 0.0775 - val_loss: 0.0101 - val_mae: 0.0834\n",
            "Epoch 514/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0099 - mae: 0.0793 - val_loss: 0.0123 - val_mae: 0.0900\n",
            "Epoch 515/600\n",
            "150/150 [==============================] - 0s 206us/sample - loss: 0.0105 - mae: 0.0819 - val_loss: 0.0111 - val_mae: 0.0870\n",
            "Epoch 516/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0109 - val_mae: 0.0878\n",
            "Epoch 517/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0102 - mae: 0.0786 - val_loss: 0.0109 - val_mae: 0.0870\n",
            "Epoch 518/600\n",
            "150/150 [==============================] - 0s 227us/sample - loss: 0.0102 - mae: 0.0780 - val_loss: 0.0110 - val_mae: 0.0860\n",
            "Epoch 519/600\n",
            "150/150 [==============================] - 0s 223us/sample - loss: 0.0103 - mae: 0.0792 - val_loss: 0.0110 - val_mae: 0.0868\n",
            "Epoch 520/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0098 - mae: 0.0786 - val_loss: 0.0105 - val_mae: 0.0847\n",
            "Epoch 521/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0105 - mae: 0.0813 - val_loss: 0.0119 - val_mae: 0.0887\n",
            "Epoch 522/600\n",
            "150/150 [==============================] - 0s 227us/sample - loss: 0.0101 - mae: 0.0808 - val_loss: 0.0102 - val_mae: 0.0843\n",
            "Epoch 523/600\n",
            "150/150 [==============================] - 0s 240us/sample - loss: 0.0100 - mae: 0.0793 - val_loss: 0.0109 - val_mae: 0.0877\n",
            "Epoch 524/600\n",
            "150/150 [==============================] - 0s 217us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0123 - val_mae: 0.0917\n",
            "Epoch 525/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0099 - mae: 0.0794 - val_loss: 0.0114 - val_mae: 0.0883\n",
            "Epoch 526/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0106 - mae: 0.0823 - val_loss: 0.0120 - val_mae: 0.0888\n",
            "Epoch 527/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0099 - mae: 0.0791 - val_loss: 0.0115 - val_mae: 0.0883\n",
            "Epoch 528/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0101 - mae: 0.0800 - val_loss: 0.0103 - val_mae: 0.0853\n",
            "Epoch 529/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0102 - mae: 0.0800 - val_loss: 0.0110 - val_mae: 0.0882\n",
            "Epoch 530/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0100 - mae: 0.0789 - val_loss: 0.0104 - val_mae: 0.0843\n",
            "Epoch 531/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0118 - val_mae: 0.0881\n",
            "Epoch 532/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0104 - mae: 0.0807 - val_loss: 0.0105 - val_mae: 0.0850\n",
            "Epoch 533/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0098 - mae: 0.0778 - val_loss: 0.0102 - val_mae: 0.0840\n",
            "Epoch 534/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0103 - mae: 0.0796 - val_loss: 0.0117 - val_mae: 0.0897\n",
            "Epoch 535/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0100 - mae: 0.0784 - val_loss: 0.0111 - val_mae: 0.0886\n",
            "Epoch 536/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0128 - val_mae: 0.0935\n",
            "Epoch 537/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0102 - mae: 0.0806 - val_loss: 0.0119 - val_mae: 0.0911\n",
            "Epoch 538/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0104 - mae: 0.0813 - val_loss: 0.0107 - val_mae: 0.0873\n",
            "Epoch 539/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0102 - mae: 0.0795 - val_loss: 0.0112 - val_mae: 0.0868\n",
            "Epoch 540/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0100 - mae: 0.0785 - val_loss: 0.0112 - val_mae: 0.0867\n",
            "Epoch 541/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0104 - mae: 0.0812 - val_loss: 0.0106 - val_mae: 0.0859\n",
            "Epoch 542/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0096 - mae: 0.0785 - val_loss: 0.0106 - val_mae: 0.0864\n",
            "Epoch 543/600\n",
            "150/150 [==============================] - 0s 244us/sample - loss: 0.0108 - mae: 0.0834 - val_loss: 0.0107 - val_mae: 0.0854\n",
            "Epoch 544/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0102 - mae: 0.0808 - val_loss: 0.0106 - val_mae: 0.0860\n",
            "Epoch 545/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0097 - mae: 0.0790 - val_loss: 0.0143 - val_mae: 0.0966\n",
            "Epoch 546/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0103 - mae: 0.0817 - val_loss: 0.0114 - val_mae: 0.0891\n",
            "Epoch 547/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0098 - mae: 0.0795 - val_loss: 0.0116 - val_mae: 0.0881\n",
            "Epoch 548/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0100 - mae: 0.0790 - val_loss: 0.0104 - val_mae: 0.0845\n",
            "Epoch 549/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0107 - mae: 0.0817 - val_loss: 0.0116 - val_mae: 0.0871\n",
            "Epoch 550/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0099 - mae: 0.0800 - val_loss: 0.0108 - val_mae: 0.0847\n",
            "Epoch 551/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0101 - mae: 0.0802 - val_loss: 0.0117 - val_mae: 0.0891\n",
            "Epoch 552/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0101 - mae: 0.0792 - val_loss: 0.0112 - val_mae: 0.0883\n",
            "Epoch 553/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0099 - mae: 0.0798 - val_loss: 0.0114 - val_mae: 0.0878\n",
            "Epoch 554/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0099 - mae: 0.0781 - val_loss: 0.0143 - val_mae: 0.0969\n",
            "Epoch 555/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0099 - mae: 0.0769 - val_loss: 0.0123 - val_mae: 0.0912\n",
            "Epoch 556/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0104 - mae: 0.0821 - val_loss: 0.0110 - val_mae: 0.0876\n",
            "Epoch 557/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0119 - val_mae: 0.0904\n",
            "Epoch 558/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0099 - mae: 0.0795 - val_loss: 0.0117 - val_mae: 0.0879\n",
            "Epoch 559/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0096 - mae: 0.0779 - val_loss: 0.0112 - val_mae: 0.0885\n",
            "Epoch 560/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0103 - mae: 0.0815 - val_loss: 0.0116 - val_mae: 0.0897\n",
            "Epoch 561/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0102 - mae: 0.0831 - val_loss: 0.0160 - val_mae: 0.1030\n",
            "Epoch 562/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0104 - mae: 0.0815 - val_loss: 0.0137 - val_mae: 0.0945\n",
            "Epoch 563/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0102 - mae: 0.0812 - val_loss: 0.0115 - val_mae: 0.0869\n",
            "Epoch 564/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0100 - mae: 0.0793 - val_loss: 0.0113 - val_mae: 0.0888\n",
            "Epoch 565/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0105 - mae: 0.0808 - val_loss: 0.0106 - val_mae: 0.0853\n",
            "Epoch 566/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0100 - mae: 0.0794 - val_loss: 0.0122 - val_mae: 0.0922\n",
            "Epoch 567/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0104 - mae: 0.0822 - val_loss: 0.0141 - val_mae: 0.0962\n",
            "Epoch 568/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0102 - mae: 0.0794 - val_loss: 0.0116 - val_mae: 0.0897\n",
            "Epoch 569/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0101 - mae: 0.0806 - val_loss: 0.0129 - val_mae: 0.0919\n",
            "Epoch 570/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0097 - mae: 0.0782 - val_loss: 0.0170 - val_mae: 0.1064\n",
            "Epoch 571/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0130 - val_mae: 0.0922\n",
            "Epoch 572/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0097 - mae: 0.0793 - val_loss: 0.0120 - val_mae: 0.0904\n",
            "Epoch 573/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0118 - val_mae: 0.0899\n",
            "Epoch 574/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0100 - mae: 0.0800 - val_loss: 0.0126 - val_mae: 0.0920\n",
            "Epoch 575/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0100 - mae: 0.0807 - val_loss: 0.0117 - val_mae: 0.0889\n",
            "Epoch 576/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0099 - mae: 0.0784 - val_loss: 0.0105 - val_mae: 0.0849\n",
            "Epoch 577/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0100 - mae: 0.0791 - val_loss: 0.0116 - val_mae: 0.0898\n",
            "Epoch 578/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0101 - mae: 0.0788 - val_loss: 0.0123 - val_mae: 0.0911\n",
            "Epoch 579/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0101 - mae: 0.0826 - val_loss: 0.0110 - val_mae: 0.0878\n",
            "Epoch 580/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0102 - mae: 0.0806 - val_loss: 0.0117 - val_mae: 0.0889\n",
            "Epoch 581/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0103 - mae: 0.0803 - val_loss: 0.0105 - val_mae: 0.0856\n",
            "Epoch 582/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0100 - val_mae: 0.0830\n",
            "Epoch 583/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0102 - mae: 0.0794 - val_loss: 0.0105 - val_mae: 0.0845\n",
            "Epoch 584/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0097 - mae: 0.0766 - val_loss: 0.0106 - val_mae: 0.0855\n",
            "Epoch 585/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0097 - mae: 0.0778 - val_loss: 0.0099 - val_mae: 0.0829\n",
            "Epoch 586/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0104 - mae: 0.0813 - val_loss: 0.0113 - val_mae: 0.0885\n",
            "Epoch 587/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0100 - mae: 0.0804 - val_loss: 0.0100 - val_mae: 0.0834\n",
            "Epoch 588/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0102 - mae: 0.0794 - val_loss: 0.0121 - val_mae: 0.0913\n",
            "Epoch 589/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0100 - mae: 0.0808 - val_loss: 0.0121 - val_mae: 0.0893\n",
            "Epoch 590/600\n",
            "150/150 [==============================] - 0s 235us/sample - loss: 0.0100 - mae: 0.0781 - val_loss: 0.0122 - val_mae: 0.0895\n",
            "Epoch 591/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0099 - mae: 0.0787 - val_loss: 0.0110 - val_mae: 0.0870\n",
            "Epoch 592/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0099 - mae: 0.0779 - val_loss: 0.0142 - val_mae: 0.0979\n",
            "Epoch 593/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0108 - mae: 0.0849 - val_loss: 0.0121 - val_mae: 0.0887\n",
            "Epoch 594/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0102 - mae: 0.0807 - val_loss: 0.0123 - val_mae: 0.0899\n",
            "Epoch 595/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0102 - mae: 0.0811 - val_loss: 0.0118 - val_mae: 0.0902\n",
            "Epoch 596/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0105 - mae: 0.0816 - val_loss: 0.0109 - val_mae: 0.0883\n",
            "Epoch 597/600\n",
            "150/150 [==============================] - 0s 246us/sample - loss: 0.0101 - mae: 0.0798 - val_loss: 0.0119 - val_mae: 0.0885\n",
            "Epoch 598/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0099 - mae: 0.0798 - val_loss: 0.0107 - val_mae: 0.0856\n",
            "Epoch 599/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0100 - mae: 0.0798 - val_loss: 0.0110 - val_mae: 0.0885\n",
            "Epoch 600/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0101 - mae: 0.0815 - val_loss: 0.0110 - val_mae: 0.0863\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Fas4iPyBKtnW",
        "outputId": "4a5158b9-31be-40a3-8e3d-29fb1b7696f3"
      },
      "source": [
        "#Toy Problem Y=sin(x) 250 samples of period pi to 2pi\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 250\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=math.pi, high=2*math.pi,size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "#plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_2.summary()\n",
        "history_2 = model_2.fit(x_train, y_train, epochs=600, batch_size=16, validation_data=(x_validate, y_validate))\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_2.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_48 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 150 samples, validate on 50 samples\n",
            "Epoch 1/600\n",
            "150/150 [==============================] - 0s 1ms/sample - loss: 13.7157 - mae: 3.6295 - val_loss: 10.8549 - val_mae: 3.2379\n",
            "Epoch 2/600\n",
            "150/150 [==============================] - 0s 112us/sample - loss: 9.4674 - mae: 3.0141 - val_loss: 7.9096 - val_mae: 2.7606\n",
            "Epoch 3/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 7.0125 - mae: 2.5856 - val_loss: 5.9912 - val_mae: 2.3988\n",
            "Epoch 4/600\n",
            "150/150 [==============================] - 0s 117us/sample - loss: 5.2742 - mae: 2.2374 - val_loss: 4.4238 - val_mae: 2.0565\n",
            "Epoch 5/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 3.8598 - mae: 1.9104 - val_loss: 3.2239 - val_mae: 1.7504\n",
            "Epoch 6/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 2.8176 - mae: 1.6205 - val_loss: 2.3389 - val_mae: 1.4840\n",
            "Epoch 7/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 2.0063 - mae: 1.3603 - val_loss: 1.6066 - val_mae: 1.2203\n",
            "Epoch 8/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 1.3648 - mae: 1.1057 - val_loss: 1.0671 - val_mae: 0.9817\n",
            "Epoch 9/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.8863 - mae: 0.8760 - val_loss: 0.6544 - val_mae: 0.7494\n",
            "Epoch 10/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.5383 - mae: 0.6600 - val_loss: 0.3821 - val_mae: 0.5484\n",
            "Epoch 11/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.3144 - mae: 0.4926 - val_loss: 0.2142 - val_mae: 0.3926\n",
            "Epoch 12/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.1817 - mae: 0.3774 - val_loss: 0.1204 - val_mae: 0.3025\n",
            "Epoch 13/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.1179 - mae: 0.3012 - val_loss: 0.0909 - val_mae: 0.2697\n",
            "Epoch 14/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0994 - mae: 0.2748 - val_loss: 0.0793 - val_mae: 0.2509\n",
            "Epoch 15/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.0922 - mae: 0.2589 - val_loss: 0.0761 - val_mae: 0.2427\n",
            "Epoch 16/600\n",
            "150/150 [==============================] - 0s 121us/sample - loss: 0.0920 - mae: 0.2551 - val_loss: 0.0765 - val_mae: 0.2410\n",
            "Epoch 17/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0929 - mae: 0.2547 - val_loss: 0.0775 - val_mae: 0.2473\n",
            "Epoch 18/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0924 - mae: 0.2586 - val_loss: 0.0758 - val_mae: 0.2420\n",
            "Epoch 19/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0922 - mae: 0.2569 - val_loss: 0.0758 - val_mae: 0.2410\n",
            "Epoch 20/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0932 - mae: 0.2536 - val_loss: 0.0763 - val_mae: 0.2447\n",
            "Epoch 21/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0911 - mae: 0.2555 - val_loss: 0.0784 - val_mae: 0.2404\n",
            "Epoch 22/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0923 - mae: 0.2540 - val_loss: 0.0756 - val_mae: 0.2429\n",
            "Epoch 23/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0903 - mae: 0.2529 - val_loss: 0.0781 - val_mae: 0.2485\n",
            "Epoch 24/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0922 - mae: 0.2600 - val_loss: 0.0761 - val_mae: 0.2395\n",
            "Epoch 25/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0916 - mae: 0.2540 - val_loss: 0.0770 - val_mae: 0.2395\n",
            "Epoch 26/600\n",
            "150/150 [==============================] - 0s 133us/sample - loss: 0.0909 - mae: 0.2517 - val_loss: 0.0776 - val_mae: 0.2477\n",
            "Epoch 27/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0907 - mae: 0.2564 - val_loss: 0.0754 - val_mae: 0.2434\n",
            "Epoch 28/600\n",
            "150/150 [==============================] - 0s 120us/sample - loss: 0.0906 - mae: 0.2558 - val_loss: 0.0749 - val_mae: 0.2419\n",
            "Epoch 29/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0914 - mae: 0.2556 - val_loss: 0.0749 - val_mae: 0.2408\n",
            "Epoch 30/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0900 - mae: 0.2506 - val_loss: 0.0821 - val_mae: 0.2555\n",
            "Epoch 31/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0931 - mae: 0.2593 - val_loss: 0.0758 - val_mae: 0.2446\n",
            "Epoch 32/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0907 - mae: 0.2567 - val_loss: 0.0744 - val_mae: 0.2393\n",
            "Epoch 33/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0900 - mae: 0.2518 - val_loss: 0.0745 - val_mae: 0.2417\n",
            "Epoch 34/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0908 - mae: 0.2540 - val_loss: 0.0761 - val_mae: 0.2448\n",
            "Epoch 35/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0890 - mae: 0.2539 - val_loss: 0.0758 - val_mae: 0.2448\n",
            "Epoch 36/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0903 - mae: 0.2558 - val_loss: 0.0737 - val_mae: 0.2389\n",
            "Epoch 37/600\n",
            "150/150 [==============================] - 0s 117us/sample - loss: 0.0901 - mae: 0.2527 - val_loss: 0.0738 - val_mae: 0.2404\n",
            "Epoch 38/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0899 - mae: 0.2521 - val_loss: 0.0742 - val_mae: 0.2368\n",
            "Epoch 39/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0899 - mae: 0.2510 - val_loss: 0.0732 - val_mae: 0.2377\n",
            "Epoch 40/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0902 - mae: 0.2528 - val_loss: 0.0735 - val_mae: 0.2370\n",
            "Epoch 41/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0893 - mae: 0.2512 - val_loss: 0.0737 - val_mae: 0.2406\n",
            "Epoch 42/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0900 - mae: 0.2526 - val_loss: 0.0751 - val_mae: 0.2430\n",
            "Epoch 43/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0888 - mae: 0.2533 - val_loss: 0.0742 - val_mae: 0.2352\n",
            "Epoch 44/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0883 - mae: 0.2477 - val_loss: 0.0725 - val_mae: 0.2374\n",
            "Epoch 45/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0884 - mae: 0.2524 - val_loss: 0.0727 - val_mae: 0.2385\n",
            "Epoch 46/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0893 - mae: 0.2538 - val_loss: 0.0767 - val_mae: 0.2354\n",
            "Epoch 47/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0894 - mae: 0.2481 - val_loss: 0.0736 - val_mae: 0.2405\n",
            "Epoch 48/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0887 - mae: 0.2534 - val_loss: 0.0728 - val_mae: 0.2329\n",
            "Epoch 49/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0870 - mae: 0.2483 - val_loss: 0.0736 - val_mae: 0.2338\n",
            "Epoch 50/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0878 - mae: 0.2472 - val_loss: 0.0756 - val_mae: 0.2439\n",
            "Epoch 51/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0876 - mae: 0.2507 - val_loss: 0.0714 - val_mae: 0.2348\n",
            "Epoch 52/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0874 - mae: 0.2489 - val_loss: 0.0733 - val_mae: 0.2338\n",
            "Epoch 53/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0874 - mae: 0.2466 - val_loss: 0.0714 - val_mae: 0.2366\n",
            "Epoch 54/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0876 - mae: 0.2506 - val_loss: 0.0744 - val_mae: 0.2333\n",
            "Epoch 55/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0872 - mae: 0.2446 - val_loss: 0.0724 - val_mae: 0.2386\n",
            "Epoch 56/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0871 - mae: 0.2497 - val_loss: 0.0709 - val_mae: 0.2332\n",
            "Epoch 57/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0886 - mae: 0.2470 - val_loss: 0.0717 - val_mae: 0.2375\n",
            "Epoch 58/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0872 - mae: 0.2496 - val_loss: 0.0706 - val_mae: 0.2353\n",
            "Epoch 59/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0862 - mae: 0.2492 - val_loss: 0.0734 - val_mae: 0.2317\n",
            "Epoch 60/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0863 - mae: 0.2439 - val_loss: 0.0701 - val_mae: 0.2344\n",
            "Epoch 61/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0868 - mae: 0.2493 - val_loss: 0.0702 - val_mae: 0.2315\n",
            "Epoch 62/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0855 - mae: 0.2455 - val_loss: 0.0702 - val_mae: 0.2320\n",
            "Epoch 63/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0855 - mae: 0.2464 - val_loss: 0.0693 - val_mae: 0.2319\n",
            "Epoch 64/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0856 - mae: 0.2481 - val_loss: 0.0692 - val_mae: 0.2307\n",
            "Epoch 65/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0857 - mae: 0.2471 - val_loss: 0.0695 - val_mae: 0.2322\n",
            "Epoch 66/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0871 - mae: 0.2465 - val_loss: 0.0690 - val_mae: 0.2322\n",
            "Epoch 67/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0848 - mae: 0.2440 - val_loss: 0.0697 - val_mae: 0.2342\n",
            "Epoch 68/600\n",
            "150/150 [==============================] - 0s 218us/sample - loss: 0.0846 - mae: 0.2463 - val_loss: 0.0713 - val_mae: 0.2367\n",
            "Epoch 69/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0846 - mae: 0.2466 - val_loss: 0.0719 - val_mae: 0.2377\n",
            "Epoch 70/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0856 - mae: 0.2480 - val_loss: 0.0679 - val_mae: 0.2291\n",
            "Epoch 71/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0844 - mae: 0.2437 - val_loss: 0.0680 - val_mae: 0.2286\n",
            "Epoch 72/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0839 - mae: 0.2413 - val_loss: 0.0727 - val_mae: 0.2399\n",
            "Epoch 73/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0846 - mae: 0.2463 - val_loss: 0.0694 - val_mae: 0.2266\n",
            "Epoch 74/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0846 - mae: 0.2449 - val_loss: 0.0674 - val_mae: 0.2289\n",
            "Epoch 75/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0835 - mae: 0.2422 - val_loss: 0.0673 - val_mae: 0.2294\n",
            "Epoch 76/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0834 - mae: 0.2446 - val_loss: 0.0686 - val_mae: 0.2279\n",
            "Epoch 77/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0840 - mae: 0.2452 - val_loss: 0.0667 - val_mae: 0.2277\n",
            "Epoch 78/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0840 - mae: 0.2416 - val_loss: 0.0669 - val_mae: 0.2268\n",
            "Epoch 79/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0835 - mae: 0.2426 - val_loss: 0.0667 - val_mae: 0.2266\n",
            "Epoch 80/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0833 - mae: 0.2425 - val_loss: 0.0669 - val_mae: 0.2273\n",
            "Epoch 81/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0837 - mae: 0.2433 - val_loss: 0.0661 - val_mae: 0.2267\n",
            "Epoch 82/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0811 - mae: 0.2358 - val_loss: 0.0738 - val_mae: 0.2425\n",
            "Epoch 83/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0836 - mae: 0.2456 - val_loss: 0.0677 - val_mae: 0.2259\n",
            "Epoch 84/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0824 - mae: 0.2400 - val_loss: 0.0667 - val_mae: 0.2277\n",
            "Epoch 85/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0817 - mae: 0.2412 - val_loss: 0.0652 - val_mae: 0.2240\n",
            "Epoch 86/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0825 - mae: 0.2408 - val_loss: 0.0672 - val_mae: 0.2294\n",
            "Epoch 87/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0829 - mae: 0.2438 - val_loss: 0.0675 - val_mae: 0.2300\n",
            "Epoch 88/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0823 - mae: 0.2424 - val_loss: 0.0685 - val_mae: 0.2327\n",
            "Epoch 89/600\n",
            "150/150 [==============================] - 0s 119us/sample - loss: 0.0827 - mae: 0.2439 - val_loss: 0.0655 - val_mae: 0.2264\n",
            "Epoch 90/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0819 - mae: 0.2420 - val_loss: 0.0693 - val_mae: 0.2345\n",
            "Epoch 91/600\n",
            "150/150 [==============================] - 0s 116us/sample - loss: 0.0827 - mae: 0.2439 - val_loss: 0.0645 - val_mae: 0.2238\n",
            "Epoch 92/600\n",
            "150/150 [==============================] - 0s 113us/sample - loss: 0.0798 - mae: 0.2391 - val_loss: 0.0642 - val_mae: 0.2221\n",
            "Epoch 93/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0800 - mae: 0.2382 - val_loss: 0.0650 - val_mae: 0.2249\n",
            "Epoch 94/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0813 - mae: 0.2396 - val_loss: 0.0650 - val_mae: 0.2253\n",
            "Epoch 95/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0796 - mae: 0.2379 - val_loss: 0.0632 - val_mae: 0.2205\n",
            "Epoch 96/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0810 - mae: 0.2407 - val_loss: 0.0632 - val_mae: 0.2203\n",
            "Epoch 97/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0798 - mae: 0.2373 - val_loss: 0.0632 - val_mae: 0.2207\n",
            "Epoch 98/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0793 - mae: 0.2366 - val_loss: 0.0633 - val_mae: 0.2214\n",
            "Epoch 99/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0794 - mae: 0.2382 - val_loss: 0.0629 - val_mae: 0.2184\n",
            "Epoch 100/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0799 - mae: 0.2372 - val_loss: 0.0623 - val_mae: 0.2187\n",
            "Epoch 101/600\n",
            "150/150 [==============================] - 0s 115us/sample - loss: 0.0777 - mae: 0.2345 - val_loss: 0.0621 - val_mae: 0.2193\n",
            "Epoch 102/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0788 - mae: 0.2371 - val_loss: 0.0618 - val_mae: 0.2188\n",
            "Epoch 103/600\n",
            "150/150 [==============================] - 0s 111us/sample - loss: 0.0780 - mae: 0.2354 - val_loss: 0.0618 - val_mae: 0.2167\n",
            "Epoch 104/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.0786 - mae: 0.2361 - val_loss: 0.0612 - val_mae: 0.2171\n",
            "Epoch 105/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0781 - mae: 0.2361 - val_loss: 0.0629 - val_mae: 0.2156\n",
            "Epoch 106/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0776 - mae: 0.2350 - val_loss: 0.0645 - val_mae: 0.2164\n",
            "Epoch 107/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0773 - mae: 0.2303 - val_loss: 0.0648 - val_mae: 0.2267\n",
            "Epoch 108/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0772 - mae: 0.2372 - val_loss: 0.0617 - val_mae: 0.2147\n",
            "Epoch 109/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0783 - mae: 0.2344 - val_loss: 0.0632 - val_mae: 0.2145\n",
            "Epoch 110/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0774 - mae: 0.2330 - val_loss: 0.0615 - val_mae: 0.2128\n",
            "Epoch 111/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0770 - mae: 0.2338 - val_loss: 0.0622 - val_mae: 0.2141\n",
            "Epoch 112/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0783 - mae: 0.2369 - val_loss: 0.0609 - val_mae: 0.2139\n",
            "Epoch 113/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0779 - mae: 0.2334 - val_loss: 0.0594 - val_mae: 0.2138\n",
            "Epoch 114/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0768 - mae: 0.2328 - val_loss: 0.0595 - val_mae: 0.2147\n",
            "Epoch 115/600\n",
            "150/150 [==============================] - 0s 223us/sample - loss: 0.0745 - mae: 0.2333 - val_loss: 0.0615 - val_mae: 0.2121\n",
            "Epoch 116/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0767 - mae: 0.2333 - val_loss: 0.0653 - val_mae: 0.2154\n",
            "Epoch 117/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0747 - mae: 0.2278 - val_loss: 0.0592 - val_mae: 0.2099\n",
            "Epoch 118/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0745 - mae: 0.2265 - val_loss: 0.0590 - val_mae: 0.2144\n",
            "Epoch 119/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0755 - mae: 0.2326 - val_loss: 0.0585 - val_mae: 0.2119\n",
            "Epoch 120/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0740 - mae: 0.2310 - val_loss: 0.0587 - val_mae: 0.2095\n",
            "Epoch 121/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0743 - mae: 0.2276 - val_loss: 0.0618 - val_mae: 0.2121\n",
            "Epoch 122/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0747 - mae: 0.2280 - val_loss: 0.0577 - val_mae: 0.2112\n",
            "Epoch 123/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0738 - mae: 0.2261 - val_loss: 0.0577 - val_mae: 0.2115\n",
            "Epoch 124/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0733 - mae: 0.2272 - val_loss: 0.0575 - val_mae: 0.2114\n",
            "Epoch 125/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0742 - mae: 0.2311 - val_loss: 0.0580 - val_mae: 0.2090\n",
            "Epoch 126/600\n",
            "150/150 [==============================] - 0s 128us/sample - loss: 0.0731 - mae: 0.2272 - val_loss: 0.0607 - val_mae: 0.2092\n",
            "Epoch 127/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0727 - mae: 0.2241 - val_loss: 0.0598 - val_mae: 0.2088\n",
            "Epoch 128/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0723 - mae: 0.2257 - val_loss: 0.0575 - val_mae: 0.2075\n",
            "Epoch 129/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0737 - mae: 0.2302 - val_loss: 0.0632 - val_mae: 0.2110\n",
            "Epoch 130/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0736 - mae: 0.2225 - val_loss: 0.0594 - val_mae: 0.2167\n",
            "Epoch 131/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0721 - mae: 0.2292 - val_loss: 0.0563 - val_mae: 0.2092\n",
            "Epoch 132/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0725 - mae: 0.2277 - val_loss: 0.0556 - val_mae: 0.2046\n",
            "Epoch 133/600\n",
            "150/150 [==============================] - 0s 120us/sample - loss: 0.0704 - mae: 0.2225 - val_loss: 0.0584 - val_mae: 0.2062\n",
            "Epoch 134/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0721 - mae: 0.2248 - val_loss: 0.0561 - val_mae: 0.2053\n",
            "Epoch 135/600\n",
            "150/150 [==============================] - 0s 125us/sample - loss: 0.0735 - mae: 0.2295 - val_loss: 0.0543 - val_mae: 0.2023\n",
            "Epoch 136/600\n",
            "150/150 [==============================] - 0s 110us/sample - loss: 0.0701 - mae: 0.2219 - val_loss: 0.0555 - val_mae: 0.2078\n",
            "Epoch 137/600\n",
            "150/150 [==============================] - 0s 122us/sample - loss: 0.0705 - mae: 0.2244 - val_loss: 0.0539 - val_mae: 0.2024\n",
            "Epoch 138/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0701 - mae: 0.2213 - val_loss: 0.0541 - val_mae: 0.2038\n",
            "Epoch 139/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0697 - mae: 0.2199 - val_loss: 0.0536 - val_mae: 0.2025\n",
            "Epoch 140/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0700 - mae: 0.2238 - val_loss: 0.0542 - val_mae: 0.2052\n",
            "Epoch 141/600\n",
            "150/150 [==============================] - 0s 115us/sample - loss: 0.0686 - mae: 0.2201 - val_loss: 0.0576 - val_mae: 0.2132\n",
            "Epoch 142/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0708 - mae: 0.2237 - val_loss: 0.0531 - val_mae: 0.2013\n",
            "Epoch 143/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0688 - mae: 0.2211 - val_loss: 0.0567 - val_mae: 0.2115\n",
            "Epoch 144/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0686 - mae: 0.2223 - val_loss: 0.0533 - val_mae: 0.1983\n",
            "Epoch 145/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0679 - mae: 0.2181 - val_loss: 0.0533 - val_mae: 0.1985\n",
            "Epoch 146/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0694 - mae: 0.2153 - val_loss: 0.0554 - val_mae: 0.2089\n",
            "Epoch 147/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0684 - mae: 0.2208 - val_loss: 0.0526 - val_mae: 0.2010\n",
            "Epoch 148/600\n",
            "150/150 [==============================] - 0s 131us/sample - loss: 0.0690 - mae: 0.2235 - val_loss: 0.0559 - val_mae: 0.2005\n",
            "Epoch 149/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0678 - mae: 0.2176 - val_loss: 0.0518 - val_mae: 0.1966\n",
            "Epoch 150/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0662 - mae: 0.2134 - val_loss: 0.0515 - val_mae: 0.1995\n",
            "Epoch 151/600\n",
            "150/150 [==============================] - 0s 118us/sample - loss: 0.0661 - mae: 0.2177 - val_loss: 0.0574 - val_mae: 0.2019\n",
            "Epoch 152/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0681 - mae: 0.2126 - val_loss: 0.0504 - val_mae: 0.1957\n",
            "Epoch 153/600\n",
            "150/150 [==============================] - 0s 238us/sample - loss: 0.0645 - mae: 0.2144 - val_loss: 0.0571 - val_mae: 0.2012\n",
            "Epoch 154/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0673 - mae: 0.2153 - val_loss: 0.0500 - val_mae: 0.1932\n",
            "Epoch 155/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0650 - mae: 0.2140 - val_loss: 0.0500 - val_mae: 0.1947\n",
            "Epoch 156/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0657 - mae: 0.2163 - val_loss: 0.0518 - val_mae: 0.1936\n",
            "Epoch 157/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0648 - mae: 0.2125 - val_loss: 0.0496 - val_mae: 0.1923\n",
            "Epoch 158/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0653 - mae: 0.2140 - val_loss: 0.0531 - val_mae: 0.2042\n",
            "Epoch 159/600\n",
            "150/150 [==============================] - 0s 138us/sample - loss: 0.0641 - mae: 0.2138 - val_loss: 0.0504 - val_mae: 0.1987\n",
            "Epoch 160/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0645 - mae: 0.2128 - val_loss: 0.0508 - val_mae: 0.1947\n",
            "Epoch 161/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0621 - mae: 0.2073 - val_loss: 0.0486 - val_mae: 0.1881\n",
            "Epoch 162/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0621 - mae: 0.2069 - val_loss: 0.0476 - val_mae: 0.1902\n",
            "Epoch 163/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0634 - mae: 0.2091 - val_loss: 0.0510 - val_mae: 0.1992\n",
            "Epoch 164/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0644 - mae: 0.2104 - val_loss: 0.0466 - val_mae: 0.1866\n",
            "Epoch 165/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0612 - mae: 0.2050 - val_loss: 0.0466 - val_mae: 0.1849\n",
            "Epoch 166/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0604 - mae: 0.2049 - val_loss: 0.0481 - val_mae: 0.1871\n",
            "Epoch 167/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0607 - mae: 0.2063 - val_loss: 0.0452 - val_mae: 0.1811\n",
            "Epoch 168/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0603 - mae: 0.2043 - val_loss: 0.0474 - val_mae: 0.1924\n",
            "Epoch 169/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0606 - mae: 0.2064 - val_loss: 0.0459 - val_mae: 0.1842\n",
            "Epoch 170/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0599 - mae: 0.2041 - val_loss: 0.0508 - val_mae: 0.1874\n",
            "Epoch 171/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0594 - mae: 0.1994 - val_loss: 0.0450 - val_mae: 0.1842\n",
            "Epoch 172/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0591 - mae: 0.2057 - val_loss: 0.0455 - val_mae: 0.1814\n",
            "Epoch 173/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0596 - mae: 0.2047 - val_loss: 0.0435 - val_mae: 0.1769\n",
            "Epoch 174/600\n",
            "150/150 [==============================] - 0s 130us/sample - loss: 0.0573 - mae: 0.1976 - val_loss: 0.0439 - val_mae: 0.1840\n",
            "Epoch 175/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0584 - mae: 0.2047 - val_loss: 0.0427 - val_mae: 0.1737\n",
            "Epoch 176/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0570 - mae: 0.1984 - val_loss: 0.0440 - val_mae: 0.1779\n",
            "Epoch 177/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0569 - mae: 0.1983 - val_loss: 0.0424 - val_mae: 0.1802\n",
            "Epoch 178/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0564 - mae: 0.1986 - val_loss: 0.0416 - val_mae: 0.1780\n",
            "Epoch 179/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0553 - mae: 0.1967 - val_loss: 0.0457 - val_mae: 0.1892\n",
            "Epoch 180/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0562 - mae: 0.1984 - val_loss: 0.0431 - val_mae: 0.1818\n",
            "Epoch 181/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0552 - mae: 0.1981 - val_loss: 0.0401 - val_mae: 0.1730\n",
            "Epoch 182/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0541 - mae: 0.1927 - val_loss: 0.0407 - val_mae: 0.1761\n",
            "Epoch 183/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0538 - mae: 0.1965 - val_loss: 0.0455 - val_mae: 0.1783\n",
            "Epoch 184/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0549 - mae: 0.1939 - val_loss: 0.0392 - val_mae: 0.1655\n",
            "Epoch 185/600\n",
            "150/150 [==============================] - 0s 134us/sample - loss: 0.0547 - mae: 0.1946 - val_loss: 0.0418 - val_mae: 0.1686\n",
            "Epoch 186/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0528 - mae: 0.1902 - val_loss: 0.0405 - val_mae: 0.1685\n",
            "Epoch 187/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0529 - mae: 0.1895 - val_loss: 0.0375 - val_mae: 0.1659\n",
            "Epoch 188/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0499 - mae: 0.1859 - val_loss: 0.0426 - val_mae: 0.1670\n",
            "Epoch 189/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0534 - mae: 0.1924 - val_loss: 0.0427 - val_mae: 0.1682\n",
            "Epoch 190/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0498 - mae: 0.1833 - val_loss: 0.0375 - val_mae: 0.1663\n",
            "Epoch 191/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0499 - mae: 0.1876 - val_loss: 0.0384 - val_mae: 0.1615\n",
            "Epoch 192/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0488 - mae: 0.1824 - val_loss: 0.0415 - val_mae: 0.1640\n",
            "Epoch 193/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0496 - mae: 0.1806 - val_loss: 0.0348 - val_mae: 0.1589\n",
            "Epoch 194/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0501 - mae: 0.1878 - val_loss: 0.0356 - val_mae: 0.1616\n",
            "Epoch 195/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0483 - mae: 0.1826 - val_loss: 0.0349 - val_mae: 0.1562\n",
            "Epoch 196/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0471 - mae: 0.1800 - val_loss: 0.0354 - val_mae: 0.1597\n",
            "Epoch 197/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0455 - mae: 0.1757 - val_loss: 0.0363 - val_mae: 0.1656\n",
            "Epoch 198/600\n",
            "150/150 [==============================] - 0s 135us/sample - loss: 0.0477 - mae: 0.1808 - val_loss: 0.0362 - val_mae: 0.1589\n",
            "Epoch 199/600\n",
            "150/150 [==============================] - 0s 126us/sample - loss: 0.0462 - mae: 0.1738 - val_loss: 0.0326 - val_mae: 0.1528\n",
            "Epoch 200/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0475 - mae: 0.1780 - val_loss: 0.0335 - val_mae: 0.1570\n",
            "Epoch 201/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0450 - mae: 0.1769 - val_loss: 0.0343 - val_mae: 0.1606\n",
            "Epoch 202/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0461 - mae: 0.1793 - val_loss: 0.0319 - val_mae: 0.1512\n",
            "Epoch 203/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0451 - mae: 0.1780 - val_loss: 0.0312 - val_mae: 0.1489\n",
            "Epoch 204/600\n",
            "150/150 [==============================] - 0s 124us/sample - loss: 0.0450 - mae: 0.1769 - val_loss: 0.0307 - val_mae: 0.1464\n",
            "Epoch 205/600\n",
            "150/150 [==============================] - 0s 129us/sample - loss: 0.0445 - mae: 0.1730 - val_loss: 0.0302 - val_mae: 0.1445\n",
            "Epoch 206/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0431 - mae: 0.1732 - val_loss: 0.0304 - val_mae: 0.1465\n",
            "Epoch 207/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0429 - mae: 0.1709 - val_loss: 0.0312 - val_mae: 0.1525\n",
            "Epoch 208/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0421 - mae: 0.1710 - val_loss: 0.0296 - val_mae: 0.1466\n",
            "Epoch 209/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0426 - mae: 0.1720 - val_loss: 0.0305 - val_mae: 0.1480\n",
            "Epoch 210/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0420 - mae: 0.1707 - val_loss: 0.0297 - val_mae: 0.1471\n",
            "Epoch 211/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0406 - mae: 0.1673 - val_loss: 0.0314 - val_mae: 0.1440\n",
            "Epoch 212/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0407 - mae: 0.1684 - val_loss: 0.0294 - val_mae: 0.1399\n",
            "Epoch 213/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0382 - mae: 0.1608 - val_loss: 0.0344 - val_mae: 0.1469\n",
            "Epoch 214/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0397 - mae: 0.1652 - val_loss: 0.0306 - val_mae: 0.1418\n",
            "Epoch 215/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0399 - mae: 0.1629 - val_loss: 0.0348 - val_mae: 0.1579\n",
            "Epoch 216/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0389 - mae: 0.1649 - val_loss: 0.0286 - val_mae: 0.1351\n",
            "Epoch 217/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0384 - mae: 0.1621 - val_loss: 0.0253 - val_mae: 0.1297\n",
            "Epoch 218/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0374 - mae: 0.1613 - val_loss: 0.0259 - val_mae: 0.1337\n",
            "Epoch 219/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0371 - mae: 0.1549 - val_loss: 0.0295 - val_mae: 0.1430\n",
            "Epoch 220/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0369 - mae: 0.1601 - val_loss: 0.0235 - val_mae: 0.1257\n",
            "Epoch 221/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0355 - mae: 0.1561 - val_loss: 0.0245 - val_mae: 0.1299\n",
            "Epoch 222/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0360 - mae: 0.1575 - val_loss: 0.0228 - val_mae: 0.1228\n",
            "Epoch 223/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0335 - mae: 0.1502 - val_loss: 0.0285 - val_mae: 0.1329\n",
            "Epoch 224/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0341 - mae: 0.1506 - val_loss: 0.0226 - val_mae: 0.1209\n",
            "Epoch 225/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0338 - mae: 0.1526 - val_loss: 0.0290 - val_mae: 0.1352\n",
            "Epoch 226/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0336 - mae: 0.1487 - val_loss: 0.0270 - val_mae: 0.1314\n",
            "Epoch 227/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0334 - mae: 0.1495 - val_loss: 0.0253 - val_mae: 0.1269\n",
            "Epoch 228/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0329 - mae: 0.1483 - val_loss: 0.0217 - val_mae: 0.1203\n",
            "Epoch 229/600\n",
            "150/150 [==============================] - 0s 123us/sample - loss: 0.0313 - mae: 0.1463 - val_loss: 0.0224 - val_mae: 0.1209\n",
            "Epoch 230/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0322 - mae: 0.1482 - val_loss: 0.0218 - val_mae: 0.1188\n",
            "Epoch 231/600\n",
            "150/150 [==============================] - 0s 249us/sample - loss: 0.0319 - mae: 0.1475 - val_loss: 0.0203 - val_mae: 0.1132\n",
            "Epoch 232/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0304 - mae: 0.1431 - val_loss: 0.0202 - val_mae: 0.1145\n",
            "Epoch 233/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0291 - mae: 0.1407 - val_loss: 0.0194 - val_mae: 0.1111\n",
            "Epoch 234/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0312 - mae: 0.1449 - val_loss: 0.0235 - val_mae: 0.1247\n",
            "Epoch 235/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0305 - mae: 0.1454 - val_loss: 0.0195 - val_mae: 0.1120\n",
            "Epoch 236/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0281 - mae: 0.1390 - val_loss: 0.0187 - val_mae: 0.1095\n",
            "Epoch 237/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0292 - mae: 0.1378 - val_loss: 0.0183 - val_mae: 0.1078\n",
            "Epoch 238/600\n",
            "150/150 [==============================] - 0s 136us/sample - loss: 0.0290 - mae: 0.1378 - val_loss: 0.0179 - val_mae: 0.1058\n",
            "Epoch 239/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0284 - mae: 0.1373 - val_loss: 0.0257 - val_mae: 0.1274\n",
            "Epoch 240/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0282 - mae: 0.1384 - val_loss: 0.0220 - val_mae: 0.1194\n",
            "Epoch 241/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0262 - mae: 0.1316 - val_loss: 0.0176 - val_mae: 0.1045\n",
            "Epoch 242/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0284 - mae: 0.1370 - val_loss: 0.0170 - val_mae: 0.1021\n",
            "Epoch 243/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0269 - mae: 0.1364 - val_loss: 0.0167 - val_mae: 0.1015\n",
            "Epoch 244/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0252 - mae: 0.1306 - val_loss: 0.0169 - val_mae: 0.1012\n",
            "Epoch 245/600\n",
            "150/150 [==============================] - 0s 127us/sample - loss: 0.0250 - mae: 0.1293 - val_loss: 0.0227 - val_mae: 0.1170\n",
            "Epoch 246/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0273 - mae: 0.1332 - val_loss: 0.0159 - val_mae: 0.0976\n",
            "Epoch 247/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0242 - mae: 0.1273 - val_loss: 0.0167 - val_mae: 0.1017\n",
            "Epoch 248/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0245 - mae: 0.1281 - val_loss: 0.0160 - val_mae: 0.0969\n",
            "Epoch 249/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0252 - mae: 0.1309 - val_loss: 0.0183 - val_mae: 0.1038\n",
            "Epoch 250/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0237 - mae: 0.1262 - val_loss: 0.0155 - val_mae: 0.0971\n",
            "Epoch 251/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0227 - mae: 0.1230 - val_loss: 0.0151 - val_mae: 0.0936\n",
            "Epoch 252/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0234 - mae: 0.1238 - val_loss: 0.0148 - val_mae: 0.0924\n",
            "Epoch 253/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0227 - mae: 0.1260 - val_loss: 0.0145 - val_mae: 0.0915\n",
            "Epoch 254/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0240 - mae: 0.1245 - val_loss: 0.0156 - val_mae: 0.0977\n",
            "Epoch 255/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0215 - mae: 0.1193 - val_loss: 0.0167 - val_mae: 0.1023\n",
            "Epoch 256/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0224 - mae: 0.1225 - val_loss: 0.0141 - val_mae: 0.0900\n",
            "Epoch 257/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0226 - mae: 0.1223 - val_loss: 0.0136 - val_mae: 0.0891\n",
            "Epoch 258/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0211 - mae: 0.1182 - val_loss: 0.0137 - val_mae: 0.0886\n",
            "Epoch 259/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0215 - mae: 0.1178 - val_loss: 0.0135 - val_mae: 0.0867\n",
            "Epoch 260/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0201 - mae: 0.1163 - val_loss: 0.0135 - val_mae: 0.0887\n",
            "Epoch 261/600\n",
            "150/150 [==============================] - 0s 259us/sample - loss: 0.0211 - mae: 0.1196 - val_loss: 0.0132 - val_mae: 0.0862\n",
            "Epoch 262/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0217 - mae: 0.1206 - val_loss: 0.0134 - val_mae: 0.0874\n",
            "Epoch 263/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0196 - mae: 0.1156 - val_loss: 0.0169 - val_mae: 0.0998\n",
            "Epoch 264/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0196 - mae: 0.1161 - val_loss: 0.0172 - val_mae: 0.1004\n",
            "Epoch 265/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0194 - mae: 0.1128 - val_loss: 0.0163 - val_mae: 0.1002\n",
            "Epoch 266/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0206 - mae: 0.1160 - val_loss: 0.0129 - val_mae: 0.0886\n",
            "Epoch 267/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0190 - mae: 0.1113 - val_loss: 0.0209 - val_mae: 0.1086\n",
            "Epoch 268/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0198 - mae: 0.1150 - val_loss: 0.0153 - val_mae: 0.0978\n",
            "Epoch 269/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0184 - mae: 0.1084 - val_loss: 0.0127 - val_mae: 0.0856\n",
            "Epoch 270/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0178 - mae: 0.1101 - val_loss: 0.0212 - val_mae: 0.1089\n",
            "Epoch 271/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0193 - mae: 0.1094 - val_loss: 0.0131 - val_mae: 0.0883\n",
            "Epoch 272/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0178 - mae: 0.1095 - val_loss: 0.0145 - val_mae: 0.0899\n",
            "Epoch 273/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0185 - mae: 0.1123 - val_loss: 0.0129 - val_mae: 0.0852\n",
            "Epoch 274/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0177 - mae: 0.1098 - val_loss: 0.0119 - val_mae: 0.0832\n",
            "Epoch 275/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0172 - mae: 0.1061 - val_loss: 0.0144 - val_mae: 0.0948\n",
            "Epoch 276/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0171 - mae: 0.1070 - val_loss: 0.0128 - val_mae: 0.0869\n",
            "Epoch 277/600\n",
            "150/150 [==============================] - 0s 218us/sample - loss: 0.0183 - mae: 0.1086 - val_loss: 0.0159 - val_mae: 0.0984\n",
            "Epoch 278/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0170 - mae: 0.1038 - val_loss: 0.0118 - val_mae: 0.0856\n",
            "Epoch 279/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0180 - mae: 0.1076 - val_loss: 0.0129 - val_mae: 0.0905\n",
            "Epoch 280/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0157 - mae: 0.1009 - val_loss: 0.0114 - val_mae: 0.0833\n",
            "Epoch 281/600\n",
            "150/150 [==============================] - 0s 174us/sample - loss: 0.0172 - mae: 0.1052 - val_loss: 0.0126 - val_mae: 0.0860\n",
            "Epoch 282/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0161 - mae: 0.1024 - val_loss: 0.0125 - val_mae: 0.0868\n",
            "Epoch 283/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0177 - mae: 0.1077 - val_loss: 0.0109 - val_mae: 0.0814\n",
            "Epoch 284/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0168 - mae: 0.1042 - val_loss: 0.0108 - val_mae: 0.0813\n",
            "Epoch 285/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0152 - mae: 0.0978 - val_loss: 0.0124 - val_mae: 0.0890\n",
            "Epoch 286/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0161 - mae: 0.1028 - val_loss: 0.0111 - val_mae: 0.0830\n",
            "Epoch 287/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0157 - mae: 0.0996 - val_loss: 0.0107 - val_mae: 0.0811\n",
            "Epoch 288/600\n",
            "150/150 [==============================] - 0s 190us/sample - loss: 0.0163 - mae: 0.1028 - val_loss: 0.0171 - val_mae: 0.1020\n",
            "Epoch 289/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0152 - mae: 0.1001 - val_loss: 0.0137 - val_mae: 0.0922\n",
            "Epoch 290/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0156 - mae: 0.1002 - val_loss: 0.0107 - val_mae: 0.0801\n",
            "Epoch 291/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0146 - mae: 0.0974 - val_loss: 0.0121 - val_mae: 0.0889\n",
            "Epoch 292/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0165 - mae: 0.1020 - val_loss: 0.0105 - val_mae: 0.0814\n",
            "Epoch 293/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0146 - mae: 0.0970 - val_loss: 0.0161 - val_mae: 0.0996\n",
            "Epoch 294/600\n",
            "150/150 [==============================] - 0s 229us/sample - loss: 0.0144 - mae: 0.0979 - val_loss: 0.0122 - val_mae: 0.0890\n",
            "Epoch 295/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0140 - mae: 0.0951 - val_loss: 0.0148 - val_mae: 0.0959\n",
            "Epoch 296/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0138 - mae: 0.0946 - val_loss: 0.0117 - val_mae: 0.0876\n",
            "Epoch 297/600\n",
            "150/150 [==============================] - 0s 137us/sample - loss: 0.0151 - mae: 0.0970 - val_loss: 0.0126 - val_mae: 0.0874\n",
            "Epoch 298/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0152 - mae: 0.0949 - val_loss: 0.0110 - val_mae: 0.0848\n",
            "Epoch 299/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0136 - mae: 0.0934 - val_loss: 0.0125 - val_mae: 0.0886\n",
            "Epoch 300/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0140 - mae: 0.0942 - val_loss: 0.0104 - val_mae: 0.0818\n",
            "Epoch 301/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0136 - mae: 0.0950 - val_loss: 0.0122 - val_mae: 0.0870\n",
            "Epoch 302/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0152 - mae: 0.0984 - val_loss: 0.0101 - val_mae: 0.0800\n",
            "Epoch 303/600\n",
            "150/150 [==============================] - 0s 202us/sample - loss: 0.0140 - mae: 0.0940 - val_loss: 0.0103 - val_mae: 0.0814\n",
            "Epoch 304/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0131 - mae: 0.0883 - val_loss: 0.0099 - val_mae: 0.0793\n",
            "Epoch 305/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0135 - mae: 0.0931 - val_loss: 0.0109 - val_mae: 0.0836\n",
            "Epoch 306/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0130 - mae: 0.0915 - val_loss: 0.0109 - val_mae: 0.0831\n",
            "Epoch 307/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0141 - mae: 0.0922 - val_loss: 0.0102 - val_mae: 0.0805\n",
            "Epoch 308/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0146 - mae: 0.0944 - val_loss: 0.0101 - val_mae: 0.0800\n",
            "Epoch 309/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0131 - mae: 0.0887 - val_loss: 0.0110 - val_mae: 0.0835\n",
            "Epoch 310/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0107 - val_mae: 0.0832\n",
            "Epoch 311/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0140 - mae: 0.0923 - val_loss: 0.0108 - val_mae: 0.0828\n",
            "Epoch 312/600\n",
            "150/150 [==============================] - 0s 235us/sample - loss: 0.0133 - mae: 0.0928 - val_loss: 0.0100 - val_mae: 0.0784\n",
            "Epoch 313/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0137 - mae: 0.0936 - val_loss: 0.0173 - val_mae: 0.1031\n",
            "Epoch 314/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0136 - mae: 0.0917 - val_loss: 0.0134 - val_mae: 0.0927\n",
            "Epoch 315/600\n",
            "150/150 [==============================] - 0s 222us/sample - loss: 0.0123 - mae: 0.0883 - val_loss: 0.0154 - val_mae: 0.0984\n",
            "Epoch 316/600\n",
            "150/150 [==============================] - 0s 229us/sample - loss: 0.0129 - mae: 0.0892 - val_loss: 0.0106 - val_mae: 0.0825\n",
            "Epoch 317/600\n",
            "150/150 [==============================] - 0s 142us/sample - loss: 0.0133 - mae: 0.0915 - val_loss: 0.0116 - val_mae: 0.0868\n",
            "Epoch 318/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0133 - mae: 0.0908 - val_loss: 0.0116 - val_mae: 0.0865\n",
            "Epoch 319/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0127 - mae: 0.0885 - val_loss: 0.0177 - val_mae: 0.1054\n",
            "Epoch 320/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0142 - mae: 0.0935 - val_loss: 0.0101 - val_mae: 0.0799\n",
            "Epoch 321/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0122 - mae: 0.0882 - val_loss: 0.0110 - val_mae: 0.0837\n",
            "Epoch 322/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0128 - mae: 0.0903 - val_loss: 0.0129 - val_mae: 0.0912\n",
            "Epoch 323/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0129 - mae: 0.0874 - val_loss: 0.0108 - val_mae: 0.0836\n",
            "Epoch 324/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0128 - mae: 0.0898 - val_loss: 0.0101 - val_mae: 0.0798\n",
            "Epoch 325/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0140 - mae: 0.0931 - val_loss: 0.0100 - val_mae: 0.0803\n",
            "Epoch 326/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0126 - mae: 0.0877 - val_loss: 0.0144 - val_mae: 0.0963\n",
            "Epoch 327/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0126 - mae: 0.0888 - val_loss: 0.0112 - val_mae: 0.0852\n",
            "Epoch 328/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0123 - mae: 0.0860 - val_loss: 0.0130 - val_mae: 0.0907\n",
            "Epoch 329/600\n",
            "150/150 [==============================] - 0s 208us/sample - loss: 0.0126 - mae: 0.0909 - val_loss: 0.0123 - val_mae: 0.0890\n",
            "Epoch 330/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0134 - mae: 0.0899 - val_loss: 0.0128 - val_mae: 0.0914\n",
            "Epoch 331/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0129 - mae: 0.0910 - val_loss: 0.0105 - val_mae: 0.0821\n",
            "Epoch 332/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0133 - mae: 0.0901 - val_loss: 0.0108 - val_mae: 0.0839\n",
            "Epoch 333/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0123 - mae: 0.0876 - val_loss: 0.0117 - val_mae: 0.0866\n",
            "Epoch 334/600\n",
            "150/150 [==============================] - 0s 132us/sample - loss: 0.0122 - mae: 0.0884 - val_loss: 0.0160 - val_mae: 0.0999\n",
            "Epoch 335/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0117 - mae: 0.0844 - val_loss: 0.0130 - val_mae: 0.0915\n",
            "Epoch 336/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0133 - mae: 0.0909 - val_loss: 0.0099 - val_mae: 0.0807\n",
            "Epoch 337/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0123 - mae: 0.0875 - val_loss: 0.0103 - val_mae: 0.0821\n",
            "Epoch 338/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0124 - mae: 0.0886 - val_loss: 0.0210 - val_mae: 0.1118\n",
            "Epoch 339/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0128 - mae: 0.0892 - val_loss: 0.0125 - val_mae: 0.0892\n",
            "Epoch 340/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0127 - mae: 0.0880 - val_loss: 0.0111 - val_mae: 0.0855\n",
            "Epoch 341/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0118 - mae: 0.0854 - val_loss: 0.0227 - val_mae: 0.1155\n",
            "Epoch 342/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0137 - mae: 0.0887 - val_loss: 0.0125 - val_mae: 0.0887\n",
            "Epoch 343/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0120 - mae: 0.0874 - val_loss: 0.0115 - val_mae: 0.0848\n",
            "Epoch 344/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0122 - mae: 0.0882 - val_loss: 0.0123 - val_mae: 0.0883\n",
            "Epoch 345/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0122 - mae: 0.0882 - val_loss: 0.0150 - val_mae: 0.0968\n",
            "Epoch 346/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0122 - mae: 0.0866 - val_loss: 0.0103 - val_mae: 0.0818\n",
            "Epoch 347/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0139 - mae: 0.0883 - val_loss: 0.0100 - val_mae: 0.0790\n",
            "Epoch 348/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0126 - mae: 0.0891 - val_loss: 0.0110 - val_mae: 0.0844\n",
            "Epoch 349/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0117 - mae: 0.0845 - val_loss: 0.0121 - val_mae: 0.0894\n",
            "Epoch 350/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0120 - mae: 0.0847 - val_loss: 0.0105 - val_mae: 0.0813\n",
            "Epoch 351/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0120 - mae: 0.0869 - val_loss: 0.0117 - val_mae: 0.0853\n",
            "Epoch 352/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0126 - mae: 0.0870 - val_loss: 0.0094 - val_mae: 0.0788\n",
            "Epoch 353/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0121 - mae: 0.0869 - val_loss: 0.0114 - val_mae: 0.0864\n",
            "Epoch 354/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0130 - mae: 0.0891 - val_loss: 0.0117 - val_mae: 0.0855\n",
            "Epoch 355/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0117 - mae: 0.0845 - val_loss: 0.0114 - val_mae: 0.0865\n",
            "Epoch 356/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0120 - mae: 0.0877 - val_loss: 0.0125 - val_mae: 0.0879\n",
            "Epoch 357/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0122 - mae: 0.0866 - val_loss: 0.0106 - val_mae: 0.0814\n",
            "Epoch 358/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0124 - mae: 0.0862 - val_loss: 0.0157 - val_mae: 0.0985\n",
            "Epoch 359/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0132 - mae: 0.0901 - val_loss: 0.0124 - val_mae: 0.0886\n",
            "Epoch 360/600\n",
            "150/150 [==============================] - 0s 239us/sample - loss: 0.0125 - mae: 0.0879 - val_loss: 0.0103 - val_mae: 0.0802\n",
            "Epoch 361/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0117 - mae: 0.0845 - val_loss: 0.0104 - val_mae: 0.0800\n",
            "Epoch 362/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0118 - mae: 0.0871 - val_loss: 0.0105 - val_mae: 0.0808\n",
            "Epoch 363/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0110 - mae: 0.0808 - val_loss: 0.0182 - val_mae: 0.1072\n",
            "Epoch 364/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0160 - val_mae: 0.1005\n",
            "Epoch 365/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0138 - val_mae: 0.0944\n",
            "Epoch 366/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0121 - mae: 0.0865 - val_loss: 0.0099 - val_mae: 0.0815\n",
            "Epoch 367/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0131 - mae: 0.0895 - val_loss: 0.0112 - val_mae: 0.0867\n",
            "Epoch 368/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0120 - mae: 0.0847 - val_loss: 0.0106 - val_mae: 0.0808\n",
            "Epoch 369/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0121 - mae: 0.0865 - val_loss: 0.0108 - val_mae: 0.0842\n",
            "Epoch 370/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0122 - mae: 0.0876 - val_loss: 0.0128 - val_mae: 0.0897\n",
            "Epoch 371/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0118 - mae: 0.0849 - val_loss: 0.0110 - val_mae: 0.0827\n",
            "Epoch 372/600\n",
            "150/150 [==============================] - 0s 214us/sample - loss: 0.0119 - mae: 0.0840 - val_loss: 0.0100 - val_mae: 0.0824\n",
            "Epoch 373/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0118 - mae: 0.0866 - val_loss: 0.0143 - val_mae: 0.0970\n",
            "Epoch 374/600\n",
            "150/150 [==============================] - 0s 218us/sample - loss: 0.0124 - mae: 0.0859 - val_loss: 0.0100 - val_mae: 0.0797\n",
            "Epoch 375/600\n",
            "150/150 [==============================] - 0s 140us/sample - loss: 0.0118 - mae: 0.0862 - val_loss: 0.0226 - val_mae: 0.1152\n",
            "Epoch 376/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0143 - mae: 0.0945 - val_loss: 0.0110 - val_mae: 0.0863\n",
            "Epoch 377/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0128 - mae: 0.0904 - val_loss: 0.0113 - val_mae: 0.0837\n",
            "Epoch 378/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0114 - mae: 0.0821 - val_loss: 0.0161 - val_mae: 0.1008\n",
            "Epoch 379/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0122 - mae: 0.0859 - val_loss: 0.0104 - val_mae: 0.0832\n",
            "Epoch 380/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0117 - mae: 0.0856 - val_loss: 0.0134 - val_mae: 0.0918\n",
            "Epoch 381/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0117 - val_mae: 0.0854\n",
            "Epoch 382/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0119 - mae: 0.0835 - val_loss: 0.0119 - val_mae: 0.0894\n",
            "Epoch 383/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0119 - mae: 0.0862 - val_loss: 0.0110 - val_mae: 0.0860\n",
            "Epoch 384/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0125 - mae: 0.0867 - val_loss: 0.0102 - val_mae: 0.0822\n",
            "Epoch 385/600\n",
            "150/150 [==============================] - 0s 189us/sample - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0107 - val_mae: 0.0822\n",
            "Epoch 386/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0120 - mae: 0.0845 - val_loss: 0.0095 - val_mae: 0.0799\n",
            "Epoch 387/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0130 - mae: 0.0884 - val_loss: 0.0110 - val_mae: 0.0869\n",
            "Epoch 388/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0115 - val_mae: 0.0840\n",
            "Epoch 389/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0134 - val_mae: 0.0909\n",
            "Epoch 390/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0117 - mae: 0.0843 - val_loss: 0.0108 - val_mae: 0.0860\n",
            "Epoch 391/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0117 - mae: 0.0827 - val_loss: 0.0121 - val_mae: 0.0905\n",
            "Epoch 392/600\n",
            "150/150 [==============================] - 0s 228us/sample - loss: 0.0119 - mae: 0.0858 - val_loss: 0.0112 - val_mae: 0.0878\n",
            "Epoch 393/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0112 - mae: 0.0847 - val_loss: 0.0115 - val_mae: 0.0876\n",
            "Epoch 394/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0109 - mae: 0.0817 - val_loss: 0.0093 - val_mae: 0.0774\n",
            "Epoch 395/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0125 - mae: 0.0874 - val_loss: 0.0093 - val_mae: 0.0782\n",
            "Epoch 396/600\n",
            "150/150 [==============================] - 0s 215us/sample - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0093 - val_mae: 0.0784\n",
            "Epoch 397/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0117 - val_mae: 0.0858\n",
            "Epoch 398/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0177 - val_mae: 0.1046\n",
            "Epoch 399/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0118 - mae: 0.0866 - val_loss: 0.0112 - val_mae: 0.0837\n",
            "Epoch 400/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0112 - mae: 0.0816 - val_loss: 0.0092 - val_mae: 0.0786\n",
            "Epoch 401/600\n",
            "150/150 [==============================] - 0s 139us/sample - loss: 0.0122 - mae: 0.0873 - val_loss: 0.0112 - val_mae: 0.0845\n",
            "Epoch 402/600\n",
            "150/150 [==============================] - 0s 141us/sample - loss: 0.0120 - mae: 0.0863 - val_loss: 0.0092 - val_mae: 0.0782\n",
            "Epoch 403/600\n",
            "150/150 [==============================] - 0s 148us/sample - loss: 0.0123 - mae: 0.0857 - val_loss: 0.0108 - val_mae: 0.0821\n",
            "Epoch 404/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0114 - mae: 0.0837 - val_loss: 0.0109 - val_mae: 0.0834\n",
            "Epoch 405/600\n",
            "150/150 [==============================] - 0s 234us/sample - loss: 0.0114 - mae: 0.0836 - val_loss: 0.0107 - val_mae: 0.0815\n",
            "Epoch 406/600\n",
            "150/150 [==============================] - 0s 216us/sample - loss: 0.0118 - mae: 0.0848 - val_loss: 0.0235 - val_mae: 0.1184\n",
            "Epoch 407/600\n",
            "150/150 [==============================] - 0s 226us/sample - loss: 0.0123 - mae: 0.0869 - val_loss: 0.0135 - val_mae: 0.0923\n",
            "Epoch 408/600\n",
            "150/150 [==============================] - 0s 210us/sample - loss: 0.0115 - mae: 0.0846 - val_loss: 0.0089 - val_mae: 0.0768\n",
            "Epoch 409/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0117 - mae: 0.0851 - val_loss: 0.0246 - val_mae: 0.1207\n",
            "Epoch 410/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0123 - mae: 0.0844 - val_loss: 0.0120 - val_mae: 0.0902\n",
            "Epoch 411/600\n",
            "150/150 [==============================] - 0s 147us/sample - loss: 0.0131 - mae: 0.0912 - val_loss: 0.0119 - val_mae: 0.0861\n",
            "Epoch 412/600\n",
            "150/150 [==============================] - 0s 144us/sample - loss: 0.0118 - mae: 0.0870 - val_loss: 0.0116 - val_mae: 0.0854\n",
            "Epoch 413/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0113 - mae: 0.0838 - val_loss: 0.0095 - val_mae: 0.0801\n",
            "Epoch 414/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0108 - mae: 0.0814 - val_loss: 0.0134 - val_mae: 0.0917\n",
            "Epoch 415/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0093 - val_mae: 0.0806\n",
            "Epoch 416/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0123 - mae: 0.0861 - val_loss: 0.0103 - val_mae: 0.0844\n",
            "Epoch 417/600\n",
            "150/150 [==============================] - 0s 184us/sample - loss: 0.0117 - mae: 0.0836 - val_loss: 0.0090 - val_mae: 0.0770\n",
            "Epoch 418/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0115 - mae: 0.0831 - val_loss: 0.0109 - val_mae: 0.0815\n",
            "Epoch 419/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0122 - mae: 0.0856 - val_loss: 0.0128 - val_mae: 0.0898\n",
            "Epoch 420/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0108 - mae: 0.0806 - val_loss: 0.0102 - val_mae: 0.0839\n",
            "Epoch 421/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0129 - mae: 0.0886 - val_loss: 0.0116 - val_mae: 0.0899\n",
            "Epoch 422/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0113 - mae: 0.0828 - val_loss: 0.0100 - val_mae: 0.0808\n",
            "Epoch 423/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0118 - mae: 0.0860 - val_loss: 0.0104 - val_mae: 0.0811\n",
            "Epoch 424/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0116 - mae: 0.0838 - val_loss: 0.0254 - val_mae: 0.1222\n",
            "Epoch 425/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0128 - mae: 0.0875 - val_loss: 0.0101 - val_mae: 0.0801\n",
            "Epoch 426/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0116 - mae: 0.0836 - val_loss: 0.0129 - val_mae: 0.0917\n",
            "Epoch 427/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0123 - mae: 0.0860 - val_loss: 0.0229 - val_mae: 0.1180\n",
            "Epoch 428/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0120 - mae: 0.0859 - val_loss: 0.0097 - val_mae: 0.0812\n",
            "Epoch 429/600\n",
            "150/150 [==============================] - 0s 185us/sample - loss: 0.0113 - mae: 0.0846 - val_loss: 0.0108 - val_mae: 0.0807\n",
            "Epoch 430/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0108 - mae: 0.0811 - val_loss: 0.0094 - val_mae: 0.0782\n",
            "Epoch 431/600\n",
            "150/150 [==============================] - 0s 277us/sample - loss: 0.0115 - mae: 0.0854 - val_loss: 0.0136 - val_mae: 0.0924\n",
            "Epoch 432/600\n",
            "150/150 [==============================] - 0s 206us/sample - loss: 0.0116 - mae: 0.0836 - val_loss: 0.0109 - val_mae: 0.0834\n",
            "Epoch 433/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0113 - mae: 0.0834 - val_loss: 0.0163 - val_mae: 0.1029\n",
            "Epoch 434/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0115 - mae: 0.0844 - val_loss: 0.0138 - val_mae: 0.0933\n",
            "Epoch 435/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0115 - mae: 0.0857 - val_loss: 0.0170 - val_mae: 0.1022\n",
            "Epoch 436/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0114 - mae: 0.0829 - val_loss: 0.0139 - val_mae: 0.0931\n",
            "Epoch 437/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0117 - mae: 0.0864 - val_loss: 0.0107 - val_mae: 0.0820\n",
            "Epoch 438/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0116 - mae: 0.0837 - val_loss: 0.0123 - val_mae: 0.0926\n",
            "Epoch 439/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0116 - mae: 0.0832 - val_loss: 0.0121 - val_mae: 0.0873\n",
            "Epoch 440/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0107 - mae: 0.0808 - val_loss: 0.0108 - val_mae: 0.0827\n",
            "Epoch 441/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0122 - mae: 0.0862 - val_loss: 0.0097 - val_mae: 0.0820\n",
            "Epoch 442/600\n",
            "150/150 [==============================] - 0s 206us/sample - loss: 0.0115 - mae: 0.0873 - val_loss: 0.0090 - val_mae: 0.0773\n",
            "Epoch 443/600\n",
            "150/150 [==============================] - 0s 162us/sample - loss: 0.0108 - mae: 0.0806 - val_loss: 0.0090 - val_mae: 0.0767\n",
            "Epoch 444/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0112 - mae: 0.0832 - val_loss: 0.0121 - val_mae: 0.0897\n",
            "Epoch 445/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0135 - mae: 0.0912 - val_loss: 0.0095 - val_mae: 0.0807\n",
            "Epoch 446/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0112 - mae: 0.0827 - val_loss: 0.0101 - val_mae: 0.0815\n",
            "Epoch 447/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.0116 - mae: 0.0838 - val_loss: 0.0094 - val_mae: 0.0791\n",
            "Epoch 448/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0120 - mae: 0.0867 - val_loss: 0.0105 - val_mae: 0.0831\n",
            "Epoch 449/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0100 - val_mae: 0.0796\n",
            "Epoch 450/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0115 - mae: 0.0837 - val_loss: 0.0096 - val_mae: 0.0783\n",
            "Epoch 451/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0111 - mae: 0.0830 - val_loss: 0.0106 - val_mae: 0.0842\n",
            "Epoch 452/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0115 - mae: 0.0816 - val_loss: 0.0132 - val_mae: 0.0925\n",
            "Epoch 453/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0100 - val_mae: 0.0828\n",
            "Epoch 454/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0107 - mae: 0.0818 - val_loss: 0.0278 - val_mae: 0.1305\n",
            "Epoch 455/600\n",
            "150/150 [==============================] - 0s 234us/sample - loss: 0.0118 - mae: 0.0839 - val_loss: 0.0093 - val_mae: 0.0771\n",
            "Epoch 456/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0113 - mae: 0.0852 - val_loss: 0.0094 - val_mae: 0.0799\n",
            "Epoch 457/600\n",
            "150/150 [==============================] - 0s 234us/sample - loss: 0.0120 - mae: 0.0861 - val_loss: 0.0108 - val_mae: 0.0817\n",
            "Epoch 458/600\n",
            "150/150 [==============================] - 0s 146us/sample - loss: 0.0117 - mae: 0.0855 - val_loss: 0.0118 - val_mae: 0.0906\n",
            "Epoch 459/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0106 - mae: 0.0799 - val_loss: 0.0188 - val_mae: 0.1079\n",
            "Epoch 460/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0125 - mae: 0.0863 - val_loss: 0.0167 - val_mae: 0.1026\n",
            "Epoch 461/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0109 - mae: 0.0830 - val_loss: 0.0123 - val_mae: 0.0883\n",
            "Epoch 462/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0126 - mae: 0.0867 - val_loss: 0.0098 - val_mae: 0.0822\n",
            "Epoch 463/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0111 - mae: 0.0830 - val_loss: 0.0100 - val_mae: 0.0805\n",
            "Epoch 464/600\n",
            "150/150 [==============================] - 0s 151us/sample - loss: 0.0102 - mae: 0.0786 - val_loss: 0.0171 - val_mae: 0.1025\n",
            "Epoch 465/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0128 - mae: 0.0852 - val_loss: 0.0102 - val_mae: 0.0815\n",
            "Epoch 466/600\n",
            "150/150 [==============================] - 0s 165us/sample - loss: 0.0105 - mae: 0.0807 - val_loss: 0.0146 - val_mae: 0.0954\n",
            "Epoch 467/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0113 - mae: 0.0831 - val_loss: 0.0191 - val_mae: 0.1086\n",
            "Epoch 468/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.0115 - mae: 0.0847 - val_loss: 0.0108 - val_mae: 0.0860\n",
            "Epoch 469/600\n",
            "150/150 [==============================] - 0s 199us/sample - loss: 0.0110 - mae: 0.0816 - val_loss: 0.0091 - val_mae: 0.0798\n",
            "Epoch 470/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0136 - val_mae: 0.0937\n",
            "Epoch 471/600\n",
            "150/150 [==============================] - 0s 153us/sample - loss: 0.0107 - mae: 0.0801 - val_loss: 0.0108 - val_mae: 0.0845\n",
            "Epoch 472/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0113 - mae: 0.0842 - val_loss: 0.0141 - val_mae: 0.0957\n",
            "Epoch 473/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0114 - mae: 0.0820 - val_loss: 0.0096 - val_mae: 0.0786\n",
            "Epoch 474/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0122 - mae: 0.0877 - val_loss: 0.0113 - val_mae: 0.0888\n",
            "Epoch 475/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0119 - mae: 0.0844 - val_loss: 0.0095 - val_mae: 0.0811\n",
            "Epoch 476/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0109 - mae: 0.0819 - val_loss: 0.0093 - val_mae: 0.0783\n",
            "Epoch 477/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0113 - mae: 0.0835 - val_loss: 0.0117 - val_mae: 0.0856\n",
            "Epoch 478/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0093 - val_mae: 0.0798\n",
            "Epoch 479/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0115 - mae: 0.0828 - val_loss: 0.0105 - val_mae: 0.0820\n",
            "Epoch 480/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0122 - mae: 0.0857 - val_loss: 0.0148 - val_mae: 0.0973\n",
            "Epoch 481/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0098 - val_mae: 0.0810\n",
            "Epoch 482/600\n",
            "150/150 [==============================] - 0s 172us/sample - loss: 0.0113 - mae: 0.0840 - val_loss: 0.0096 - val_mae: 0.0784\n",
            "Epoch 483/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0113 - mae: 0.0825 - val_loss: 0.0102 - val_mae: 0.0827\n",
            "Epoch 484/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0110 - mae: 0.0816 - val_loss: 0.0096 - val_mae: 0.0812\n",
            "Epoch 485/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0113 - mae: 0.0847 - val_loss: 0.0099 - val_mae: 0.0801\n",
            "Epoch 486/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0107 - mae: 0.0809 - val_loss: 0.0149 - val_mae: 0.0982\n",
            "Epoch 487/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0126 - mae: 0.0878 - val_loss: 0.0122 - val_mae: 0.0878\n",
            "Epoch 488/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0108 - mae: 0.0810 - val_loss: 0.0116 - val_mae: 0.0863\n",
            "Epoch 489/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0097 - val_mae: 0.0790\n",
            "Epoch 490/600\n",
            "150/150 [==============================] - 0s 269us/sample - loss: 0.0113 - mae: 0.0829 - val_loss: 0.0138 - val_mae: 0.0961\n",
            "Epoch 491/600\n",
            "150/150 [==============================] - 0s 187us/sample - loss: 0.0123 - mae: 0.0880 - val_loss: 0.0118 - val_mae: 0.0905\n",
            "Epoch 492/600\n",
            "150/150 [==============================] - 0s 207us/sample - loss: 0.0105 - mae: 0.0795 - val_loss: 0.0113 - val_mae: 0.0880\n",
            "Epoch 493/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0116 - mae: 0.0835 - val_loss: 0.0101 - val_mae: 0.0835\n",
            "Epoch 494/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0111 - mae: 0.0815 - val_loss: 0.0108 - val_mae: 0.0871\n",
            "Epoch 495/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0124 - mae: 0.0872 - val_loss: 0.0147 - val_mae: 0.0961\n",
            "Epoch 496/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0115 - mae: 0.0833 - val_loss: 0.0133 - val_mae: 0.0933\n",
            "Epoch 497/600\n",
            "150/150 [==============================] - 0s 192us/sample - loss: 0.0117 - mae: 0.0853 - val_loss: 0.0223 - val_mae: 0.1167\n",
            "Epoch 498/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0109 - mae: 0.0838 - val_loss: 0.0100 - val_mae: 0.0834\n",
            "Epoch 499/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0102 - mae: 0.0779 - val_loss: 0.0151 - val_mae: 0.0979\n",
            "Epoch 500/600\n",
            "150/150 [==============================] - 0s 260us/sample - loss: 0.0113 - mae: 0.0838 - val_loss: 0.0091 - val_mae: 0.0792\n",
            "Epoch 501/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0105 - mae: 0.0787 - val_loss: 0.0122 - val_mae: 0.0883\n",
            "Epoch 502/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0122 - mae: 0.0875 - val_loss: 0.0105 - val_mae: 0.0835\n",
            "Epoch 503/600\n",
            "150/150 [==============================] - 0s 188us/sample - loss: 0.0109 - mae: 0.0825 - val_loss: 0.0168 - val_mae: 0.1019\n",
            "Epoch 504/600\n",
            "150/150 [==============================] - 0s 205us/sample - loss: 0.0101 - mae: 0.0783 - val_loss: 0.0145 - val_mae: 0.0961\n",
            "Epoch 505/600\n",
            "150/150 [==============================] - 0s 203us/sample - loss: 0.0116 - mae: 0.0851 - val_loss: 0.0188 - val_mae: 0.1087\n",
            "Epoch 506/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0119 - mae: 0.0854 - val_loss: 0.0098 - val_mae: 0.0823\n",
            "Epoch 507/600\n",
            "150/150 [==============================] - 0s 149us/sample - loss: 0.0104 - mae: 0.0786 - val_loss: 0.0193 - val_mae: 0.1097\n",
            "Epoch 508/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0109 - mae: 0.0810 - val_loss: 0.0091 - val_mae: 0.0781\n",
            "Epoch 509/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0116 - mae: 0.0852 - val_loss: 0.0100 - val_mae: 0.0794\n",
            "Epoch 510/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0115 - mae: 0.0864 - val_loss: 0.0128 - val_mae: 0.0899\n",
            "Epoch 511/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0115 - mae: 0.0839 - val_loss: 0.0112 - val_mae: 0.0887\n",
            "Epoch 512/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0115 - mae: 0.0844 - val_loss: 0.0091 - val_mae: 0.0794\n",
            "Epoch 513/600\n",
            "150/150 [==============================] - 0s 213us/sample - loss: 0.0107 - mae: 0.0784 - val_loss: 0.0093 - val_mae: 0.0789\n",
            "Epoch 514/600\n",
            "150/150 [==============================] - 0s 234us/sample - loss: 0.0109 - mae: 0.0841 - val_loss: 0.0094 - val_mae: 0.0779\n",
            "Epoch 515/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0121 - mae: 0.0860 - val_loss: 0.0106 - val_mae: 0.0818\n",
            "Epoch 516/600\n",
            "150/150 [==============================] - 0s 164us/sample - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0132 - val_mae: 0.0925\n",
            "Epoch 517/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0111 - mae: 0.0826 - val_loss: 0.0099 - val_mae: 0.0801\n",
            "Epoch 518/600\n",
            "150/150 [==============================] - 0s 158us/sample - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0100 - val_mae: 0.0823\n",
            "Epoch 519/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0124 - mae: 0.0857 - val_loss: 0.0121 - val_mae: 0.0880\n",
            "Epoch 520/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0104 - mae: 0.0803 - val_loss: 0.0110 - val_mae: 0.0841\n",
            "Epoch 521/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0117 - mae: 0.0853 - val_loss: 0.0105 - val_mae: 0.0820\n",
            "Epoch 522/600\n",
            "150/150 [==============================] - 0s 193us/sample - loss: 0.0119 - mae: 0.0864 - val_loss: 0.0098 - val_mae: 0.0819\n",
            "Epoch 523/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0107 - mae: 0.0792 - val_loss: 0.0116 - val_mae: 0.0872\n",
            "Epoch 524/600\n",
            "150/150 [==============================] - 0s 160us/sample - loss: 0.0120 - mae: 0.0864 - val_loss: 0.0136 - val_mae: 0.0941\n",
            "Epoch 525/600\n",
            "150/150 [==============================] - 0s 173us/sample - loss: 0.0110 - mae: 0.0819 - val_loss: 0.0143 - val_mae: 0.0964\n",
            "Epoch 526/600\n",
            "150/150 [==============================] - 0s 159us/sample - loss: 0.0117 - mae: 0.0857 - val_loss: 0.0188 - val_mae: 0.1087\n",
            "Epoch 527/600\n",
            "150/150 [==============================] - 0s 191us/sample - loss: 0.0108 - mae: 0.0817 - val_loss: 0.0100 - val_mae: 0.0802\n",
            "Epoch 528/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0116 - mae: 0.0850 - val_loss: 0.0125 - val_mae: 0.0894\n",
            "Epoch 529/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0108 - mae: 0.0820 - val_loss: 0.0111 - val_mae: 0.0878\n",
            "Epoch 530/600\n",
            "150/150 [==============================] - 0s 179us/sample - loss: 0.0114 - mae: 0.0842 - val_loss: 0.0096 - val_mae: 0.0800\n",
            "Epoch 531/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0110 - mae: 0.0815 - val_loss: 0.0107 - val_mae: 0.0821\n",
            "Epoch 532/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0111 - mae: 0.0817 - val_loss: 0.0095 - val_mae: 0.0779\n",
            "Epoch 533/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.0118 - mae: 0.0849 - val_loss: 0.0099 - val_mae: 0.0814\n",
            "Epoch 534/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0111 - val_mae: 0.0866\n",
            "Epoch 535/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0108 - mae: 0.0820 - val_loss: 0.0116 - val_mae: 0.0893\n",
            "Epoch 536/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0124 - mae: 0.0876 - val_loss: 0.0120 - val_mae: 0.0885\n",
            "Epoch 537/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0104 - mae: 0.0803 - val_loss: 0.0128 - val_mae: 0.0934\n",
            "Epoch 538/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0110 - mae: 0.0829 - val_loss: 0.0098 - val_mae: 0.0827\n",
            "Epoch 539/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0116 - mae: 0.0840 - val_loss: 0.0111 - val_mae: 0.0849\n",
            "Epoch 540/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0100 - mae: 0.0773 - val_loss: 0.0117 - val_mae: 0.0863\n",
            "Epoch 541/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0121 - mae: 0.0856 - val_loss: 0.0098 - val_mae: 0.0798\n",
            "Epoch 542/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0111 - val_mae: 0.0840\n",
            "Epoch 543/600\n",
            "150/150 [==============================] - 0s 163us/sample - loss: 0.0113 - mae: 0.0839 - val_loss: 0.0099 - val_mae: 0.0796\n",
            "Epoch 544/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0108 - mae: 0.0829 - val_loss: 0.0115 - val_mae: 0.0872\n",
            "Epoch 545/600\n",
            "150/150 [==============================] - 0s 161us/sample - loss: 0.0108 - mae: 0.0834 - val_loss: 0.0267 - val_mae: 0.1262\n",
            "Epoch 546/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0124 - mae: 0.0869 - val_loss: 0.0113 - val_mae: 0.0878\n",
            "Epoch 547/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0107 - mae: 0.0832 - val_loss: 0.0104 - val_mae: 0.0818\n",
            "Epoch 548/600\n",
            "150/150 [==============================] - 0s 194us/sample - loss: 0.0114 - mae: 0.0842 - val_loss: 0.0102 - val_mae: 0.0811\n",
            "Epoch 549/600\n",
            "150/150 [==============================] - 0s 152us/sample - loss: 0.0109 - mae: 0.0816 - val_loss: 0.0117 - val_mae: 0.0860\n",
            "Epoch 550/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0110 - mae: 0.0841 - val_loss: 0.0136 - val_mae: 0.0934\n",
            "Epoch 551/600\n",
            "150/150 [==============================] - 0s 273us/sample - loss: 0.0106 - mae: 0.0804 - val_loss: 0.0127 - val_mae: 0.0904\n",
            "Epoch 552/600\n",
            "150/150 [==============================] - 0s 178us/sample - loss: 0.0119 - mae: 0.0843 - val_loss: 0.0108 - val_mae: 0.0869\n",
            "Epoch 553/600\n",
            "150/150 [==============================] - 0s 177us/sample - loss: 0.0100 - mae: 0.0785 - val_loss: 0.0101 - val_mae: 0.0805\n",
            "Epoch 554/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0105 - mae: 0.0801 - val_loss: 0.0140 - val_mae: 0.0941\n",
            "Epoch 555/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0110 - mae: 0.0812 - val_loss: 0.0130 - val_mae: 0.0916\n",
            "Epoch 556/600\n",
            "150/150 [==============================] - 0s 166us/sample - loss: 0.0107 - mae: 0.0821 - val_loss: 0.0100 - val_mae: 0.0824\n",
            "Epoch 557/600\n",
            "150/150 [==============================] - 0s 197us/sample - loss: 0.0124 - mae: 0.0880 - val_loss: 0.0125 - val_mae: 0.0902\n",
            "Epoch 558/600\n",
            "150/150 [==============================] - 0s 209us/sample - loss: 0.0105 - mae: 0.0798 - val_loss: 0.0128 - val_mae: 0.0902\n",
            "Epoch 559/600\n",
            "150/150 [==============================] - 0s 212us/sample - loss: 0.0098 - mae: 0.0783 - val_loss: 0.0116 - val_mae: 0.0866\n",
            "Epoch 560/600\n",
            "150/150 [==============================] - 0s 233us/sample - loss: 0.0118 - mae: 0.0878 - val_loss: 0.0117 - val_mae: 0.0892\n",
            "Epoch 561/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0107 - mae: 0.0821 - val_loss: 0.0154 - val_mae: 0.0982\n",
            "Epoch 562/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0115 - mae: 0.0842 - val_loss: 0.0095 - val_mae: 0.0803\n",
            "Epoch 563/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0111 - mae: 0.0826 - val_loss: 0.0104 - val_mae: 0.0813\n",
            "Epoch 564/600\n",
            "150/150 [==============================] - 0s 155us/sample - loss: 0.0106 - mae: 0.0808 - val_loss: 0.0120 - val_mae: 0.0876\n",
            "Epoch 565/600\n",
            "150/150 [==============================] - 0s 236us/sample - loss: 0.0120 - mae: 0.0830 - val_loss: 0.0101 - val_mae: 0.0831\n",
            "Epoch 566/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0113 - mae: 0.0845 - val_loss: 0.0119 - val_mae: 0.0906\n",
            "Epoch 567/600\n",
            "150/150 [==============================] - 0s 201us/sample - loss: 0.0114 - mae: 0.0851 - val_loss: 0.0223 - val_mae: 0.1151\n",
            "Epoch 568/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0108 - mae: 0.0809 - val_loss: 0.0117 - val_mae: 0.0889\n",
            "Epoch 569/600\n",
            "150/150 [==============================] - 0s 200us/sample - loss: 0.0105 - mae: 0.0812 - val_loss: 0.0128 - val_mae: 0.0902\n",
            "Epoch 570/600\n",
            "150/150 [==============================] - 0s 186us/sample - loss: 0.0107 - mae: 0.0814 - val_loss: 0.0208 - val_mae: 0.1126\n",
            "Epoch 571/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0109 - mae: 0.0811 - val_loss: 0.0153 - val_mae: 0.0982\n",
            "Epoch 572/600\n",
            "150/150 [==============================] - 0s 211us/sample - loss: 0.0118 - mae: 0.0844 - val_loss: 0.0155 - val_mae: 0.1006\n",
            "Epoch 573/600\n",
            "150/150 [==============================] - 0s 198us/sample - loss: 0.0109 - mae: 0.0833 - val_loss: 0.0138 - val_mae: 0.0946\n",
            "Epoch 574/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0119 - mae: 0.0882 - val_loss: 0.0133 - val_mae: 0.0928\n",
            "Epoch 575/600\n",
            "150/150 [==============================] - 0s 143us/sample - loss: 0.0102 - mae: 0.0811 - val_loss: 0.0162 - val_mae: 0.1012\n",
            "Epoch 576/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0104 - val_mae: 0.0841\n",
            "Epoch 577/600\n",
            "150/150 [==============================] - 0s 181us/sample - loss: 0.0100 - mae: 0.0786 - val_loss: 0.0118 - val_mae: 0.0903\n",
            "Epoch 578/600\n",
            "150/150 [==============================] - 0s 169us/sample - loss: 0.0111 - mae: 0.0814 - val_loss: 0.0108 - val_mae: 0.0864\n",
            "Epoch 579/600\n",
            "150/150 [==============================] - 0s 232us/sample - loss: 0.0114 - mae: 0.0858 - val_loss: 0.0122 - val_mae: 0.0900\n",
            "Epoch 580/600\n",
            "150/150 [==============================] - 0s 180us/sample - loss: 0.0112 - mae: 0.0817 - val_loss: 0.0137 - val_mae: 0.0938\n",
            "Epoch 581/600\n",
            "150/150 [==============================] - 0s 277us/sample - loss: 0.0117 - mae: 0.0859 - val_loss: 0.0112 - val_mae: 0.0868\n",
            "Epoch 582/600\n",
            "150/150 [==============================] - 0s 176us/sample - loss: 0.0106 - mae: 0.0799 - val_loss: 0.0099 - val_mae: 0.0803\n",
            "Epoch 583/600\n",
            "150/150 [==============================] - 0s 196us/sample - loss: 0.0107 - mae: 0.0811 - val_loss: 0.0102 - val_mae: 0.0835\n",
            "Epoch 584/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0108 - mae: 0.0807 - val_loss: 0.0119 - val_mae: 0.0900\n",
            "Epoch 585/600\n",
            "150/150 [==============================] - 0s 195us/sample - loss: 0.0111 - mae: 0.0812 - val_loss: 0.0096 - val_mae: 0.0820\n",
            "Epoch 586/600\n",
            "150/150 [==============================] - 0s 221us/sample - loss: 0.0112 - mae: 0.0822 - val_loss: 0.0123 - val_mae: 0.0889\n",
            "Epoch 587/600\n",
            "150/150 [==============================] - 0s 145us/sample - loss: 0.0120 - mae: 0.0867 - val_loss: 0.0100 - val_mae: 0.0829\n",
            "Epoch 588/600\n",
            "150/150 [==============================] - 0s 167us/sample - loss: 0.0112 - mae: 0.0841 - val_loss: 0.0120 - val_mae: 0.0908\n",
            "Epoch 589/600\n",
            "150/150 [==============================] - 0s 154us/sample - loss: 0.0101 - mae: 0.0805 - val_loss: 0.0112 - val_mae: 0.0843\n",
            "Epoch 590/600\n",
            "150/150 [==============================] - 0s 175us/sample - loss: 0.0100 - mae: 0.0791 - val_loss: 0.0118 - val_mae: 0.0863\n",
            "Epoch 591/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0107 - val_mae: 0.0854\n",
            "Epoch 592/600\n",
            "150/150 [==============================] - 0s 168us/sample - loss: 0.0114 - mae: 0.0831 - val_loss: 0.0134 - val_mae: 0.0948\n",
            "Epoch 593/600\n",
            "150/150 [==============================] - 0s 150us/sample - loss: 0.0119 - mae: 0.0873 - val_loss: 0.0119 - val_mae: 0.0866\n",
            "Epoch 594/600\n",
            "150/150 [==============================] - 0s 182us/sample - loss: 0.0108 - mae: 0.0829 - val_loss: 0.0129 - val_mae: 0.0901\n",
            "Epoch 595/600\n",
            "150/150 [==============================] - 0s 156us/sample - loss: 0.0119 - mae: 0.0874 - val_loss: 0.0115 - val_mae: 0.0877\n",
            "Epoch 596/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0107 - mae: 0.0810 - val_loss: 0.0096 - val_mae: 0.0803\n",
            "Epoch 597/600\n",
            "150/150 [==============================] - 0s 171us/sample - loss: 0.0105 - mae: 0.0809 - val_loss: 0.0100 - val_mae: 0.0808\n",
            "Epoch 598/600\n",
            "150/150 [==============================] - 0s 183us/sample - loss: 0.0103 - mae: 0.0804 - val_loss: 0.0096 - val_mae: 0.0807\n",
            "Epoch 599/600\n",
            "150/150 [==============================] - 0s 170us/sample - loss: 0.0110 - mae: 0.0851 - val_loss: 0.0139 - val_mae: 0.0966\n",
            "Epoch 600/600\n",
            "150/150 [==============================] - 0s 157us/sample - loss: 0.0109 - mae: 0.0830 - val_loss: 0.0116 - val_mae: 0.0860\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HSYMdjnQyyBa",
        "outputId": "fa679777-482a-4b32-8dcd-39887a700cac"
      },
      "source": [
        "#Toy Problem Y=sin(x) 300 samples of period -2pi to 2pi\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 300\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x1_values = np.random.uniform(low=-(2*math.pi), high=2*math.pi,size=SAMPLES)\n",
        "np.random.shuffle(x1_values)\n",
        "y1_values = np.sin(x1_values)\n",
        "plt.plot(x1_values,y1_values, 'b.')\n",
        "plt.show()\n",
        "y1_values += 0.1*np.random.randn(*y1_values.shape)\n",
        "plt.plot(x1_values, y1_values, 'b.')\n",
        "#plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x1_train, x1_validate, x1_test = np.split(x1_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y1_train, y1_validate, y1_test = np.split(y1_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x1_train.size + x1_validate.size + x1_test.size) == SAMPLES\n",
        "plt.plot(x1_train, y1_train, 'b.', label=\"Train\")\n",
        "plt.plot(x1_validate, y1_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x1_test, y1_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_2.summary()\n",
        "history_2 = model_2.fit(x1_train, y1_train, epochs=600, batch_size=16, validation_data=(x1_validate, y1_validate))\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions1 = model_2.predict(x1_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x1_test, y1_test, 'b.', label='Actual')\n",
        "plt.plot(x1_train, predictions1, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_75 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 180 samples, validate on 60 samples\n",
            "Epoch 1/600\n",
            "180/180 [==============================] - 0s 1ms/sample - loss: 3.2646 - mae: 1.3041 - val_loss: 3.6890 - val_mae: 1.4154\n",
            "Epoch 2/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 2.1031 - mae: 1.0289 - val_loss: 2.5623 - val_mae: 1.1485\n",
            "Epoch 3/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 1.5579 - mae: 0.9024 - val_loss: 1.8589 - val_mae: 0.9848\n",
            "Epoch 4/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 1.1921 - mae: 0.8200 - val_loss: 1.3633 - val_mae: 0.9038\n",
            "Epoch 5/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.9192 - mae: 0.7487 - val_loss: 1.0283 - val_mae: 0.8175\n",
            "Epoch 6/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.7326 - mae: 0.6930 - val_loss: 0.7941 - val_mae: 0.7373\n",
            "Epoch 7/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.6036 - mae: 0.6505 - val_loss: 0.6383 - val_mae: 0.6864\n",
            "Epoch 8/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.5082 - mae: 0.6126 - val_loss: 0.5582 - val_mae: 0.6481\n",
            "Epoch 9/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.4577 - mae: 0.5877 - val_loss: 0.4758 - val_mae: 0.5888\n",
            "Epoch 10/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.4246 - mae: 0.5636 - val_loss: 0.4471 - val_mae: 0.5613\n",
            "Epoch 11/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.3955 - mae: 0.5407 - val_loss: 0.4050 - val_mae: 0.5233\n",
            "Epoch 12/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.3809 - mae: 0.5253 - val_loss: 0.4116 - val_mae: 0.5313\n",
            "Epoch 13/600\n",
            "180/180 [==============================] - 0s 109us/sample - loss: 0.3669 - mae: 0.5098 - val_loss: 0.3741 - val_mae: 0.4985\n",
            "Epoch 14/600\n",
            "180/180 [==============================] - 0s 111us/sample - loss: 0.3553 - mae: 0.4980 - val_loss: 0.3775 - val_mae: 0.5080\n",
            "Epoch 15/600\n",
            "180/180 [==============================] - 0s 105us/sample - loss: 0.3453 - mae: 0.4935 - val_loss: 0.3613 - val_mae: 0.4944\n",
            "Epoch 16/600\n",
            "180/180 [==============================] - 0s 115us/sample - loss: 0.3406 - mae: 0.4942 - val_loss: 0.3654 - val_mae: 0.5009\n",
            "Epoch 17/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.3290 - mae: 0.4803 - val_loss: 0.3677 - val_mae: 0.5049\n",
            "Epoch 18/600\n",
            "180/180 [==============================] - 0s 106us/sample - loss: 0.3254 - mae: 0.4826 - val_loss: 0.3439 - val_mae: 0.4835\n",
            "Epoch 19/600\n",
            "180/180 [==============================] - 0s 102us/sample - loss: 0.3175 - mae: 0.4769 - val_loss: 0.3470 - val_mae: 0.4890\n",
            "Epoch 20/600\n",
            "180/180 [==============================] - 0s 108us/sample - loss: 0.3127 - mae: 0.4714 - val_loss: 0.3349 - val_mae: 0.4803\n",
            "Epoch 21/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.3044 - mae: 0.4671 - val_loss: 0.3390 - val_mae: 0.4871\n",
            "Epoch 22/600\n",
            "180/180 [==============================] - 0s 125us/sample - loss: 0.2970 - mae: 0.4593 - val_loss: 0.3304 - val_mae: 0.4831\n",
            "Epoch 23/600\n",
            "180/180 [==============================] - 0s 178us/sample - loss: 0.2862 - mae: 0.4503 - val_loss: 0.3104 - val_mae: 0.4680\n",
            "Epoch 24/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.2782 - mae: 0.4477 - val_loss: 0.3046 - val_mae: 0.4651\n",
            "Epoch 25/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.2708 - mae: 0.4391 - val_loss: 0.3076 - val_mae: 0.4707\n",
            "Epoch 26/600\n",
            "180/180 [==============================] - 0s 109us/sample - loss: 0.2649 - mae: 0.4367 - val_loss: 0.3078 - val_mae: 0.4720\n",
            "Epoch 27/600\n",
            "180/180 [==============================] - 0s 107us/sample - loss: 0.2579 - mae: 0.4310 - val_loss: 0.2909 - val_mae: 0.4576\n",
            "Epoch 28/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.2524 - mae: 0.4292 - val_loss: 0.3147 - val_mae: 0.4810\n",
            "Epoch 29/600\n",
            "180/180 [==============================] - 0s 113us/sample - loss: 0.2537 - mae: 0.4283 - val_loss: 0.2979 - val_mae: 0.4677\n",
            "Epoch 30/600\n",
            "180/180 [==============================] - 0s 107us/sample - loss: 0.2482 - mae: 0.4233 - val_loss: 0.3110 - val_mae: 0.4793\n",
            "Epoch 31/600\n",
            "180/180 [==============================] - 0s 118us/sample - loss: 0.2442 - mae: 0.4236 - val_loss: 0.3010 - val_mae: 0.4726\n",
            "Epoch 32/600\n",
            "180/180 [==============================] - 0s 119us/sample - loss: 0.2398 - mae: 0.4161 - val_loss: 0.2707 - val_mae: 0.4446\n",
            "Epoch 33/600\n",
            "180/180 [==============================] - 0s 117us/sample - loss: 0.2333 - mae: 0.4098 - val_loss: 0.2647 - val_mae: 0.4392\n",
            "Epoch 34/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.2329 - mae: 0.4113 - val_loss: 0.3066 - val_mae: 0.4765\n",
            "Epoch 35/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.2281 - mae: 0.4097 - val_loss: 0.2716 - val_mae: 0.4499\n",
            "Epoch 36/600\n",
            "180/180 [==============================] - 0s 127us/sample - loss: 0.2216 - mae: 0.4009 - val_loss: 0.2539 - val_mae: 0.4335\n",
            "Epoch 37/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.2169 - mae: 0.3954 - val_loss: 0.2746 - val_mae: 0.4552\n",
            "Epoch 38/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.2129 - mae: 0.3932 - val_loss: 0.2529 - val_mae: 0.4344\n",
            "Epoch 39/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.2076 - mae: 0.3913 - val_loss: 0.2524 - val_mae: 0.4358\n",
            "Epoch 40/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.2027 - mae: 0.3850 - val_loss: 0.2408 - val_mae: 0.4241\n",
            "Epoch 41/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.1995 - mae: 0.3822 - val_loss: 0.2629 - val_mae: 0.4463\n",
            "Epoch 42/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.1957 - mae: 0.3767 - val_loss: 0.2410 - val_mae: 0.4251\n",
            "Epoch 43/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.1935 - mae: 0.3750 - val_loss: 0.2563 - val_mae: 0.4404\n",
            "Epoch 44/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.1895 - mae: 0.3738 - val_loss: 0.2389 - val_mae: 0.4257\n",
            "Epoch 45/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.1835 - mae: 0.3650 - val_loss: 0.2289 - val_mae: 0.4163\n",
            "Epoch 46/600\n",
            "180/180 [==============================] - 0s 122us/sample - loss: 0.1836 - mae: 0.3657 - val_loss: 0.2269 - val_mae: 0.4146\n",
            "Epoch 47/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.1769 - mae: 0.3596 - val_loss: 0.2276 - val_mae: 0.4160\n",
            "Epoch 48/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.1742 - mae: 0.3559 - val_loss: 0.2572 - val_mae: 0.4385\n",
            "Epoch 49/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.1702 - mae: 0.3513 - val_loss: 0.2299 - val_mae: 0.4094\n",
            "Epoch 50/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.1723 - mae: 0.3478 - val_loss: 0.2271 - val_mae: 0.4142\n",
            "Epoch 51/600\n",
            "180/180 [==============================] - 0s 169us/sample - loss: 0.1631 - mae: 0.3491 - val_loss: 0.2178 - val_mae: 0.4028\n",
            "Epoch 52/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.1677 - mae: 0.3429 - val_loss: 0.2273 - val_mae: 0.4096\n",
            "Epoch 53/600\n",
            "180/180 [==============================] - 0s 123us/sample - loss: 0.1566 - mae: 0.3357 - val_loss: 0.2197 - val_mae: 0.4008\n",
            "Epoch 54/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.1608 - mae: 0.3387 - val_loss: 0.2146 - val_mae: 0.3972\n",
            "Epoch 55/600\n",
            "180/180 [==============================] - 0s 124us/sample - loss: 0.1569 - mae: 0.3314 - val_loss: 0.2345 - val_mae: 0.4144\n",
            "Epoch 56/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.1529 - mae: 0.3281 - val_loss: 0.2102 - val_mae: 0.3951\n",
            "Epoch 57/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.1518 - mae: 0.3293 - val_loss: 0.2129 - val_mae: 0.3962\n",
            "Epoch 58/600\n",
            "180/180 [==============================] - 0s 124us/sample - loss: 0.1466 - mae: 0.3224 - val_loss: 0.2032 - val_mae: 0.3878\n",
            "Epoch 59/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.1496 - mae: 0.3226 - val_loss: 0.2172 - val_mae: 0.3981\n",
            "Epoch 60/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.1441 - mae: 0.3208 - val_loss: 0.2151 - val_mae: 0.3927\n",
            "Epoch 61/600\n",
            "180/180 [==============================] - 0s 117us/sample - loss: 0.1429 - mae: 0.3154 - val_loss: 0.2163 - val_mae: 0.3913\n",
            "Epoch 62/600\n",
            "180/180 [==============================] - 0s 111us/sample - loss: 0.1408 - mae: 0.3142 - val_loss: 0.2081 - val_mae: 0.3862\n",
            "Epoch 63/600\n",
            "180/180 [==============================] - 0s 118us/sample - loss: 0.1400 - mae: 0.3118 - val_loss: 0.2140 - val_mae: 0.3906\n",
            "Epoch 64/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.1356 - mae: 0.3074 - val_loss: 0.2246 - val_mae: 0.3928\n",
            "Epoch 65/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.1374 - mae: 0.3095 - val_loss: 0.2317 - val_mae: 0.3931\n",
            "Epoch 66/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.1336 - mae: 0.2985 - val_loss: 0.2147 - val_mae: 0.3850\n",
            "Epoch 67/600\n",
            "180/180 [==============================] - 0s 116us/sample - loss: 0.1320 - mae: 0.2974 - val_loss: 0.2487 - val_mae: 0.4117\n",
            "Epoch 68/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.1311 - mae: 0.2977 - val_loss: 0.2152 - val_mae: 0.3860\n",
            "Epoch 69/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.1255 - mae: 0.2919 - val_loss: 0.2071 - val_mae: 0.3783\n",
            "Epoch 70/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.1276 - mae: 0.2943 - val_loss: 0.2603 - val_mae: 0.4196\n",
            "Epoch 71/600\n",
            "180/180 [==============================] - 0s 134us/sample - loss: 0.1303 - mae: 0.2951 - val_loss: 0.2331 - val_mae: 0.3864\n",
            "Epoch 72/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.1276 - mae: 0.2868 - val_loss: 0.2249 - val_mae: 0.3808\n",
            "Epoch 73/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.1253 - mae: 0.2845 - val_loss: 0.2106 - val_mae: 0.3777\n",
            "Epoch 74/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.1271 - mae: 0.2900 - val_loss: 0.2543 - val_mae: 0.4079\n",
            "Epoch 75/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.1258 - mae: 0.2848 - val_loss: 0.2190 - val_mae: 0.3785\n",
            "Epoch 76/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.1243 - mae: 0.2844 - val_loss: 0.2529 - val_mae: 0.4078\n",
            "Epoch 77/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.1208 - mae: 0.2787 - val_loss: 0.2330 - val_mae: 0.3913\n",
            "Epoch 78/600\n",
            "180/180 [==============================] - 0s 115us/sample - loss: 0.1199 - mae: 0.2842 - val_loss: 0.2160 - val_mae: 0.3749\n",
            "Epoch 79/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.1216 - mae: 0.2835 - val_loss: 0.2463 - val_mae: 0.3989\n",
            "Epoch 80/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.1193 - mae: 0.2773 - val_loss: 0.2368 - val_mae: 0.3844\n",
            "Epoch 81/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.1216 - mae: 0.2781 - val_loss: 0.2166 - val_mae: 0.3728\n",
            "Epoch 82/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.1181 - mae: 0.2735 - val_loss: 0.2277 - val_mae: 0.3786\n",
            "Epoch 83/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.1153 - mae: 0.2713 - val_loss: 0.2271 - val_mae: 0.3716\n",
            "Epoch 84/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.1204 - mae: 0.2724 - val_loss: 0.2082 - val_mae: 0.3679\n",
            "Epoch 85/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.1165 - mae: 0.2732 - val_loss: 0.2346 - val_mae: 0.3892\n",
            "Epoch 86/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.1183 - mae: 0.2726 - val_loss: 0.2140 - val_mae: 0.3689\n",
            "Epoch 87/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.1192 - mae: 0.2717 - val_loss: 0.2273 - val_mae: 0.3765\n",
            "Epoch 88/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.1166 - mae: 0.2705 - val_loss: 0.2054 - val_mae: 0.3636\n",
            "Epoch 89/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.1136 - mae: 0.2681 - val_loss: 0.2108 - val_mae: 0.3662\n",
            "Epoch 90/600\n",
            "180/180 [==============================] - 0s 198us/sample - loss: 0.1103 - mae: 0.2664 - val_loss: 0.2223 - val_mae: 0.3681\n",
            "Epoch 91/600\n",
            "180/180 [==============================] - 0s 125us/sample - loss: 0.1137 - mae: 0.2615 - val_loss: 0.2553 - val_mae: 0.3920\n",
            "Epoch 92/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.1153 - mae: 0.2664 - val_loss: 0.2564 - val_mae: 0.3874\n",
            "Epoch 93/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.1147 - mae: 0.2665 - val_loss: 0.2291 - val_mae: 0.3669\n",
            "Epoch 94/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.1159 - mae: 0.2612 - val_loss: 0.2353 - val_mae: 0.3696\n",
            "Epoch 95/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.1159 - mae: 0.2644 - val_loss: 0.2409 - val_mae: 0.3701\n",
            "Epoch 96/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.1096 - mae: 0.2571 - val_loss: 0.2126 - val_mae: 0.3608\n",
            "Epoch 97/600\n",
            "180/180 [==============================] - 0s 127us/sample - loss: 0.1105 - mae: 0.2611 - val_loss: 0.2362 - val_mae: 0.3638\n",
            "Epoch 98/600\n",
            "180/180 [==============================] - 0s 186us/sample - loss: 0.1132 - mae: 0.2547 - val_loss: 0.2374 - val_mae: 0.3751\n",
            "Epoch 99/600\n",
            "180/180 [==============================] - 0s 172us/sample - loss: 0.1169 - mae: 0.2610 - val_loss: 0.2580 - val_mae: 0.3794\n",
            "Epoch 100/600\n",
            "180/180 [==============================] - 0s 113us/sample - loss: 0.1086 - mae: 0.2567 - val_loss: 0.2189 - val_mae: 0.3598\n",
            "Epoch 101/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.1104 - mae: 0.2537 - val_loss: 0.2232 - val_mae: 0.3627\n",
            "Epoch 102/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.1088 - mae: 0.2530 - val_loss: 0.2313 - val_mae: 0.3643\n",
            "Epoch 103/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.1104 - mae: 0.2585 - val_loss: 0.2743 - val_mae: 0.3912\n",
            "Epoch 104/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.1111 - mae: 0.2539 - val_loss: 0.2364 - val_mae: 0.3646\n",
            "Epoch 105/600\n",
            "180/180 [==============================] - 0s 182us/sample - loss: 0.1114 - mae: 0.2543 - val_loss: 0.2461 - val_mae: 0.3705\n",
            "Epoch 106/600\n",
            "180/180 [==============================] - 0s 127us/sample - loss: 0.1067 - mae: 0.2511 - val_loss: 0.2254 - val_mae: 0.3610\n",
            "Epoch 107/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.1113 - mae: 0.2554 - val_loss: 0.2380 - val_mae: 0.3621\n",
            "Epoch 108/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.1088 - mae: 0.2517 - val_loss: 0.2271 - val_mae: 0.3587\n",
            "Epoch 109/600\n",
            "180/180 [==============================] - 0s 120us/sample - loss: 0.1102 - mae: 0.2543 - val_loss: 0.2471 - val_mae: 0.3642\n",
            "Epoch 110/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.1082 - mae: 0.2483 - val_loss: 0.2396 - val_mae: 0.3674\n",
            "Epoch 111/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.1044 - mae: 0.2501 - val_loss: 0.2537 - val_mae: 0.3647\n",
            "Epoch 112/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.1047 - mae: 0.2463 - val_loss: 0.2438 - val_mae: 0.3596\n",
            "Epoch 113/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.1076 - mae: 0.2489 - val_loss: 0.2267 - val_mae: 0.3564\n",
            "Epoch 114/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.1044 - mae: 0.2464 - val_loss: 0.2726 - val_mae: 0.3841\n",
            "Epoch 115/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.1043 - mae: 0.2485 - val_loss: 0.2533 - val_mae: 0.3608\n",
            "Epoch 116/600\n",
            "180/180 [==============================] - 0s 117us/sample - loss: 0.1124 - mae: 0.2472 - val_loss: 0.2694 - val_mae: 0.3742\n",
            "Epoch 117/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.1063 - mae: 0.2462 - val_loss: 0.2391 - val_mae: 0.3591\n",
            "Epoch 118/600\n",
            "180/180 [==============================] - 0s 119us/sample - loss: 0.1065 - mae: 0.2446 - val_loss: 0.2313 - val_mae: 0.3585\n",
            "Epoch 119/600\n",
            "180/180 [==============================] - 0s 116us/sample - loss: 0.1042 - mae: 0.2454 - val_loss: 0.2274 - val_mae: 0.3535\n",
            "Epoch 120/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.1097 - mae: 0.2498 - val_loss: 0.2278 - val_mae: 0.3543\n",
            "Epoch 121/600\n",
            "180/180 [==============================] - 0s 118us/sample - loss: 0.1039 - mae: 0.2412 - val_loss: 0.2299 - val_mae: 0.3618\n",
            "Epoch 122/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.1050 - mae: 0.2492 - val_loss: 0.2293 - val_mae: 0.3567\n",
            "Epoch 123/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.1017 - mae: 0.2424 - val_loss: 0.2656 - val_mae: 0.3804\n",
            "Epoch 124/600\n",
            "180/180 [==============================] - 0s 202us/sample - loss: 0.1039 - mae: 0.2465 - val_loss: 0.2331 - val_mae: 0.3634\n",
            "Epoch 125/600\n",
            "180/180 [==============================] - 0s 127us/sample - loss: 0.1007 - mae: 0.2429 - val_loss: 0.2276 - val_mae: 0.3550\n",
            "Epoch 126/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.1003 - mae: 0.2412 - val_loss: 0.2066 - val_mae: 0.3487\n",
            "Epoch 127/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.1031 - mae: 0.2431 - val_loss: 0.2269 - val_mae: 0.3541\n",
            "Epoch 128/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.1030 - mae: 0.2426 - val_loss: 0.2345 - val_mae: 0.3550\n",
            "Epoch 129/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.1023 - mae: 0.2435 - val_loss: 0.2426 - val_mae: 0.3572\n",
            "Epoch 130/600\n",
            "180/180 [==============================] - 0s 121us/sample - loss: 0.0960 - mae: 0.2350 - val_loss: 0.2454 - val_mae: 0.3659\n",
            "Epoch 131/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.1031 - mae: 0.2435 - val_loss: 0.2446 - val_mae: 0.3591\n",
            "Epoch 132/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.1007 - mae: 0.2379 - val_loss: 0.2527 - val_mae: 0.3605\n",
            "Epoch 133/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.0986 - mae: 0.2375 - val_loss: 0.2175 - val_mae: 0.3515\n",
            "Epoch 134/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0981 - mae: 0.2376 - val_loss: 0.2315 - val_mae: 0.3619\n",
            "Epoch 135/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.1014 - mae: 0.2415 - val_loss: 0.2328 - val_mae: 0.3549\n",
            "Epoch 136/600\n",
            "180/180 [==============================] - 0s 119us/sample - loss: 0.0982 - mae: 0.2374 - val_loss: 0.2262 - val_mae: 0.3532\n",
            "Epoch 137/600\n",
            "180/180 [==============================] - 0s 111us/sample - loss: 0.1011 - mae: 0.2412 - val_loss: 0.2294 - val_mae: 0.3511\n",
            "Epoch 138/600\n",
            "180/180 [==============================] - 0s 134us/sample - loss: 0.0998 - mae: 0.2392 - val_loss: 0.2432 - val_mae: 0.3531\n",
            "Epoch 139/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.0979 - mae: 0.2344 - val_loss: 0.2782 - val_mae: 0.3921\n",
            "Epoch 140/600\n",
            "180/180 [==============================] - 0s 150us/sample - loss: 0.1004 - mae: 0.2433 - val_loss: 0.2147 - val_mae: 0.3492\n",
            "Epoch 141/600\n",
            "180/180 [==============================] - 0s 124us/sample - loss: 0.0994 - mae: 0.2395 - val_loss: 0.2602 - val_mae: 0.3763\n",
            "Epoch 142/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0970 - mae: 0.2367 - val_loss: 0.2522 - val_mae: 0.3635\n",
            "Epoch 143/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0989 - mae: 0.2393 - val_loss: 0.2388 - val_mae: 0.3544\n",
            "Epoch 144/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0947 - mae: 0.2376 - val_loss: 0.2529 - val_mae: 0.3551\n",
            "Epoch 145/600\n",
            "180/180 [==============================] - 0s 150us/sample - loss: 0.0981 - mae: 0.2275 - val_loss: 0.2298 - val_mae: 0.3530\n",
            "Epoch 146/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0953 - mae: 0.2327 - val_loss: 0.2297 - val_mae: 0.3492\n",
            "Epoch 147/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.0968 - mae: 0.2311 - val_loss: 0.2296 - val_mae: 0.3547\n",
            "Epoch 148/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.0993 - mae: 0.2355 - val_loss: 0.2377 - val_mae: 0.3544\n",
            "Epoch 149/600\n",
            "180/180 [==============================] - 0s 124us/sample - loss: 0.0920 - mae: 0.2318 - val_loss: 0.2345 - val_mae: 0.3496\n",
            "Epoch 150/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0954 - mae: 0.2305 - val_loss: 0.2689 - val_mae: 0.3855\n",
            "Epoch 151/600\n",
            "180/180 [==============================] - 0s 150us/sample - loss: 0.0984 - mae: 0.2362 - val_loss: 0.2353 - val_mae: 0.3602\n",
            "Epoch 152/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0958 - mae: 0.2335 - val_loss: 0.2145 - val_mae: 0.3460\n",
            "Epoch 153/600\n",
            "180/180 [==============================] - 0s 120us/sample - loss: 0.0934 - mae: 0.2312 - val_loss: 0.2557 - val_mae: 0.3635\n",
            "Epoch 154/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0920 - mae: 0.2340 - val_loss: 0.2504 - val_mae: 0.3515\n",
            "Epoch 155/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.0929 - mae: 0.2264 - val_loss: 0.2211 - val_mae: 0.3464\n",
            "Epoch 156/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0952 - mae: 0.2307 - val_loss: 0.2294 - val_mae: 0.3548\n",
            "Epoch 157/600\n",
            "180/180 [==============================] - 0s 114us/sample - loss: 0.0912 - mae: 0.2325 - val_loss: 0.2318 - val_mae: 0.3486\n",
            "Epoch 158/600\n",
            "180/180 [==============================] - 0s 185us/sample - loss: 0.0940 - mae: 0.2273 - val_loss: 0.2312 - val_mae: 0.3478\n",
            "Epoch 159/600\n",
            "180/180 [==============================] - 0s 112us/sample - loss: 0.0925 - mae: 0.2300 - val_loss: 0.2264 - val_mae: 0.3468\n",
            "Epoch 160/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0954 - mae: 0.2321 - val_loss: 0.2586 - val_mae: 0.3586\n",
            "Epoch 161/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0923 - mae: 0.2290 - val_loss: 0.2297 - val_mae: 0.3474\n",
            "Epoch 162/600\n",
            "180/180 [==============================] - 0s 171us/sample - loss: 0.0934 - mae: 0.2290 - val_loss: 0.2271 - val_mae: 0.3461\n",
            "Epoch 163/600\n",
            "180/180 [==============================] - 0s 116us/sample - loss: 0.0941 - mae: 0.2328 - val_loss: 0.2301 - val_mae: 0.3466\n",
            "Epoch 164/600\n",
            "180/180 [==============================] - 0s 118us/sample - loss: 0.0899 - mae: 0.2269 - val_loss: 0.2233 - val_mae: 0.3442\n",
            "Epoch 165/600\n",
            "180/180 [==============================] - 0s 125us/sample - loss: 0.0913 - mae: 0.2266 - val_loss: 0.2227 - val_mae: 0.3441\n",
            "Epoch 166/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.0962 - mae: 0.2337 - val_loss: 0.2201 - val_mae: 0.3432\n",
            "Epoch 167/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.0904 - mae: 0.2271 - val_loss: 0.2256 - val_mae: 0.3458\n",
            "Epoch 168/600\n",
            "180/180 [==============================] - 0s 116us/sample - loss: 0.0918 - mae: 0.2273 - val_loss: 0.2044 - val_mae: 0.3421\n",
            "Epoch 169/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0884 - mae: 0.2280 - val_loss: 0.2242 - val_mae: 0.3440\n",
            "Epoch 170/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.0921 - mae: 0.2328 - val_loss: 0.2250 - val_mae: 0.3477\n",
            "Epoch 171/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0912 - mae: 0.2289 - val_loss: 0.2165 - val_mae: 0.3402\n",
            "Epoch 172/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0891 - mae: 0.2263 - val_loss: 0.2138 - val_mae: 0.3393\n",
            "Epoch 173/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0900 - mae: 0.2214 - val_loss: 0.2156 - val_mae: 0.3429\n",
            "Epoch 174/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0894 - mae: 0.2270 - val_loss: 0.2438 - val_mae: 0.3608\n",
            "Epoch 175/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0876 - mae: 0.2279 - val_loss: 0.2249 - val_mae: 0.3423\n",
            "Epoch 176/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0888 - mae: 0.2290 - val_loss: 0.2465 - val_mae: 0.3467\n",
            "Epoch 177/600\n",
            "180/180 [==============================] - 0s 121us/sample - loss: 0.0889 - mae: 0.2209 - val_loss: 0.2537 - val_mae: 0.3683\n",
            "Epoch 178/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0875 - mae: 0.2287 - val_loss: 0.2248 - val_mae: 0.3406\n",
            "Epoch 179/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0857 - mae: 0.2215 - val_loss: 0.2213 - val_mae: 0.3410\n",
            "Epoch 180/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0864 - mae: 0.2236 - val_loss: 0.2259 - val_mae: 0.3429\n",
            "Epoch 181/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0877 - mae: 0.2245 - val_loss: 0.2112 - val_mae: 0.3356\n",
            "Epoch 182/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0884 - mae: 0.2213 - val_loss: 0.2279 - val_mae: 0.3393\n",
            "Epoch 183/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0883 - mae: 0.2237 - val_loss: 0.2248 - val_mae: 0.3416\n",
            "Epoch 184/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0886 - mae: 0.2230 - val_loss: 0.2337 - val_mae: 0.3411\n",
            "Epoch 185/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0866 - mae: 0.2206 - val_loss: 0.2451 - val_mae: 0.3472\n",
            "Epoch 186/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0892 - mae: 0.2244 - val_loss: 0.2372 - val_mae: 0.3557\n",
            "Epoch 187/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.0849 - mae: 0.2225 - val_loss: 0.2203 - val_mae: 0.3374\n",
            "Epoch 188/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0835 - mae: 0.2209 - val_loss: 0.2409 - val_mae: 0.3408\n",
            "Epoch 189/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.0872 - mae: 0.2175 - val_loss: 0.2446 - val_mae: 0.3575\n",
            "Epoch 190/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0847 - mae: 0.2206 - val_loss: 0.2041 - val_mae: 0.3323\n",
            "Epoch 191/600\n",
            "180/180 [==============================] - 0s 128us/sample - loss: 0.0840 - mae: 0.2169 - val_loss: 0.2083 - val_mae: 0.3344\n",
            "Epoch 192/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0881 - mae: 0.2237 - val_loss: 0.2100 - val_mae: 0.3447\n",
            "Epoch 193/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.0830 - mae: 0.2208 - val_loss: 0.2128 - val_mae: 0.3318\n",
            "Epoch 194/600\n",
            "180/180 [==============================] - 0s 134us/sample - loss: 0.0824 - mae: 0.2141 - val_loss: 0.1974 - val_mae: 0.3298\n",
            "Epoch 195/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0837 - mae: 0.2160 - val_loss: 0.2126 - val_mae: 0.3317\n",
            "Epoch 196/600\n",
            "180/180 [==============================] - 0s 123us/sample - loss: 0.0852 - mae: 0.2175 - val_loss: 0.2199 - val_mae: 0.3346\n",
            "Epoch 197/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.0849 - mae: 0.2170 - val_loss: 0.2356 - val_mae: 0.3507\n",
            "Epoch 198/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0836 - mae: 0.2195 - val_loss: 0.2104 - val_mae: 0.3320\n",
            "Epoch 199/600\n",
            "180/180 [==============================] - 0s 180us/sample - loss: 0.0822 - mae: 0.2150 - val_loss: 0.2114 - val_mae: 0.3304\n",
            "Epoch 200/600\n",
            "180/180 [==============================] - 0s 188us/sample - loss: 0.0828 - mae: 0.2124 - val_loss: 0.2135 - val_mae: 0.3304\n",
            "Epoch 201/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.0872 - mae: 0.2130 - val_loss: 0.2104 - val_mae: 0.3304\n",
            "Epoch 202/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0801 - mae: 0.2123 - val_loss: 0.2193 - val_mae: 0.3342\n",
            "Epoch 203/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0830 - mae: 0.2107 - val_loss: 0.2146 - val_mae: 0.3328\n",
            "Epoch 204/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0816 - mae: 0.2120 - val_loss: 0.2594 - val_mae: 0.3595\n",
            "Epoch 205/600\n",
            "180/180 [==============================] - 0s 131us/sample - loss: 0.0820 - mae: 0.2158 - val_loss: 0.2338 - val_mae: 0.3428\n",
            "Epoch 206/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.0808 - mae: 0.2118 - val_loss: 0.1974 - val_mae: 0.3270\n",
            "Epoch 207/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0785 - mae: 0.2135 - val_loss: 0.2341 - val_mae: 0.3402\n",
            "Epoch 208/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0776 - mae: 0.2103 - val_loss: 0.2051 - val_mae: 0.3270\n",
            "Epoch 209/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0820 - mae: 0.2154 - val_loss: 0.2250 - val_mae: 0.3371\n",
            "Epoch 210/600\n",
            "180/180 [==============================] - 0s 171us/sample - loss: 0.0778 - mae: 0.2090 - val_loss: 0.2372 - val_mae: 0.3357\n",
            "Epoch 211/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0797 - mae: 0.2099 - val_loss: 0.2161 - val_mae: 0.3287\n",
            "Epoch 212/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0783 - mae: 0.2068 - val_loss: 0.1983 - val_mae: 0.3242\n",
            "Epoch 213/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0800 - mae: 0.2087 - val_loss: 0.2121 - val_mae: 0.3293\n",
            "Epoch 214/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0822 - mae: 0.2145 - val_loss: 0.2216 - val_mae: 0.3319\n",
            "Epoch 215/600\n",
            "180/180 [==============================] - 0s 120us/sample - loss: 0.0790 - mae: 0.2090 - val_loss: 0.2220 - val_mae: 0.3310\n",
            "Epoch 216/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0783 - mae: 0.2124 - val_loss: 0.2072 - val_mae: 0.3257\n",
            "Epoch 217/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0798 - mae: 0.2105 - val_loss: 0.2173 - val_mae: 0.3280\n",
            "Epoch 218/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.0800 - mae: 0.2093 - val_loss: 0.2282 - val_mae: 0.3351\n",
            "Epoch 219/600\n",
            "180/180 [==============================] - 0s 164us/sample - loss: 0.0787 - mae: 0.2067 - val_loss: 0.2223 - val_mae: 0.3340\n",
            "Epoch 220/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0766 - mae: 0.2049 - val_loss: 0.1996 - val_mae: 0.3263\n",
            "Epoch 221/600\n",
            "180/180 [==============================] - 0s 120us/sample - loss: 0.0779 - mae: 0.2116 - val_loss: 0.2220 - val_mae: 0.3286\n",
            "Epoch 222/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0765 - mae: 0.2049 - val_loss: 0.2194 - val_mae: 0.3279\n",
            "Epoch 223/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0761 - mae: 0.2070 - val_loss: 0.2409 - val_mae: 0.3374\n",
            "Epoch 224/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.0768 - mae: 0.2036 - val_loss: 0.2542 - val_mae: 0.3680\n",
            "Epoch 225/600\n",
            "180/180 [==============================] - 0s 119us/sample - loss: 0.0799 - mae: 0.2141 - val_loss: 0.2240 - val_mae: 0.3352\n",
            "Epoch 226/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.0737 - mae: 0.2043 - val_loss: 0.2345 - val_mae: 0.3418\n",
            "Epoch 227/600\n",
            "180/180 [==============================] - 0s 171us/sample - loss: 0.0762 - mae: 0.2063 - val_loss: 0.2136 - val_mae: 0.3255\n",
            "Epoch 228/600\n",
            "180/180 [==============================] - 0s 190us/sample - loss: 0.0784 - mae: 0.2055 - val_loss: 0.2014 - val_mae: 0.3288\n",
            "Epoch 229/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0737 - mae: 0.2006 - val_loss: 0.2225 - val_mae: 0.3434\n",
            "Epoch 230/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0741 - mae: 0.2041 - val_loss: 0.1989 - val_mae: 0.3214\n",
            "Epoch 231/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0728 - mae: 0.2000 - val_loss: 0.2142 - val_mae: 0.3295\n",
            "Epoch 232/600\n",
            "180/180 [==============================] - 0s 119us/sample - loss: 0.0739 - mae: 0.2017 - val_loss: 0.2055 - val_mae: 0.3288\n",
            "Epoch 233/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0729 - mae: 0.2026 - val_loss: 0.2096 - val_mae: 0.3222\n",
            "Epoch 234/600\n",
            "180/180 [==============================] - 0s 120us/sample - loss: 0.0745 - mae: 0.2051 - val_loss: 0.2155 - val_mae: 0.3244\n",
            "Epoch 235/600\n",
            "180/180 [==============================] - 0s 125us/sample - loss: 0.0742 - mae: 0.2036 - val_loss: 0.2216 - val_mae: 0.3249\n",
            "Epoch 236/600\n",
            "180/180 [==============================] - 0s 191us/sample - loss: 0.0751 - mae: 0.1973 - val_loss: 0.1998 - val_mae: 0.3258\n",
            "Epoch 237/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0719 - mae: 0.2014 - val_loss: 0.2145 - val_mae: 0.3328\n",
            "Epoch 238/600\n",
            "180/180 [==============================] - 0s 127us/sample - loss: 0.0748 - mae: 0.2031 - val_loss: 0.2034 - val_mae: 0.3189\n",
            "Epoch 239/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0724 - mae: 0.2004 - val_loss: 0.2284 - val_mae: 0.3416\n",
            "Epoch 240/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.0752 - mae: 0.2026 - val_loss: 0.2199 - val_mae: 0.3236\n",
            "Epoch 241/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.0752 - mae: 0.2017 - val_loss: 0.2125 - val_mae: 0.3328\n",
            "Epoch 242/600\n",
            "180/180 [==============================] - 0s 117us/sample - loss: 0.0701 - mae: 0.1982 - val_loss: 0.1981 - val_mae: 0.3172\n",
            "Epoch 243/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0688 - mae: 0.1944 - val_loss: 0.2270 - val_mae: 0.3537\n",
            "Epoch 244/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0727 - mae: 0.2030 - val_loss: 0.1883 - val_mae: 0.3224\n",
            "Epoch 245/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0687 - mae: 0.1980 - val_loss: 0.2302 - val_mae: 0.3421\n",
            "Epoch 246/600\n",
            "180/180 [==============================] - 0s 189us/sample - loss: 0.0696 - mae: 0.1982 - val_loss: 0.2124 - val_mae: 0.3343\n",
            "Epoch 247/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0667 - mae: 0.1935 - val_loss: 0.2015 - val_mae: 0.3173\n",
            "Epoch 248/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0685 - mae: 0.1909 - val_loss: 0.1844 - val_mae: 0.3086\n",
            "Epoch 249/600\n",
            "180/180 [==============================] - 0s 169us/sample - loss: 0.0691 - mae: 0.1967 - val_loss: 0.1873 - val_mae: 0.3095\n",
            "Epoch 250/600\n",
            "180/180 [==============================] - 0s 128us/sample - loss: 0.0672 - mae: 0.1947 - val_loss: 0.1980 - val_mae: 0.3160\n",
            "Epoch 251/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0692 - mae: 0.1919 - val_loss: 0.1985 - val_mae: 0.3221\n",
            "Epoch 252/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0644 - mae: 0.1888 - val_loss: 0.2131 - val_mae: 0.3220\n",
            "Epoch 253/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0677 - mae: 0.1918 - val_loss: 0.1934 - val_mae: 0.3153\n",
            "Epoch 254/600\n",
            "180/180 [==============================] - 0s 179us/sample - loss: 0.0675 - mae: 0.1944 - val_loss: 0.2048 - val_mae: 0.3266\n",
            "Epoch 255/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.0672 - mae: 0.1897 - val_loss: 0.1972 - val_mae: 0.3099\n",
            "Epoch 256/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0645 - mae: 0.1837 - val_loss: 0.1786 - val_mae: 0.3109\n",
            "Epoch 257/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0655 - mae: 0.1858 - val_loss: 0.1811 - val_mae: 0.3149\n",
            "Epoch 258/600\n",
            "180/180 [==============================] - 0s 178us/sample - loss: 0.0672 - mae: 0.1932 - val_loss: 0.1986 - val_mae: 0.3118\n",
            "Epoch 259/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0673 - mae: 0.1903 - val_loss: 0.1905 - val_mae: 0.3114\n",
            "Epoch 260/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0644 - mae: 0.1921 - val_loss: 0.2061 - val_mae: 0.3107\n",
            "Epoch 261/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0693 - mae: 0.1906 - val_loss: 0.1975 - val_mae: 0.3087\n",
            "Epoch 262/600\n",
            "180/180 [==============================] - 0s 176us/sample - loss: 0.0643 - mae: 0.1837 - val_loss: 0.2056 - val_mae: 0.3182\n",
            "Epoch 263/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0638 - mae: 0.1887 - val_loss: 0.2127 - val_mae: 0.3160\n",
            "Epoch 264/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0628 - mae: 0.1801 - val_loss: 0.2412 - val_mae: 0.3551\n",
            "Epoch 265/600\n",
            "180/180 [==============================] - 0s 209us/sample - loss: 0.0688 - mae: 0.1912 - val_loss: 0.1914 - val_mae: 0.3081\n",
            "Epoch 266/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.0650 - mae: 0.1891 - val_loss: 0.1887 - val_mae: 0.3156\n",
            "Epoch 267/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0638 - mae: 0.1884 - val_loss: 0.2070 - val_mae: 0.3133\n",
            "Epoch 268/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0612 - mae: 0.1832 - val_loss: 0.2138 - val_mae: 0.3162\n",
            "Epoch 269/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0634 - mae: 0.1839 - val_loss: 0.1877 - val_mae: 0.3178\n",
            "Epoch 270/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0630 - mae: 0.1858 - val_loss: 0.1874 - val_mae: 0.3050\n",
            "Epoch 271/600\n",
            "180/180 [==============================] - 0s 175us/sample - loss: 0.0651 - mae: 0.1852 - val_loss: 0.1947 - val_mae: 0.3080\n",
            "Epoch 272/600\n",
            "180/180 [==============================] - 0s 182us/sample - loss: 0.0630 - mae: 0.1803 - val_loss: 0.2376 - val_mae: 0.3426\n",
            "Epoch 273/600\n",
            "180/180 [==============================] - 0s 185us/sample - loss: 0.0641 - mae: 0.1875 - val_loss: 0.1945 - val_mae: 0.3042\n",
            "Epoch 274/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0640 - mae: 0.1832 - val_loss: 0.2029 - val_mae: 0.3120\n",
            "Epoch 275/600\n",
            "180/180 [==============================] - 0s 150us/sample - loss: 0.0603 - mae: 0.1819 - val_loss: 0.2150 - val_mae: 0.3121\n",
            "Epoch 276/600\n",
            "180/180 [==============================] - 0s 122us/sample - loss: 0.0609 - mae: 0.1792 - val_loss: 0.2044 - val_mae: 0.3042\n",
            "Epoch 277/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.0609 - mae: 0.1794 - val_loss: 0.1782 - val_mae: 0.2993\n",
            "Epoch 278/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0622 - mae: 0.1830 - val_loss: 0.1914 - val_mae: 0.3087\n",
            "Epoch 279/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0616 - mae: 0.1839 - val_loss: 0.2176 - val_mae: 0.3160\n",
            "Epoch 280/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0620 - mae: 0.1795 - val_loss: 0.1839 - val_mae: 0.2976\n",
            "Epoch 281/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0619 - mae: 0.1813 - val_loss: 0.2223 - val_mae: 0.3320\n",
            "Epoch 282/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0604 - mae: 0.1779 - val_loss: 0.1829 - val_mae: 0.3157\n",
            "Epoch 283/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0598 - mae: 0.1822 - val_loss: 0.1756 - val_mae: 0.2999\n",
            "Epoch 284/600\n",
            "180/180 [==============================] - 0s 171us/sample - loss: 0.0599 - mae: 0.1822 - val_loss: 0.1923 - val_mae: 0.2999\n",
            "Epoch 285/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.0588 - mae: 0.1772 - val_loss: 0.1951 - val_mae: 0.3113\n",
            "Epoch 286/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.0613 - mae: 0.1835 - val_loss: 0.1943 - val_mae: 0.3182\n",
            "Epoch 287/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0624 - mae: 0.1850 - val_loss: 0.1808 - val_mae: 0.2949\n",
            "Epoch 288/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0612 - mae: 0.1802 - val_loss: 0.2041 - val_mae: 0.3063\n",
            "Epoch 289/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0586 - mae: 0.1727 - val_loss: 0.2011 - val_mae: 0.3096\n",
            "Epoch 290/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0597 - mae: 0.1765 - val_loss: 0.1862 - val_mae: 0.3026\n",
            "Epoch 291/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.0586 - mae: 0.1770 - val_loss: 0.1965 - val_mae: 0.3096\n",
            "Epoch 292/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0566 - mae: 0.1762 - val_loss: 0.1719 - val_mae: 0.2896\n",
            "Epoch 293/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0579 - mae: 0.1746 - val_loss: 0.2243 - val_mae: 0.3447\n",
            "Epoch 294/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.0612 - mae: 0.1818 - val_loss: 0.2221 - val_mae: 0.3295\n",
            "Epoch 295/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.0591 - mae: 0.1765 - val_loss: 0.2110 - val_mae: 0.3113\n",
            "Epoch 296/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0585 - mae: 0.1769 - val_loss: 0.1999 - val_mae: 0.3005\n",
            "Epoch 297/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0568 - mae: 0.1746 - val_loss: 0.1950 - val_mae: 0.2930\n",
            "Epoch 298/600\n",
            "180/180 [==============================] - 0s 126us/sample - loss: 0.0587 - mae: 0.1763 - val_loss: 0.2018 - val_mae: 0.3130\n",
            "Epoch 299/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0595 - mae: 0.1798 - val_loss: 0.2141 - val_mae: 0.3247\n",
            "Epoch 300/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0545 - mae: 0.1726 - val_loss: 0.1627 - val_mae: 0.2852\n",
            "Epoch 301/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0574 - mae: 0.1765 - val_loss: 0.1654 - val_mae: 0.2879\n",
            "Epoch 302/600\n",
            "180/180 [==============================] - 0s 129us/sample - loss: 0.0572 - mae: 0.1739 - val_loss: 0.1777 - val_mae: 0.2958\n",
            "Epoch 303/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0564 - mae: 0.1751 - val_loss: 0.1936 - val_mae: 0.2964\n",
            "Epoch 304/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0552 - mae: 0.1690 - val_loss: 0.1815 - val_mae: 0.2926\n",
            "Epoch 305/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0582 - mae: 0.1759 - val_loss: 0.1953 - val_mae: 0.3042\n",
            "Epoch 306/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.0594 - mae: 0.1746 - val_loss: 0.1719 - val_mae: 0.2867\n",
            "Epoch 307/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0560 - mae: 0.1719 - val_loss: 0.1475 - val_mae: 0.2799\n",
            "Epoch 308/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0569 - mae: 0.1742 - val_loss: 0.1767 - val_mae: 0.2873\n",
            "Epoch 309/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0568 - mae: 0.1680 - val_loss: 0.1904 - val_mae: 0.2950\n",
            "Epoch 310/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0544 - mae: 0.1697 - val_loss: 0.1806 - val_mae: 0.2922\n",
            "Epoch 311/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0562 - mae: 0.1727 - val_loss: 0.1915 - val_mae: 0.2916\n",
            "Epoch 312/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0538 - mae: 0.1663 - val_loss: 0.1704 - val_mae: 0.2903\n",
            "Epoch 313/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0546 - mae: 0.1708 - val_loss: 0.1574 - val_mae: 0.2859\n",
            "Epoch 314/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0567 - mae: 0.1773 - val_loss: 0.1693 - val_mae: 0.2845\n",
            "Epoch 315/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0575 - mae: 0.1743 - val_loss: 0.1877 - val_mae: 0.2990\n",
            "Epoch 316/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0527 - mae: 0.1654 - val_loss: 0.1812 - val_mae: 0.2927\n",
            "Epoch 317/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0534 - mae: 0.1658 - val_loss: 0.1842 - val_mae: 0.2983\n",
            "Epoch 318/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0544 - mae: 0.1732 - val_loss: 0.1859 - val_mae: 0.2929\n",
            "Epoch 319/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0535 - mae: 0.1663 - val_loss: 0.1917 - val_mae: 0.2947\n",
            "Epoch 320/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0529 - mae: 0.1668 - val_loss: 0.1926 - val_mae: 0.2939\n",
            "Epoch 321/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0537 - mae: 0.1643 - val_loss: 0.1895 - val_mae: 0.2987\n",
            "Epoch 322/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0527 - mae: 0.1650 - val_loss: 0.1450 - val_mae: 0.2739\n",
            "Epoch 323/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0517 - mae: 0.1668 - val_loss: 0.1889 - val_mae: 0.3047\n",
            "Epoch 324/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0530 - mae: 0.1682 - val_loss: 0.1615 - val_mae: 0.2779\n",
            "Epoch 325/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0548 - mae: 0.1721 - val_loss: 0.1612 - val_mae: 0.2872\n",
            "Epoch 326/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0521 - mae: 0.1646 - val_loss: 0.2091 - val_mae: 0.3222\n",
            "Epoch 327/600\n",
            "180/180 [==============================] - 0s 191us/sample - loss: 0.0524 - mae: 0.1678 - val_loss: 0.1785 - val_mae: 0.2872\n",
            "Epoch 328/600\n",
            "180/180 [==============================] - 0s 186us/sample - loss: 0.0521 - mae: 0.1633 - val_loss: 0.1846 - val_mae: 0.2874\n",
            "Epoch 329/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0506 - mae: 0.1607 - val_loss: 0.2253 - val_mae: 0.3444\n",
            "Epoch 330/600\n",
            "180/180 [==============================] - 0s 150us/sample - loss: 0.0556 - mae: 0.1709 - val_loss: 0.1705 - val_mae: 0.2810\n",
            "Epoch 331/600\n",
            "180/180 [==============================] - 0s 172us/sample - loss: 0.0526 - mae: 0.1679 - val_loss: 0.1807 - val_mae: 0.2883\n",
            "Epoch 332/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0497 - mae: 0.1602 - val_loss: 0.1824 - val_mae: 0.2807\n",
            "Epoch 333/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0517 - mae: 0.1660 - val_loss: 0.1938 - val_mae: 0.3123\n",
            "Epoch 334/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.0504 - mae: 0.1654 - val_loss: 0.1810 - val_mae: 0.2807\n",
            "Epoch 335/600\n",
            "180/180 [==============================] - 0s 130us/sample - loss: 0.0516 - mae: 0.1610 - val_loss: 0.1894 - val_mae: 0.3116\n",
            "Epoch 336/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0503 - mae: 0.1641 - val_loss: 0.1648 - val_mae: 0.2754\n",
            "Epoch 337/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0518 - mae: 0.1627 - val_loss: 0.1743 - val_mae: 0.2838\n",
            "Epoch 338/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0493 - mae: 0.1582 - val_loss: 0.1606 - val_mae: 0.2755\n",
            "Epoch 339/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0501 - mae: 0.1637 - val_loss: 0.1752 - val_mae: 0.2827\n",
            "Epoch 340/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0485 - mae: 0.1601 - val_loss: 0.1804 - val_mae: 0.2737\n",
            "Epoch 341/600\n",
            "180/180 [==============================] - 0s 228us/sample - loss: 0.0525 - mae: 0.1641 - val_loss: 0.1800 - val_mae: 0.2948\n",
            "Epoch 342/600\n",
            "180/180 [==============================] - 0s 136us/sample - loss: 0.0480 - mae: 0.1568 - val_loss: 0.1909 - val_mae: 0.3057\n",
            "Epoch 343/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0516 - mae: 0.1610 - val_loss: 0.1627 - val_mae: 0.2795\n",
            "Epoch 344/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0498 - mae: 0.1617 - val_loss: 0.1531 - val_mae: 0.2696\n",
            "Epoch 345/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0505 - mae: 0.1576 - val_loss: 0.1547 - val_mae: 0.2765\n",
            "Epoch 346/600\n",
            "180/180 [==============================] - 0s 201us/sample - loss: 0.0478 - mae: 0.1616 - val_loss: 0.1943 - val_mae: 0.3077\n",
            "Epoch 347/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0474 - mae: 0.1550 - val_loss: 0.1499 - val_mae: 0.2726\n",
            "Epoch 348/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0480 - mae: 0.1583 - val_loss: 0.1728 - val_mae: 0.2824\n",
            "Epoch 349/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0466 - mae: 0.1549 - val_loss: 0.1551 - val_mae: 0.2645\n",
            "Epoch 350/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0469 - mae: 0.1544 - val_loss: 0.1594 - val_mae: 0.2686\n",
            "Epoch 351/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0477 - mae: 0.1564 - val_loss: 0.1615 - val_mae: 0.2745\n",
            "Epoch 352/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0478 - mae: 0.1557 - val_loss: 0.1605 - val_mae: 0.2829\n",
            "Epoch 353/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0477 - mae: 0.1569 - val_loss: 0.1500 - val_mae: 0.2774\n",
            "Epoch 354/600\n",
            "180/180 [==============================] - 0s 192us/sample - loss: 0.0475 - mae: 0.1588 - val_loss: 0.1628 - val_mae: 0.2691\n",
            "Epoch 355/600\n",
            "180/180 [==============================] - 0s 196us/sample - loss: 0.0454 - mae: 0.1536 - val_loss: 0.1811 - val_mae: 0.2775\n",
            "Epoch 356/600\n",
            "180/180 [==============================] - 0s 179us/sample - loss: 0.0469 - mae: 0.1574 - val_loss: 0.1491 - val_mae: 0.2615\n",
            "Epoch 357/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0468 - mae: 0.1561 - val_loss: 0.1946 - val_mae: 0.3173\n",
            "Epoch 358/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.0470 - mae: 0.1583 - val_loss: 0.1507 - val_mae: 0.2607\n",
            "Epoch 359/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0501 - mae: 0.1588 - val_loss: 0.1638 - val_mae: 0.2846\n",
            "Epoch 360/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0477 - mae: 0.1535 - val_loss: 0.1708 - val_mae: 0.2946\n",
            "Epoch 361/600\n",
            "180/180 [==============================] - 0s 201us/sample - loss: 0.0471 - mae: 0.1579 - val_loss: 0.1628 - val_mae: 0.2723\n",
            "Epoch 362/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.0470 - mae: 0.1552 - val_loss: 0.1802 - val_mae: 0.2888\n",
            "Epoch 363/600\n",
            "180/180 [==============================] - 0s 169us/sample - loss: 0.0453 - mae: 0.1530 - val_loss: 0.1743 - val_mae: 0.2704\n",
            "Epoch 364/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0442 - mae: 0.1517 - val_loss: 0.1669 - val_mae: 0.2746\n",
            "Epoch 365/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.0455 - mae: 0.1538 - val_loss: 0.1481 - val_mae: 0.2608\n",
            "Epoch 366/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0449 - mae: 0.1541 - val_loss: 0.1747 - val_mae: 0.3029\n",
            "Epoch 367/600\n",
            "180/180 [==============================] - 0s 196us/sample - loss: 0.0456 - mae: 0.1562 - val_loss: 0.1694 - val_mae: 0.2786\n",
            "Epoch 368/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0434 - mae: 0.1514 - val_loss: 0.1436 - val_mae: 0.2587\n",
            "Epoch 369/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0442 - mae: 0.1527 - val_loss: 0.1509 - val_mae: 0.2651\n",
            "Epoch 370/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0445 - mae: 0.1511 - val_loss: 0.1537 - val_mae: 0.2694\n",
            "Epoch 371/600\n",
            "180/180 [==============================] - 0s 171us/sample - loss: 0.0455 - mae: 0.1568 - val_loss: 0.1452 - val_mae: 0.2641\n",
            "Epoch 372/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0444 - mae: 0.1516 - val_loss: 0.1458 - val_mae: 0.2539\n",
            "Epoch 373/600\n",
            "180/180 [==============================] - 0s 176us/sample - loss: 0.0448 - mae: 0.1547 - val_loss: 0.1553 - val_mae: 0.2566\n",
            "Epoch 374/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0425 - mae: 0.1497 - val_loss: 0.1511 - val_mae: 0.2706\n",
            "Epoch 375/600\n",
            "180/180 [==============================] - 0s 185us/sample - loss: 0.0432 - mae: 0.1507 - val_loss: 0.1542 - val_mae: 0.2600\n",
            "Epoch 376/600\n",
            "180/180 [==============================] - 0s 176us/sample - loss: 0.0413 - mae: 0.1487 - val_loss: 0.1696 - val_mae: 0.2716\n",
            "Epoch 377/600\n",
            "180/180 [==============================] - 0s 192us/sample - loss: 0.0438 - mae: 0.1518 - val_loss: 0.1471 - val_mae: 0.2736\n",
            "Epoch 378/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0410 - mae: 0.1484 - val_loss: 0.1380 - val_mae: 0.2550\n",
            "Epoch 379/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0434 - mae: 0.1519 - val_loss: 0.1588 - val_mae: 0.2724\n",
            "Epoch 380/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0449 - mae: 0.1530 - val_loss: 0.1618 - val_mae: 0.2620\n",
            "Epoch 381/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0414 - mae: 0.1462 - val_loss: 0.1373 - val_mae: 0.2528\n",
            "Epoch 382/600\n",
            "180/180 [==============================] - 0s 178us/sample - loss: 0.0412 - mae: 0.1499 - val_loss: 0.1639 - val_mae: 0.2736\n",
            "Epoch 383/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0424 - mae: 0.1516 - val_loss: 0.1430 - val_mae: 0.2542\n",
            "Epoch 384/600\n",
            "180/180 [==============================] - 0s 185us/sample - loss: 0.0454 - mae: 0.1544 - val_loss: 0.1376 - val_mae: 0.2604\n",
            "Epoch 385/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0424 - mae: 0.1504 - val_loss: 0.1373 - val_mae: 0.2474\n",
            "Epoch 386/600\n",
            "180/180 [==============================] - 0s 134us/sample - loss: 0.0418 - mae: 0.1519 - val_loss: 0.1342 - val_mae: 0.2473\n",
            "Epoch 387/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0420 - mae: 0.1543 - val_loss: 0.1706 - val_mae: 0.2737\n",
            "Epoch 388/600\n",
            "180/180 [==============================] - 0s 189us/sample - loss: 0.0397 - mae: 0.1441 - val_loss: 0.1325 - val_mae: 0.2479\n",
            "Epoch 389/600\n",
            "180/180 [==============================] - 0s 164us/sample - loss: 0.0436 - mae: 0.1530 - val_loss: 0.1487 - val_mae: 0.2577\n",
            "Epoch 390/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0399 - mae: 0.1449 - val_loss: 0.1478 - val_mae: 0.2569\n",
            "Epoch 391/600\n",
            "180/180 [==============================] - 0s 182us/sample - loss: 0.0427 - mae: 0.1545 - val_loss: 0.1489 - val_mae: 0.2534\n",
            "Epoch 392/600\n",
            "180/180 [==============================] - 0s 175us/sample - loss: 0.0398 - mae: 0.1479 - val_loss: 0.1611 - val_mae: 0.2720\n",
            "Epoch 393/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0402 - mae: 0.1439 - val_loss: 0.1392 - val_mae: 0.2559\n",
            "Epoch 394/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0406 - mae: 0.1486 - val_loss: 0.1634 - val_mae: 0.2700\n",
            "Epoch 395/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0398 - mae: 0.1427 - val_loss: 0.1309 - val_mae: 0.2432\n",
            "Epoch 396/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0397 - mae: 0.1490 - val_loss: 0.1323 - val_mae: 0.2406\n",
            "Epoch 397/600\n",
            "180/180 [==============================] - 0s 201us/sample - loss: 0.0388 - mae: 0.1447 - val_loss: 0.1679 - val_mae: 0.2925\n",
            "Epoch 398/600\n",
            "180/180 [==============================] - 0s 200us/sample - loss: 0.0391 - mae: 0.1463 - val_loss: 0.1424 - val_mae: 0.2451\n",
            "Epoch 399/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0407 - mae: 0.1456 - val_loss: 0.1447 - val_mae: 0.2456\n",
            "Epoch 400/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0388 - mae: 0.1450 - val_loss: 0.1493 - val_mae: 0.2481\n",
            "Epoch 401/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0387 - mae: 0.1445 - val_loss: 0.1702 - val_mae: 0.2750\n",
            "Epoch 402/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0385 - mae: 0.1441 - val_loss: 0.1372 - val_mae: 0.2405\n",
            "Epoch 403/600\n",
            "180/180 [==============================] - 0s 168us/sample - loss: 0.0391 - mae: 0.1454 - val_loss: 0.1528 - val_mae: 0.2604\n",
            "Epoch 404/600\n",
            "180/180 [==============================] - 0s 176us/sample - loss: 0.0366 - mae: 0.1393 - val_loss: 0.1300 - val_mae: 0.2530\n",
            "Epoch 405/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0367 - mae: 0.1428 - val_loss: 0.1354 - val_mae: 0.2520\n",
            "Epoch 406/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0366 - mae: 0.1397 - val_loss: 0.1367 - val_mae: 0.2509\n",
            "Epoch 407/600\n",
            "180/180 [==============================] - 0s 133us/sample - loss: 0.0399 - mae: 0.1439 - val_loss: 0.1339 - val_mae: 0.2371\n",
            "Epoch 408/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0375 - mae: 0.1440 - val_loss: 0.1434 - val_mae: 0.2442\n",
            "Epoch 409/600\n",
            "180/180 [==============================] - 0s 188us/sample - loss: 0.0380 - mae: 0.1421 - val_loss: 0.1325 - val_mae: 0.2417\n",
            "Epoch 410/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0390 - mae: 0.1450 - val_loss: 0.1344 - val_mae: 0.2413\n",
            "Epoch 411/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0360 - mae: 0.1409 - val_loss: 0.1512 - val_mae: 0.2535\n",
            "Epoch 412/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0379 - mae: 0.1386 - val_loss: 0.1418 - val_mae: 0.2654\n",
            "Epoch 413/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0384 - mae: 0.1426 - val_loss: 0.1383 - val_mae: 0.2485\n",
            "Epoch 414/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0396 - mae: 0.1453 - val_loss: 0.1378 - val_mae: 0.2453\n",
            "Epoch 415/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0363 - mae: 0.1397 - val_loss: 0.1361 - val_mae: 0.2431\n",
            "Epoch 416/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0377 - mae: 0.1413 - val_loss: 0.1194 - val_mae: 0.2330\n",
            "Epoch 417/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0362 - mae: 0.1438 - val_loss: 0.1465 - val_mae: 0.2476\n",
            "Epoch 418/600\n",
            "180/180 [==============================] - 0s 214us/sample - loss: 0.0367 - mae: 0.1375 - val_loss: 0.1460 - val_mae: 0.2427\n",
            "Epoch 419/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0373 - mae: 0.1407 - val_loss: 0.1300 - val_mae: 0.2335\n",
            "Epoch 420/600\n",
            "180/180 [==============================] - 0s 141us/sample - loss: 0.0362 - mae: 0.1375 - val_loss: 0.1288 - val_mae: 0.2313\n",
            "Epoch 421/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0348 - mae: 0.1403 - val_loss: 0.1326 - val_mae: 0.2316\n",
            "Epoch 422/600\n",
            "180/180 [==============================] - 0s 196us/sample - loss: 0.0343 - mae: 0.1368 - val_loss: 0.1438 - val_mae: 0.2509\n",
            "Epoch 423/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0344 - mae: 0.1335 - val_loss: 0.1368 - val_mae: 0.2341\n",
            "Epoch 424/600\n",
            "180/180 [==============================] - 0s 202us/sample - loss: 0.0372 - mae: 0.1421 - val_loss: 0.1405 - val_mae: 0.2656\n",
            "Epoch 425/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0334 - mae: 0.1327 - val_loss: 0.1223 - val_mae: 0.2388\n",
            "Epoch 426/600\n",
            "180/180 [==============================] - 0s 160us/sample - loss: 0.0350 - mae: 0.1406 - val_loss: 0.1457 - val_mae: 0.2644\n",
            "Epoch 427/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0349 - mae: 0.1388 - val_loss: 0.1272 - val_mae: 0.2353\n",
            "Epoch 428/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0342 - mae: 0.1381 - val_loss: 0.1335 - val_mae: 0.2463\n",
            "Epoch 429/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0353 - mae: 0.1375 - val_loss: 0.1585 - val_mae: 0.2705\n",
            "Epoch 430/600\n",
            "180/180 [==============================] - 0s 181us/sample - loss: 0.0339 - mae: 0.1340 - val_loss: 0.1433 - val_mae: 0.2612\n",
            "Epoch 431/600\n",
            "180/180 [==============================] - 0s 195us/sample - loss: 0.0342 - mae: 0.1334 - val_loss: 0.1397 - val_mae: 0.2789\n",
            "Epoch 432/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0330 - mae: 0.1343 - val_loss: 0.1312 - val_mae: 0.2414\n",
            "Epoch 433/600\n",
            "180/180 [==============================] - 0s 192us/sample - loss: 0.0323 - mae: 0.1314 - val_loss: 0.1246 - val_mae: 0.2372\n",
            "Epoch 434/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0340 - mae: 0.1371 - val_loss: 0.1446 - val_mae: 0.2408\n",
            "Epoch 435/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0330 - mae: 0.1324 - val_loss: 0.1293 - val_mae: 0.2272\n",
            "Epoch 436/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0331 - mae: 0.1328 - val_loss: 0.1502 - val_mae: 0.2396\n",
            "Epoch 437/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0329 - mae: 0.1316 - val_loss: 0.1587 - val_mae: 0.2624\n",
            "Epoch 438/600\n",
            "180/180 [==============================] - 0s 164us/sample - loss: 0.0323 - mae: 0.1325 - val_loss: 0.1307 - val_mae: 0.2243\n",
            "Epoch 439/600\n",
            "180/180 [==============================] - 0s 182us/sample - loss: 0.0327 - mae: 0.1356 - val_loss: 0.1369 - val_mae: 0.2361\n",
            "Epoch 440/600\n",
            "180/180 [==============================] - 0s 198us/sample - loss: 0.0348 - mae: 0.1352 - val_loss: 0.1160 - val_mae: 0.2206\n",
            "Epoch 441/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0314 - mae: 0.1301 - val_loss: 0.1284 - val_mae: 0.2286\n",
            "Epoch 442/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0317 - mae: 0.1310 - val_loss: 0.1287 - val_mae: 0.2275\n",
            "Epoch 443/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0317 - mae: 0.1260 - val_loss: 0.1159 - val_mae: 0.2196\n",
            "Epoch 444/600\n",
            "180/180 [==============================] - 0s 170us/sample - loss: 0.0328 - mae: 0.1317 - val_loss: 0.1273 - val_mae: 0.2253\n",
            "Epoch 445/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0313 - mae: 0.1286 - val_loss: 0.1262 - val_mae: 0.2217\n",
            "Epoch 446/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0316 - mae: 0.1299 - val_loss: 0.1123 - val_mae: 0.2181\n",
            "Epoch 447/600\n",
            "180/180 [==============================] - 0s 216us/sample - loss: 0.0317 - mae: 0.1341 - val_loss: 0.1463 - val_mae: 0.2575\n",
            "Epoch 448/600\n",
            "180/180 [==============================] - 0s 144us/sample - loss: 0.0336 - mae: 0.1308 - val_loss: 0.1233 - val_mae: 0.2269\n",
            "Epoch 449/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0321 - mae: 0.1308 - val_loss: 0.1245 - val_mae: 0.2210\n",
            "Epoch 450/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0318 - mae: 0.1285 - val_loss: 0.1098 - val_mae: 0.2296\n",
            "Epoch 451/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0318 - mae: 0.1326 - val_loss: 0.1355 - val_mae: 0.2692\n",
            "Epoch 452/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0348 - mae: 0.1348 - val_loss: 0.1184 - val_mae: 0.2190\n",
            "Epoch 453/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0292 - mae: 0.1223 - val_loss: 0.1162 - val_mae: 0.2190\n",
            "Epoch 454/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0301 - mae: 0.1293 - val_loss: 0.1189 - val_mae: 0.2179\n",
            "Epoch 455/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0294 - mae: 0.1254 - val_loss: 0.1403 - val_mae: 0.2781\n",
            "Epoch 456/600\n",
            "180/180 [==============================] - 0s 185us/sample - loss: 0.0284 - mae: 0.1234 - val_loss: 0.1187 - val_mae: 0.2320\n",
            "Epoch 457/600\n",
            "180/180 [==============================] - 0s 203us/sample - loss: 0.0311 - mae: 0.1268 - val_loss: 0.1080 - val_mae: 0.2128\n",
            "Epoch 458/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0282 - mae: 0.1223 - val_loss: 0.0996 - val_mae: 0.2095\n",
            "Epoch 459/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.0290 - mae: 0.1263 - val_loss: 0.1046 - val_mae: 0.2317\n",
            "Epoch 460/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0297 - mae: 0.1312 - val_loss: 0.1051 - val_mae: 0.2146\n",
            "Epoch 461/600\n",
            "180/180 [==============================] - 0s 192us/sample - loss: 0.0329 - mae: 0.1346 - val_loss: 0.1066 - val_mae: 0.2126\n",
            "Epoch 462/600\n",
            "180/180 [==============================] - 0s 176us/sample - loss: 0.0297 - mae: 0.1265 - val_loss: 0.0946 - val_mae: 0.2137\n",
            "Epoch 463/600\n",
            "180/180 [==============================] - 0s 175us/sample - loss: 0.0294 - mae: 0.1299 - val_loss: 0.1263 - val_mae: 0.2376\n",
            "Epoch 464/600\n",
            "180/180 [==============================] - 0s 167us/sample - loss: 0.0281 - mae: 0.1252 - val_loss: 0.0963 - val_mae: 0.2075\n",
            "Epoch 465/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0285 - mae: 0.1259 - val_loss: 0.1111 - val_mae: 0.2177\n",
            "Epoch 466/600\n",
            "180/180 [==============================] - 0s 169us/sample - loss: 0.0271 - mae: 0.1221 - val_loss: 0.1070 - val_mae: 0.2077\n",
            "Epoch 467/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0283 - mae: 0.1274 - val_loss: 0.1170 - val_mae: 0.2118\n",
            "Epoch 468/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0273 - mae: 0.1166 - val_loss: 0.1330 - val_mae: 0.2639\n",
            "Epoch 469/600\n",
            "180/180 [==============================] - 0s 164us/sample - loss: 0.0297 - mae: 0.1277 - val_loss: 0.1263 - val_mae: 0.2163\n",
            "Epoch 470/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0280 - mae: 0.1217 - val_loss: 0.1000 - val_mae: 0.2074\n",
            "Epoch 471/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0275 - mae: 0.1244 - val_loss: 0.1257 - val_mae: 0.2586\n",
            "Epoch 472/600\n",
            "180/180 [==============================] - 0s 182us/sample - loss: 0.0272 - mae: 0.1238 - val_loss: 0.1128 - val_mae: 0.2302\n",
            "Epoch 473/600\n",
            "180/180 [==============================] - 0s 148us/sample - loss: 0.0279 - mae: 0.1241 - val_loss: 0.1123 - val_mae: 0.2131\n",
            "Epoch 474/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0275 - mae: 0.1239 - val_loss: 0.1116 - val_mae: 0.2113\n",
            "Epoch 475/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0265 - mae: 0.1205 - val_loss: 0.0924 - val_mae: 0.2013\n",
            "Epoch 476/600\n",
            "180/180 [==============================] - 0s 230us/sample - loss: 0.0257 - mae: 0.1161 - val_loss: 0.1113 - val_mae: 0.2346\n",
            "Epoch 477/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0271 - mae: 0.1215 - val_loss: 0.1145 - val_mae: 0.2460\n",
            "Epoch 478/600\n",
            "180/180 [==============================] - 0s 125us/sample - loss: 0.0264 - mae: 0.1199 - val_loss: 0.0957 - val_mae: 0.2038\n",
            "Epoch 479/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0271 - mae: 0.1190 - val_loss: 0.0972 - val_mae: 0.2207\n",
            "Epoch 480/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0275 - mae: 0.1207 - val_loss: 0.0992 - val_mae: 0.2060\n",
            "Epoch 481/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0273 - mae: 0.1223 - val_loss: 0.0881 - val_mae: 0.1987\n",
            "Epoch 482/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0246 - mae: 0.1185 - val_loss: 0.1074 - val_mae: 0.2171\n",
            "Epoch 483/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0252 - mae: 0.1174 - val_loss: 0.1030 - val_mae: 0.2042\n",
            "Epoch 484/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0238 - mae: 0.1123 - val_loss: 0.1029 - val_mae: 0.2155\n",
            "Epoch 485/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0259 - mae: 0.1168 - val_loss: 0.0995 - val_mae: 0.2048\n",
            "Epoch 486/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0259 - mae: 0.1207 - val_loss: 0.1134 - val_mae: 0.2353\n",
            "Epoch 487/600\n",
            "180/180 [==============================] - 0s 153us/sample - loss: 0.0260 - mae: 0.1220 - val_loss: 0.1044 - val_mae: 0.2019\n",
            "Epoch 488/600\n",
            "180/180 [==============================] - 0s 225us/sample - loss: 0.0231 - mae: 0.1134 - val_loss: 0.1541 - val_mae: 0.2750\n",
            "Epoch 489/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0277 - mae: 0.1215 - val_loss: 0.1187 - val_mae: 0.2291\n",
            "Epoch 490/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0245 - mae: 0.1124 - val_loss: 0.1058 - val_mae: 0.2060\n",
            "Epoch 491/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.0242 - mae: 0.1157 - val_loss: 0.1065 - val_mae: 0.2130\n",
            "Epoch 492/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0245 - mae: 0.1158 - val_loss: 0.1083 - val_mae: 0.2087\n",
            "Epoch 493/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0263 - mae: 0.1214 - val_loss: 0.0958 - val_mae: 0.2135\n",
            "Epoch 494/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0237 - mae: 0.1155 - val_loss: 0.0900 - val_mae: 0.2171\n",
            "Epoch 495/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0255 - mae: 0.1212 - val_loss: 0.0906 - val_mae: 0.1977\n",
            "Epoch 496/600\n",
            "180/180 [==============================] - 0s 137us/sample - loss: 0.0251 - mae: 0.1169 - val_loss: 0.0939 - val_mae: 0.1954\n",
            "Epoch 497/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0253 - mae: 0.1174 - val_loss: 0.0918 - val_mae: 0.1962\n",
            "Epoch 498/600\n",
            "180/180 [==============================] - 0s 172us/sample - loss: 0.0236 - mae: 0.1157 - val_loss: 0.1021 - val_mae: 0.2083\n",
            "Epoch 499/600\n",
            "180/180 [==============================] - 0s 132us/sample - loss: 0.0247 - mae: 0.1178 - val_loss: 0.1018 - val_mae: 0.2035\n",
            "Epoch 500/600\n",
            "180/180 [==============================] - 0s 228us/sample - loss: 0.0242 - mae: 0.1154 - val_loss: 0.0800 - val_mae: 0.1968\n",
            "Epoch 501/600\n",
            "180/180 [==============================] - 0s 196us/sample - loss: 0.0231 - mae: 0.1144 - val_loss: 0.0791 - val_mae: 0.1908\n",
            "Epoch 502/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0245 - mae: 0.1163 - val_loss: 0.0827 - val_mae: 0.1977\n",
            "Epoch 503/600\n",
            "180/180 [==============================] - 0s 190us/sample - loss: 0.0233 - mae: 0.1146 - val_loss: 0.0815 - val_mae: 0.1930\n",
            "Epoch 504/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0243 - mae: 0.1166 - val_loss: 0.0915 - val_mae: 0.2065\n",
            "Epoch 505/600\n",
            "180/180 [==============================] - 0s 195us/sample - loss: 0.0235 - mae: 0.1179 - val_loss: 0.0970 - val_mae: 0.1934\n",
            "Epoch 506/600\n",
            "180/180 [==============================] - 0s 122us/sample - loss: 0.0218 - mae: 0.1081 - val_loss: 0.0957 - val_mae: 0.1959\n",
            "Epoch 507/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0235 - mae: 0.1102 - val_loss: 0.0975 - val_mae: 0.1950\n",
            "Epoch 508/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0230 - mae: 0.1132 - val_loss: 0.0906 - val_mae: 0.1932\n",
            "Epoch 509/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0236 - mae: 0.1126 - val_loss: 0.0844 - val_mae: 0.1891\n",
            "Epoch 510/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0237 - mae: 0.1155 - val_loss: 0.0785 - val_mae: 0.1878\n",
            "Epoch 511/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0238 - mae: 0.1125 - val_loss: 0.0776 - val_mae: 0.1857\n",
            "Epoch 512/600\n",
            "180/180 [==============================] - 0s 183us/sample - loss: 0.0220 - mae: 0.1117 - val_loss: 0.0839 - val_mae: 0.1961\n",
            "Epoch 513/600\n",
            "180/180 [==============================] - 0s 175us/sample - loss: 0.0222 - mae: 0.1144 - val_loss: 0.0806 - val_mae: 0.1895\n",
            "Epoch 514/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0201 - mae: 0.1043 - val_loss: 0.0832 - val_mae: 0.1885\n",
            "Epoch 515/600\n",
            "180/180 [==============================] - 0s 180us/sample - loss: 0.0215 - mae: 0.1090 - val_loss: 0.0950 - val_mae: 0.1922\n",
            "Epoch 516/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0215 - mae: 0.1071 - val_loss: 0.0987 - val_mae: 0.2344\n",
            "Epoch 517/600\n",
            "180/180 [==============================] - 0s 155us/sample - loss: 0.0236 - mae: 0.1124 - val_loss: 0.0813 - val_mae: 0.1887\n",
            "Epoch 518/600\n",
            "180/180 [==============================] - 0s 197us/sample - loss: 0.0236 - mae: 0.1162 - val_loss: 0.0767 - val_mae: 0.1868\n",
            "Epoch 519/600\n",
            "180/180 [==============================] - 0s 205us/sample - loss: 0.0208 - mae: 0.1088 - val_loss: 0.0818 - val_mae: 0.1842\n",
            "Epoch 520/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0209 - mae: 0.1071 - val_loss: 0.0728 - val_mae: 0.1809\n",
            "Epoch 521/600\n",
            "180/180 [==============================] - 0s 154us/sample - loss: 0.0230 - mae: 0.1103 - val_loss: 0.0800 - val_mae: 0.1869\n",
            "Epoch 522/600\n",
            "180/180 [==============================] - 0s 143us/sample - loss: 0.0218 - mae: 0.1128 - val_loss: 0.0932 - val_mae: 0.1869\n",
            "Epoch 523/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0221 - mae: 0.1090 - val_loss: 0.0889 - val_mae: 0.2045\n",
            "Epoch 524/600\n",
            "180/180 [==============================] - 0s 178us/sample - loss: 0.0204 - mae: 0.1083 - val_loss: 0.1167 - val_mae: 0.2472\n",
            "Epoch 525/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0248 - mae: 0.1096 - val_loss: 0.0788 - val_mae: 0.1904\n",
            "Epoch 526/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0201 - mae: 0.1058 - val_loss: 0.0987 - val_mae: 0.1905\n",
            "Epoch 527/600\n",
            "180/180 [==============================] - 0s 183us/sample - loss: 0.0210 - mae: 0.1053 - val_loss: 0.0877 - val_mae: 0.2112\n",
            "Epoch 528/600\n",
            "180/180 [==============================] - 0s 188us/sample - loss: 0.0200 - mae: 0.1059 - val_loss: 0.0764 - val_mae: 0.1797\n",
            "Epoch 529/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0208 - mae: 0.1086 - val_loss: 0.0859 - val_mae: 0.2081\n",
            "Epoch 530/600\n",
            "180/180 [==============================] - 0s 163us/sample - loss: 0.0211 - mae: 0.1070 - val_loss: 0.0720 - val_mae: 0.1943\n",
            "Epoch 531/600\n",
            "180/180 [==============================] - 0s 173us/sample - loss: 0.0212 - mae: 0.1105 - val_loss: 0.0788 - val_mae: 0.1843\n",
            "Epoch 532/600\n",
            "180/180 [==============================] - 0s 165us/sample - loss: 0.0207 - mae: 0.1069 - val_loss: 0.0769 - val_mae: 0.1795\n",
            "Epoch 533/600\n",
            "180/180 [==============================] - 0s 161us/sample - loss: 0.0192 - mae: 0.1022 - val_loss: 0.0833 - val_mae: 0.1844\n",
            "Epoch 534/600\n",
            "180/180 [==============================] - 0s 199us/sample - loss: 0.0200 - mae: 0.1030 - val_loss: 0.0754 - val_mae: 0.1849\n",
            "Epoch 535/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0184 - mae: 0.1012 - val_loss: 0.0895 - val_mae: 0.1869\n",
            "Epoch 536/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0215 - mae: 0.1037 - val_loss: 0.0738 - val_mae: 0.1824\n",
            "Epoch 537/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0211 - mae: 0.1086 - val_loss: 0.0787 - val_mae: 0.1724\n",
            "Epoch 538/600\n",
            "180/180 [==============================] - 0s 180us/sample - loss: 0.0207 - mae: 0.1058 - val_loss: 0.0805 - val_mae: 0.1808\n",
            "Epoch 539/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0183 - mae: 0.1017 - val_loss: 0.0762 - val_mae: 0.1994\n",
            "Epoch 540/600\n",
            "180/180 [==============================] - 0s 175us/sample - loss: 0.0207 - mae: 0.1087 - val_loss: 0.0867 - val_mae: 0.2049\n",
            "Epoch 541/600\n",
            "180/180 [==============================] - 0s 191us/sample - loss: 0.0200 - mae: 0.1064 - val_loss: 0.0728 - val_mae: 0.1740\n",
            "Epoch 542/600\n",
            "180/180 [==============================] - 0s 210us/sample - loss: 0.0197 - mae: 0.1033 - val_loss: 0.0803 - val_mae: 0.1822\n",
            "Epoch 543/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0192 - mae: 0.1058 - val_loss: 0.0736 - val_mae: 0.1750\n",
            "Epoch 544/600\n",
            "180/180 [==============================] - 0s 142us/sample - loss: 0.0218 - mae: 0.1117 - val_loss: 0.0896 - val_mae: 0.2109\n",
            "Epoch 545/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0189 - mae: 0.1009 - val_loss: 0.0570 - val_mae: 0.1675\n",
            "Epoch 546/600\n",
            "180/180 [==============================] - 0s 139us/sample - loss: 0.0187 - mae: 0.1032 - val_loss: 0.0758 - val_mae: 0.1745\n",
            "Epoch 547/600\n",
            "180/180 [==============================] - 0s 202us/sample - loss: 0.0198 - mae: 0.1065 - val_loss: 0.0659 - val_mae: 0.1700\n",
            "Epoch 548/600\n",
            "180/180 [==============================] - 0s 140us/sample - loss: 0.0203 - mae: 0.1074 - val_loss: 0.0756 - val_mae: 0.1787\n",
            "Epoch 549/600\n",
            "180/180 [==============================] - 0s 159us/sample - loss: 0.0180 - mae: 0.1008 - val_loss: 0.0773 - val_mae: 0.2013\n",
            "Epoch 550/600\n",
            "180/180 [==============================] - 0s 187us/sample - loss: 0.0196 - mae: 0.1073 - val_loss: 0.0785 - val_mae: 0.1910\n",
            "Epoch 551/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0198 - mae: 0.1057 - val_loss: 0.0656 - val_mae: 0.1726\n",
            "Epoch 552/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0197 - mae: 0.1091 - val_loss: 0.0675 - val_mae: 0.1651\n",
            "Epoch 553/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0178 - mae: 0.1009 - val_loss: 0.1095 - val_mae: 0.2494\n",
            "Epoch 554/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0216 - mae: 0.1096 - val_loss: 0.0764 - val_mae: 0.1811\n",
            "Epoch 555/600\n",
            "180/180 [==============================] - 0s 166us/sample - loss: 0.0190 - mae: 0.1016 - val_loss: 0.0720 - val_mae: 0.1920\n",
            "Epoch 556/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0207 - mae: 0.1074 - val_loss: 0.0698 - val_mae: 0.1710\n",
            "Epoch 557/600\n",
            "180/180 [==============================] - 0s 193us/sample - loss: 0.0195 - mae: 0.1048 - val_loss: 0.0884 - val_mae: 0.2209\n",
            "Epoch 558/600\n",
            "180/180 [==============================] - 0s 183us/sample - loss: 0.0182 - mae: 0.1019 - val_loss: 0.0746 - val_mae: 0.1711\n",
            "Epoch 559/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0191 - mae: 0.1051 - val_loss: 0.0850 - val_mae: 0.2014\n",
            "Epoch 560/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.0192 - mae: 0.1032 - val_loss: 0.0779 - val_mae: 0.1743\n",
            "Epoch 561/600\n",
            "180/180 [==============================] - 0s 162us/sample - loss: 0.0186 - mae: 0.0998 - val_loss: 0.0854 - val_mae: 0.2122\n",
            "Epoch 562/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0186 - mae: 0.0980 - val_loss: 0.0616 - val_mae: 0.1625\n",
            "Epoch 563/600\n",
            "180/180 [==============================] - 0s 216us/sample - loss: 0.0188 - mae: 0.1027 - val_loss: 0.0748 - val_mae: 0.1690\n",
            "Epoch 564/600\n",
            "180/180 [==============================] - 0s 149us/sample - loss: 0.0173 - mae: 0.0988 - val_loss: 0.0714 - val_mae: 0.1656\n",
            "Epoch 565/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0167 - mae: 0.0972 - val_loss: 0.0818 - val_mae: 0.2128\n",
            "Epoch 566/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0187 - mae: 0.1015 - val_loss: 0.0489 - val_mae: 0.1582\n",
            "Epoch 567/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0173 - mae: 0.0979 - val_loss: 0.0538 - val_mae: 0.1753\n",
            "Epoch 568/600\n",
            "180/180 [==============================] - 0s 183us/sample - loss: 0.0173 - mae: 0.0993 - val_loss: 0.0662 - val_mae: 0.1922\n",
            "Epoch 569/600\n",
            "180/180 [==============================] - 0s 203us/sample - loss: 0.0197 - mae: 0.1059 - val_loss: 0.0543 - val_mae: 0.1601\n",
            "Epoch 570/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0175 - mae: 0.1009 - val_loss: 0.0601 - val_mae: 0.1555\n",
            "Epoch 571/600\n",
            "180/180 [==============================] - 0s 164us/sample - loss: 0.0174 - mae: 0.0999 - val_loss: 0.0676 - val_mae: 0.1754\n",
            "Epoch 572/600\n",
            "180/180 [==============================] - 0s 169us/sample - loss: 0.0191 - mae: 0.1058 - val_loss: 0.0586 - val_mae: 0.1579\n",
            "Epoch 573/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0175 - mae: 0.1014 - val_loss: 0.0642 - val_mae: 0.1670\n",
            "Epoch 574/600\n",
            "180/180 [==============================] - 0s 177us/sample - loss: 0.0159 - mae: 0.0929 - val_loss: 0.0574 - val_mae: 0.1711\n",
            "Epoch 575/600\n",
            "180/180 [==============================] - 0s 138us/sample - loss: 0.0178 - mae: 0.1018 - val_loss: 0.0605 - val_mae: 0.1582\n",
            "Epoch 576/600\n",
            "180/180 [==============================] - 0s 145us/sample - loss: 0.0167 - mae: 0.1005 - val_loss: 0.0514 - val_mae: 0.1529\n",
            "Epoch 577/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0185 - mae: 0.1064 - val_loss: 0.0707 - val_mae: 0.1656\n",
            "Epoch 578/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0173 - mae: 0.0974 - val_loss: 0.0526 - val_mae: 0.1558\n",
            "Epoch 579/600\n",
            "180/180 [==============================] - 0s 183us/sample - loss: 0.0160 - mae: 0.0978 - val_loss: 0.0642 - val_mae: 0.1799\n",
            "Epoch 580/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0159 - mae: 0.0946 - val_loss: 0.0538 - val_mae: 0.1694\n",
            "Epoch 581/600\n",
            "180/180 [==============================] - 0s 156us/sample - loss: 0.0173 - mae: 0.1013 - val_loss: 0.0677 - val_mae: 0.1625\n",
            "Epoch 582/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0173 - mae: 0.0995 - val_loss: 0.0614 - val_mae: 0.1585\n",
            "Epoch 583/600\n",
            "180/180 [==============================] - 0s 147us/sample - loss: 0.0170 - mae: 0.0958 - val_loss: 0.0491 - val_mae: 0.1536\n",
            "Epoch 584/600\n",
            "180/180 [==============================] - 0s 152us/sample - loss: 0.0169 - mae: 0.1016 - val_loss: 0.0659 - val_mae: 0.1658\n",
            "Epoch 585/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0160 - mae: 0.0961 - val_loss: 0.0630 - val_mae: 0.1909\n",
            "Epoch 586/600\n",
            "180/180 [==============================] - 0s 146us/sample - loss: 0.0172 - mae: 0.1004 - val_loss: 0.0623 - val_mae: 0.1710\n",
            "Epoch 587/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0171 - mae: 0.0993 - val_loss: 0.0458 - val_mae: 0.1685\n",
            "Epoch 588/600\n",
            "180/180 [==============================] - 0s 135us/sample - loss: 0.0168 - mae: 0.1003 - val_loss: 0.0886 - val_mae: 0.2289\n",
            "Epoch 589/600\n",
            "180/180 [==============================] - 0s 199us/sample - loss: 0.0183 - mae: 0.1029 - val_loss: 0.0614 - val_mae: 0.1719\n",
            "Epoch 590/600\n",
            "180/180 [==============================] - 0s 157us/sample - loss: 0.0161 - mae: 0.0963 - val_loss: 0.0478 - val_mae: 0.1528\n",
            "Epoch 591/600\n",
            "180/180 [==============================] - 0s 151us/sample - loss: 0.0152 - mae: 0.0956 - val_loss: 0.0819 - val_mae: 0.2322\n",
            "Epoch 592/600\n",
            "180/180 [==============================] - 0s 217us/sample - loss: 0.0188 - mae: 0.1021 - val_loss: 0.0424 - val_mae: 0.1459\n",
            "Epoch 593/600\n",
            "180/180 [==============================] - 0s 201us/sample - loss: 0.0147 - mae: 0.0941 - val_loss: 0.0839 - val_mae: 0.2219\n",
            "Epoch 594/600\n",
            "180/180 [==============================] - 0s 199us/sample - loss: 0.0175 - mae: 0.1005 - val_loss: 0.0733 - val_mae: 0.1635\n",
            "Epoch 595/600\n",
            "180/180 [==============================] - 0s 179us/sample - loss: 0.0169 - mae: 0.0990 - val_loss: 0.0550 - val_mae: 0.1608\n",
            "Epoch 596/600\n",
            "180/180 [==============================] - 0s 174us/sample - loss: 0.0163 - mae: 0.0979 - val_loss: 0.0398 - val_mae: 0.1501\n",
            "Epoch 597/600\n",
            "180/180 [==============================] - 0s 158us/sample - loss: 0.0164 - mae: 0.1016 - val_loss: 0.0613 - val_mae: 0.1731\n",
            "Epoch 598/600\n",
            "180/180 [==============================] - 0s 230us/sample - loss: 0.0160 - mae: 0.0957 - val_loss: 0.0559 - val_mae: 0.1553\n",
            "Epoch 599/600\n",
            "180/180 [==============================] - 0s 184us/sample - loss: 0.0150 - mae: 0.0951 - val_loss: 0.0463 - val_mae: 0.1460\n",
            "Epoch 600/600\n",
            "180/180 [==============================] - 0s 205us/sample - loss: 0.0181 - mae: 0.1040 - val_loss: 0.0509 - val_mae: 0.1442\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "9W1RqAydOSYT",
        "outputId": "90f45b0f-e108-4e2c-b73c-4c0c97c1f876"
      },
      "source": [
        "#Toy problem y=sin(x) training data of 1000 samples and 300 samples\n",
        "predictions1 = model_2.predict(x1_train)\n",
        "predictions = model_1.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('Training data of 1000 samples and 300 samples')\n",
        "plt.plot(x_train, predictions, 'b.', label='1000 samples')\n",
        "plt.plot(x1_train, predictions1, 'r.', label='300 samples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fAqjZlWrdsav",
        "outputId": "135663ef-9d8a-4c23-8c03-257beba98409"
      },
      "source": [
        "#Toy Problem Y=sin(x) 1000 samples of period -2pi to 2pi with batch size of 1\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 1000\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=-(2*math.pi), high=2*math.pi,size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "#plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_1 = tf.keras.Sequential()\n",
        "model_1.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_1.add(layers.Dense(16, activation='relu'))\n",
        "model_1.add(layers.Dense(1))\n",
        "model_1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_1.summary()\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=600, batch_size=1, validation_data=(x_validate, y_validate))\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_1.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_60 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 600 samples, validate on 200 samples\n",
            "Epoch 1/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.8907 - mae: 0.7065 - val_loss: 0.3539 - val_mae: 0.5018\n",
            "Epoch 2/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.3106 - mae: 0.4754 - val_loss: 0.3458 - val_mae: 0.4863\n",
            "Epoch 3/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.2452 - mae: 0.4230 - val_loss: 0.2069 - val_mae: 0.3742\n",
            "Epoch 4/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1967 - mae: 0.3654 - val_loss: 0.1556 - val_mae: 0.3231\n",
            "Epoch 5/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1778 - mae: 0.3289 - val_loss: 0.1415 - val_mae: 0.3005\n",
            "Epoch 6/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1660 - mae: 0.3080 - val_loss: 0.2291 - val_mae: 0.3457\n",
            "Epoch 7/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1732 - mae: 0.3054 - val_loss: 0.1626 - val_mae: 0.2921\n",
            "Epoch 8/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1683 - mae: 0.2958 - val_loss: 0.1314 - val_mae: 0.2718\n",
            "Epoch 9/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1700 - mae: 0.2934 - val_loss: 0.1294 - val_mae: 0.2705\n",
            "Epoch 10/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1678 - mae: 0.2925 - val_loss: 0.1315 - val_mae: 0.2693\n",
            "Epoch 11/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1667 - mae: 0.2906 - val_loss: 0.1456 - val_mae: 0.2751\n",
            "Epoch 12/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1668 - mae: 0.2877 - val_loss: 0.2008 - val_mae: 0.3080\n",
            "Epoch 13/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1727 - mae: 0.2840 - val_loss: 0.1518 - val_mae: 0.2764\n",
            "Epoch 14/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1689 - mae: 0.2890 - val_loss: 0.1343 - val_mae: 0.2647\n",
            "Epoch 15/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1719 - mae: 0.2899 - val_loss: 0.1425 - val_mae: 0.2801\n",
            "Epoch 16/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1735 - mae: 0.2919 - val_loss: 0.1436 - val_mae: 0.2819\n",
            "Epoch 17/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1706 - mae: 0.2919 - val_loss: 0.1317 - val_mae: 0.2734\n",
            "Epoch 18/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1712 - mae: 0.2894 - val_loss: 0.1339 - val_mae: 0.2707\n",
            "Epoch 19/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1721 - mae: 0.2948 - val_loss: 0.1759 - val_mae: 0.2802\n",
            "Epoch 20/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1639 - mae: 0.2885 - val_loss: 0.1259 - val_mae: 0.2612\n",
            "Epoch 21/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1600 - mae: 0.2784 - val_loss: 0.1806 - val_mae: 0.3062\n",
            "Epoch 22/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1556 - mae: 0.2772 - val_loss: 0.1194 - val_mae: 0.2542\n",
            "Epoch 23/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1579 - mae: 0.2782 - val_loss: 0.1683 - val_mae: 0.2841\n",
            "Epoch 24/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1583 - mae: 0.2782 - val_loss: 0.1164 - val_mae: 0.2506\n",
            "Epoch 25/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1515 - mae: 0.2750 - val_loss: 0.1332 - val_mae: 0.2499\n",
            "Epoch 26/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1541 - mae: 0.2749 - val_loss: 0.1229 - val_mae: 0.2507\n",
            "Epoch 27/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1491 - mae: 0.2679 - val_loss: 0.1269 - val_mae: 0.2506\n",
            "Epoch 28/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1371 - mae: 0.2586 - val_loss: 0.1342 - val_mae: 0.2575\n",
            "Epoch 29/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1466 - mae: 0.2666 - val_loss: 0.1253 - val_mae: 0.2509\n",
            "Epoch 30/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1417 - mae: 0.2618 - val_loss: 0.1097 - val_mae: 0.2363\n",
            "Epoch 31/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1395 - mae: 0.2636 - val_loss: 0.1096 - val_mae: 0.2366\n",
            "Epoch 32/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1267 - mae: 0.2523 - val_loss: 0.1150 - val_mae: 0.2301\n",
            "Epoch 33/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1275 - mae: 0.2508 - val_loss: 0.0942 - val_mae: 0.2208\n",
            "Epoch 34/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1218 - mae: 0.2428 - val_loss: 0.0890 - val_mae: 0.2198\n",
            "Epoch 35/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1217 - mae: 0.2357 - val_loss: 0.1409 - val_mae: 0.2712\n",
            "Epoch 36/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1189 - mae: 0.2415 - val_loss: 0.0921 - val_mae: 0.2131\n",
            "Epoch 37/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1111 - mae: 0.2306 - val_loss: 0.0896 - val_mae: 0.2139\n",
            "Epoch 38/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1034 - mae: 0.2252 - val_loss: 0.1114 - val_mae: 0.2369\n",
            "Epoch 39/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.1110 - mae: 0.2260 - val_loss: 0.0770 - val_mae: 0.2037\n",
            "Epoch 40/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0992 - mae: 0.2224 - val_loss: 0.0785 - val_mae: 0.1987\n",
            "Epoch 41/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0956 - mae: 0.2156 - val_loss: 0.0826 - val_mae: 0.2137\n",
            "Epoch 42/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0970 - mae: 0.2178 - val_loss: 0.0704 - val_mae: 0.1963\n",
            "Epoch 43/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0892 - mae: 0.2070 - val_loss: 0.0754 - val_mae: 0.1965\n",
            "Epoch 44/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0858 - mae: 0.2072 - val_loss: 0.0679 - val_mae: 0.1784\n",
            "Epoch 45/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0827 - mae: 0.1919 - val_loss: 0.0606 - val_mae: 0.1800\n",
            "Epoch 46/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0810 - mae: 0.1986 - val_loss: 0.0676 - val_mae: 0.1883\n",
            "Epoch 47/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0721 - mae: 0.1851 - val_loss: 0.0523 - val_mae: 0.1628\n",
            "Epoch 48/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0683 - mae: 0.1819 - val_loss: 0.0948 - val_mae: 0.2182\n",
            "Epoch 49/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0676 - mae: 0.1817 - val_loss: 0.0523 - val_mae: 0.1581\n",
            "Epoch 50/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0639 - mae: 0.1750 - val_loss: 0.0528 - val_mae: 0.1569\n",
            "Epoch 51/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0604 - mae: 0.1727 - val_loss: 0.0454 - val_mae: 0.1576\n",
            "Epoch 52/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0582 - mae: 0.1701 - val_loss: 0.0624 - val_mae: 0.1584\n",
            "Epoch 53/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0601 - mae: 0.1707 - val_loss: 0.0503 - val_mae: 0.1435\n",
            "Epoch 54/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0546 - mae: 0.1622 - val_loss: 0.0383 - val_mae: 0.1394\n",
            "Epoch 55/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0506 - mae: 0.1588 - val_loss: 0.0397 - val_mae: 0.1343\n",
            "Epoch 56/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0493 - mae: 0.1544 - val_loss: 0.0359 - val_mae: 0.1263\n",
            "Epoch 57/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0473 - mae: 0.1528 - val_loss: 0.0395 - val_mae: 0.1255\n",
            "Epoch 58/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0456 - mae: 0.1486 - val_loss: 0.0378 - val_mae: 0.1189\n",
            "Epoch 59/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0421 - mae: 0.1455 - val_loss: 0.0483 - val_mae: 0.1574\n",
            "Epoch 60/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0426 - mae: 0.1460 - val_loss: 0.0406 - val_mae: 0.1400\n",
            "Epoch 61/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0412 - mae: 0.1423 - val_loss: 0.0494 - val_mae: 0.1598\n",
            "Epoch 62/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0423 - mae: 0.1443 - val_loss: 0.0308 - val_mae: 0.1266\n",
            "Epoch 63/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0386 - mae: 0.1383 - val_loss: 0.0266 - val_mae: 0.1180\n",
            "Epoch 64/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0388 - mae: 0.1415 - val_loss: 0.0450 - val_mae: 0.1597\n",
            "Epoch 65/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0369 - mae: 0.1398 - val_loss: 0.0516 - val_mae: 0.1663\n",
            "Epoch 66/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0371 - mae: 0.1368 - val_loss: 0.0282 - val_mae: 0.1272\n",
            "Epoch 67/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0367 - mae: 0.1374 - val_loss: 0.0468 - val_mae: 0.1713\n",
            "Epoch 68/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0340 - mae: 0.1341 - val_loss: 0.0348 - val_mae: 0.1433\n",
            "Epoch 69/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0305 - mae: 0.1267 - val_loss: 0.0352 - val_mae: 0.1386\n",
            "Epoch 70/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0344 - mae: 0.1347 - val_loss: 0.0236 - val_mae: 0.1052\n",
            "Epoch 71/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0306 - mae: 0.1304 - val_loss: 0.0212 - val_mae: 0.1004\n",
            "Epoch 72/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0324 - mae: 0.1308 - val_loss: 0.0204 - val_mae: 0.0996\n",
            "Epoch 73/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0299 - mae: 0.1273 - val_loss: 0.0218 - val_mae: 0.1050\n",
            "Epoch 74/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0294 - mae: 0.1272 - val_loss: 0.0195 - val_mae: 0.1032\n",
            "Epoch 75/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0310 - mae: 0.1291 - val_loss: 0.0267 - val_mae: 0.1274\n",
            "Epoch 76/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0285 - mae: 0.1267 - val_loss: 0.0735 - val_mae: 0.1958\n",
            "Epoch 77/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0294 - mae: 0.1284 - val_loss: 0.0240 - val_mae: 0.1183\n",
            "Epoch 78/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0259 - mae: 0.1209 - val_loss: 0.0190 - val_mae: 0.1055\n",
            "Epoch 79/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0272 - mae: 0.1236 - val_loss: 0.0208 - val_mae: 0.1135\n",
            "Epoch 80/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0265 - mae: 0.1252 - val_loss: 0.0241 - val_mae: 0.1235\n",
            "Epoch 81/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0246 - mae: 0.1160 - val_loss: 0.0299 - val_mae: 0.1227\n",
            "Epoch 82/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0268 - mae: 0.1232 - val_loss: 0.0315 - val_mae: 0.1385\n",
            "Epoch 83/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0260 - mae: 0.1209 - val_loss: 0.0185 - val_mae: 0.1036\n",
            "Epoch 84/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0253 - mae: 0.1198 - val_loss: 0.0150 - val_mae: 0.0923\n",
            "Epoch 85/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0244 - mae: 0.1180 - val_loss: 0.0333 - val_mae: 0.1375\n",
            "Epoch 86/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0247 - mae: 0.1160 - val_loss: 0.0204 - val_mae: 0.1057\n",
            "Epoch 87/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0244 - mae: 0.1162 - val_loss: 0.0228 - val_mae: 0.1134\n",
            "Epoch 88/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0242 - mae: 0.1179 - val_loss: 0.0199 - val_mae: 0.1014\n",
            "Epoch 89/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0247 - mae: 0.1174 - val_loss: 0.0200 - val_mae: 0.1024\n",
            "Epoch 90/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0225 - mae: 0.1153 - val_loss: 0.0202 - val_mae: 0.1089\n",
            "Epoch 91/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0240 - mae: 0.1154 - val_loss: 0.0226 - val_mae: 0.1145\n",
            "Epoch 92/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0225 - mae: 0.1154 - val_loss: 0.0153 - val_mae: 0.0943\n",
            "Epoch 93/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0224 - mae: 0.1160 - val_loss: 0.0191 - val_mae: 0.1041\n",
            "Epoch 94/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0232 - mae: 0.1169 - val_loss: 0.0265 - val_mae: 0.1168\n",
            "Epoch 95/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0230 - mae: 0.1181 - val_loss: 0.0165 - val_mae: 0.0983\n",
            "Epoch 96/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0224 - mae: 0.1157 - val_loss: 0.0212 - val_mae: 0.1075\n",
            "Epoch 97/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0221 - mae: 0.1109 - val_loss: 0.0354 - val_mae: 0.1488\n",
            "Epoch 98/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0222 - mae: 0.1116 - val_loss: 0.0237 - val_mae: 0.1172\n",
            "Epoch 99/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0235 - mae: 0.1153 - val_loss: 0.0206 - val_mae: 0.1137\n",
            "Epoch 100/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0224 - mae: 0.1142 - val_loss: 0.0367 - val_mae: 0.1431\n",
            "Epoch 101/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0221 - mae: 0.1137 - val_loss: 0.0281 - val_mae: 0.1267\n",
            "Epoch 102/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0215 - mae: 0.1115 - val_loss: 0.0490 - val_mae: 0.1657\n",
            "Epoch 103/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0219 - mae: 0.1144 - val_loss: 0.0365 - val_mae: 0.1500\n",
            "Epoch 104/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0227 - mae: 0.1141 - val_loss: 0.0212 - val_mae: 0.1124\n",
            "Epoch 105/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0219 - mae: 0.1135 - val_loss: 0.0157 - val_mae: 0.0985\n",
            "Epoch 106/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0217 - mae: 0.1137 - val_loss: 0.0169 - val_mae: 0.1046\n",
            "Epoch 107/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1117 - val_loss: 0.0256 - val_mae: 0.1167\n",
            "Epoch 108/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0209 - mae: 0.1105 - val_loss: 0.0214 - val_mae: 0.1119\n",
            "Epoch 109/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0208 - mae: 0.1111 - val_loss: 0.0222 - val_mae: 0.1109\n",
            "Epoch 110/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0214 - mae: 0.1131 - val_loss: 0.0233 - val_mae: 0.1165\n",
            "Epoch 111/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0221 - mae: 0.1135 - val_loss: 0.0200 - val_mae: 0.1118\n",
            "Epoch 112/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0209 - mae: 0.1095 - val_loss: 0.0178 - val_mae: 0.0988\n",
            "Epoch 113/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0204 - mae: 0.1127 - val_loss: 0.0264 - val_mae: 0.1229\n",
            "Epoch 114/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1115 - val_loss: 0.0181 - val_mae: 0.1030\n",
            "Epoch 115/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1093 - val_loss: 0.0148 - val_mae: 0.0928\n",
            "Epoch 116/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0211 - mae: 0.1090 - val_loss: 0.0163 - val_mae: 0.1031\n",
            "Epoch 117/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0209 - mae: 0.1107 - val_loss: 0.0147 - val_mae: 0.0946\n",
            "Epoch 118/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1125 - val_loss: 0.0156 - val_mae: 0.0962\n",
            "Epoch 119/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0206 - mae: 0.1091 - val_loss: 0.0155 - val_mae: 0.0994\n",
            "Epoch 120/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0202 - mae: 0.1091 - val_loss: 0.0149 - val_mae: 0.0953\n",
            "Epoch 121/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1115 - val_loss: 0.0171 - val_mae: 0.1024\n",
            "Epoch 122/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0212 - mae: 0.1113 - val_loss: 0.0215 - val_mae: 0.1139\n",
            "Epoch 123/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0206 - mae: 0.1119 - val_loss: 0.0212 - val_mae: 0.1144\n",
            "Epoch 124/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0209 - mae: 0.1121 - val_loss: 0.0267 - val_mae: 0.1296\n",
            "Epoch 125/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0205 - mae: 0.1100 - val_loss: 0.0185 - val_mae: 0.1067\n",
            "Epoch 126/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0206 - mae: 0.1112 - val_loss: 0.0246 - val_mae: 0.1229\n",
            "Epoch 127/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0205 - mae: 0.1101 - val_loss: 0.0263 - val_mae: 0.1258\n",
            "Epoch 128/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0204 - mae: 0.1101 - val_loss: 0.0171 - val_mae: 0.1021\n",
            "Epoch 129/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0199 - mae: 0.1088 - val_loss: 0.0178 - val_mae: 0.1027\n",
            "Epoch 130/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0210 - mae: 0.1120 - val_loss: 0.0148 - val_mae: 0.0929\n",
            "Epoch 131/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0211 - mae: 0.1117 - val_loss: 0.0220 - val_mae: 0.1107\n",
            "Epoch 132/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0210 - mae: 0.1113 - val_loss: 0.0446 - val_mae: 0.1566\n",
            "Epoch 133/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0192 - mae: 0.1080 - val_loss: 0.0165 - val_mae: 0.1012\n",
            "Epoch 134/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0198 - mae: 0.1116 - val_loss: 0.0244 - val_mae: 0.1206\n",
            "Epoch 135/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0202 - mae: 0.1097 - val_loss: 0.0314 - val_mae: 0.1441\n",
            "Epoch 136/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0195 - mae: 0.1089 - val_loss: 0.0188 - val_mae: 0.1084\n",
            "Epoch 137/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0211 - mae: 0.1125 - val_loss: 0.0201 - val_mae: 0.1112\n",
            "Epoch 138/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0203 - mae: 0.1093 - val_loss: 0.0154 - val_mae: 0.1007\n",
            "Epoch 139/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0207 - mae: 0.1097 - val_loss: 0.0240 - val_mae: 0.1190\n",
            "Epoch 140/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0196 - mae: 0.1089 - val_loss: 0.0282 - val_mae: 0.1315\n",
            "Epoch 141/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0193 - mae: 0.1078 - val_loss: 0.0224 - val_mae: 0.1129\n",
            "Epoch 142/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0196 - mae: 0.1092 - val_loss: 0.0205 - val_mae: 0.1097\n",
            "Epoch 143/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0193 - mae: 0.1064 - val_loss: 0.0209 - val_mae: 0.1126\n",
            "Epoch 144/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0200 - mae: 0.1094 - val_loss: 0.0194 - val_mae: 0.1122\n",
            "Epoch 145/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0191 - mae: 0.1080 - val_loss: 0.0228 - val_mae: 0.1175\n",
            "Epoch 146/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0200 - mae: 0.1100 - val_loss: 0.0175 - val_mae: 0.1052\n",
            "Epoch 147/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0197 - mae: 0.1073 - val_loss: 0.0147 - val_mae: 0.0948\n",
            "Epoch 148/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0196 - mae: 0.1069 - val_loss: 0.0196 - val_mae: 0.1091\n",
            "Epoch 149/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0195 - mae: 0.1089 - val_loss: 0.0316 - val_mae: 0.1442\n",
            "Epoch 150/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0187 - mae: 0.1065 - val_loss: 0.0177 - val_mae: 0.1060\n",
            "Epoch 151/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0202 - mae: 0.1097 - val_loss: 0.0157 - val_mae: 0.1015\n",
            "Epoch 152/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0191 - mae: 0.1086 - val_loss: 0.0188 - val_mae: 0.1091\n",
            "Epoch 153/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1043 - val_loss: 0.0213 - val_mae: 0.1078\n",
            "Epoch 154/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1295\n",
            "Epoch 155/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0195 - mae: 0.1076 - val_loss: 0.0300 - val_mae: 0.1376\n",
            "Epoch 156/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0189 - mae: 0.1050 - val_loss: 0.0139 - val_mae: 0.0908\n",
            "Epoch 157/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0206 - mae: 0.1103 - val_loss: 0.0168 - val_mae: 0.1053\n",
            "Epoch 158/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0186 - mae: 0.1073 - val_loss: 0.0208 - val_mae: 0.1094\n",
            "Epoch 159/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0192 - mae: 0.1082 - val_loss: 0.0221 - val_mae: 0.1148\n",
            "Epoch 160/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0185 - mae: 0.1061 - val_loss: 0.0192 - val_mae: 0.1066\n",
            "Epoch 161/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0194 - mae: 0.1083 - val_loss: 0.0390 - val_mae: 0.1506\n",
            "Epoch 162/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0195 - mae: 0.1068 - val_loss: 0.0138 - val_mae: 0.0917\n",
            "Epoch 163/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0179 - mae: 0.1041 - val_loss: 0.0407 - val_mae: 0.1589\n",
            "Epoch 164/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0184 - mae: 0.1067 - val_loss: 0.0150 - val_mae: 0.0957\n",
            "Epoch 165/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0192 - mae: 0.1074 - val_loss: 0.0152 - val_mae: 0.0951\n",
            "Epoch 166/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0189 - mae: 0.1063 - val_loss: 0.0133 - val_mae: 0.0917\n",
            "Epoch 167/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0181 - mae: 0.1034 - val_loss: 0.0151 - val_mae: 0.0968\n",
            "Epoch 168/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1066 - val_loss: 0.0218 - val_mae: 0.1114\n",
            "Epoch 169/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0185 - mae: 0.1035 - val_loss: 0.0172 - val_mae: 0.1018\n",
            "Epoch 170/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1054 - val_loss: 0.0171 - val_mae: 0.1063\n",
            "Epoch 171/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1034 - val_loss: 0.0280 - val_mae: 0.1309\n",
            "Epoch 172/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0187 - mae: 0.1058 - val_loss: 0.0220 - val_mae: 0.1194\n",
            "Epoch 173/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0188 - mae: 0.1060 - val_loss: 0.0163 - val_mae: 0.0975\n",
            "Epoch 174/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1049 - val_loss: 0.0184 - val_mae: 0.1021\n",
            "Epoch 175/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1056 - val_loss: 0.0151 - val_mae: 0.0942\n",
            "Epoch 176/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0196 - mae: 0.1065 - val_loss: 0.0133 - val_mae: 0.0884\n",
            "Epoch 177/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1067 - val_loss: 0.0193 - val_mae: 0.1128\n",
            "Epoch 178/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0184 - mae: 0.1040 - val_loss: 0.0165 - val_mae: 0.1028\n",
            "Epoch 179/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1042 - val_loss: 0.0197 - val_mae: 0.1100\n",
            "Epoch 180/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0187 - mae: 0.1051 - val_loss: 0.0193 - val_mae: 0.1096\n",
            "Epoch 181/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1066 - val_loss: 0.0159 - val_mae: 0.1019\n",
            "Epoch 182/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0197 - mae: 0.1084 - val_loss: 0.0138 - val_mae: 0.0912\n",
            "Epoch 183/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1051 - val_loss: 0.0185 - val_mae: 0.1097\n",
            "Epoch 184/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0189 - mae: 0.1074 - val_loss: 0.0266 - val_mae: 0.1288\n",
            "Epoch 185/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0186 - mae: 0.1069 - val_loss: 0.0205 - val_mae: 0.1134\n",
            "Epoch 186/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0185 - mae: 0.1080 - val_loss: 0.0214 - val_mae: 0.1159\n",
            "Epoch 187/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0189 - mae: 0.1074 - val_loss: 0.0341 - val_mae: 0.1447\n",
            "Epoch 188/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0189 - mae: 0.1058 - val_loss: 0.0194 - val_mae: 0.1079\n",
            "Epoch 189/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1055 - val_loss: 0.0174 - val_mae: 0.1030\n",
            "Epoch 190/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1041 - val_loss: 0.0250 - val_mae: 0.1224\n",
            "Epoch 191/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1050 - val_loss: 0.0148 - val_mae: 0.0935\n",
            "Epoch 192/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1033 - val_loss: 0.0177 - val_mae: 0.1031\n",
            "Epoch 193/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0192 - mae: 0.1079 - val_loss: 0.0233 - val_mae: 0.1162\n",
            "Epoch 194/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0183 - mae: 0.1053 - val_loss: 0.0137 - val_mae: 0.0894\n",
            "Epoch 195/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1048 - val_loss: 0.0156 - val_mae: 0.0993\n",
            "Epoch 196/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0188 - mae: 0.1070 - val_loss: 0.0153 - val_mae: 0.0960\n",
            "Epoch 197/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0182 - mae: 0.1051 - val_loss: 0.0165 - val_mae: 0.1003\n",
            "Epoch 198/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0191 - mae: 0.1073 - val_loss: 0.0211 - val_mae: 0.1113\n",
            "Epoch 199/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0197 - mae: 0.1076 - val_loss: 0.0124 - val_mae: 0.0864\n",
            "Epoch 200/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0181 - mae: 0.1031 - val_loss: 0.0163 - val_mae: 0.0976\n",
            "Epoch 201/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1041 - val_loss: 0.0169 - val_mae: 0.1055\n",
            "Epoch 202/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0192 - mae: 0.1066 - val_loss: 0.0252 - val_mae: 0.1280\n",
            "Epoch 203/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0179 - mae: 0.1047 - val_loss: 0.0209 - val_mae: 0.1097\n",
            "Epoch 204/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1040 - val_loss: 0.0178 - val_mae: 0.1040\n",
            "Epoch 205/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1036 - val_loss: 0.0172 - val_mae: 0.1022\n",
            "Epoch 206/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1041 - val_loss: 0.0178 - val_mae: 0.1031\n",
            "Epoch 207/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0187 - mae: 0.1077 - val_loss: 0.0179 - val_mae: 0.1020\n",
            "Epoch 208/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1023 - val_loss: 0.0208 - val_mae: 0.1147\n",
            "Epoch 209/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0184 - mae: 0.1045 - val_loss: 0.0191 - val_mae: 0.1116\n",
            "Epoch 210/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.0994 - val_loss: 0.0178 - val_mae: 0.1032\n",
            "Epoch 211/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1023 - val_loss: 0.0152 - val_mae: 0.0970\n",
            "Epoch 212/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0185 - mae: 0.1058 - val_loss: 0.0311 - val_mae: 0.1390\n",
            "Epoch 213/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0179 - mae: 0.1038 - val_loss: 0.0294 - val_mae: 0.1265\n",
            "Epoch 214/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1034 - val_loss: 0.0204 - val_mae: 0.1097\n",
            "Epoch 215/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1046 - val_loss: 0.0192 - val_mae: 0.1061\n",
            "Epoch 216/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1037 - val_loss: 0.0138 - val_mae: 0.0925\n",
            "Epoch 217/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0184 - mae: 0.1041 - val_loss: 0.0165 - val_mae: 0.1014\n",
            "Epoch 218/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1040 - val_loss: 0.0273 - val_mae: 0.1228\n",
            "Epoch 219/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1047 - val_loss: 0.0207 - val_mae: 0.1137\n",
            "Epoch 220/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1037 - val_loss: 0.0224 - val_mae: 0.1159\n",
            "Epoch 221/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1035 - val_loss: 0.0293 - val_mae: 0.1250\n",
            "Epoch 222/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0186 - mae: 0.1059 - val_loss: 0.0161 - val_mae: 0.1002\n",
            "Epoch 223/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1057 - val_loss: 0.0139 - val_mae: 0.0944\n",
            "Epoch 224/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1040 - val_loss: 0.0206 - val_mae: 0.1164\n",
            "Epoch 225/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0181 - mae: 0.1040 - val_loss: 0.0195 - val_mae: 0.1127\n",
            "Epoch 226/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1027 - val_loss: 0.0126 - val_mae: 0.0873\n",
            "Epoch 227/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1017 - val_loss: 0.0265 - val_mae: 0.1234\n",
            "Epoch 228/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1044 - val_loss: 0.0154 - val_mae: 0.0993\n",
            "Epoch 229/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1045 - val_loss: 0.0190 - val_mae: 0.1024\n",
            "Epoch 230/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1016 - val_loss: 0.0152 - val_mae: 0.0969\n",
            "Epoch 231/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0182 - mae: 0.1030 - val_loss: 0.0310 - val_mae: 0.1424\n",
            "Epoch 232/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0179 - mae: 0.1043 - val_loss: 0.0269 - val_mae: 0.1263\n",
            "Epoch 233/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1031 - val_loss: 0.0148 - val_mae: 0.0984\n",
            "Epoch 234/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0190 - mae: 0.1045 - val_loss: 0.0146 - val_mae: 0.0921\n",
            "Epoch 235/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0184 - mae: 0.1026 - val_loss: 0.0152 - val_mae: 0.0975\n",
            "Epoch 236/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0182 - mae: 0.1022 - val_loss: 0.0158 - val_mae: 0.0963\n",
            "Epoch 237/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1022 - val_loss: 0.0140 - val_mae: 0.0931\n",
            "Epoch 238/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1029 - val_loss: 0.0186 - val_mae: 0.1053\n",
            "Epoch 239/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1027 - val_loss: 0.0144 - val_mae: 0.0961\n",
            "Epoch 240/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1025 - val_loss: 0.0351 - val_mae: 0.1445\n",
            "Epoch 241/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0187 - mae: 0.1066 - val_loss: 0.0160 - val_mae: 0.0971\n",
            "Epoch 242/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1008 - val_loss: 0.0178 - val_mae: 0.1011\n",
            "Epoch 243/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0173 - mae: 0.1019 - val_loss: 0.0254 - val_mae: 0.1230\n",
            "Epoch 244/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1033 - val_loss: 0.0162 - val_mae: 0.0983\n",
            "Epoch 245/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1035 - val_loss: 0.0185 - val_mae: 0.1051\n",
            "Epoch 246/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1036 - val_loss: 0.0146 - val_mae: 0.0939\n",
            "Epoch 247/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1022 - val_loss: 0.0175 - val_mae: 0.1069\n",
            "Epoch 248/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0173 - mae: 0.1021 - val_loss: 0.0328 - val_mae: 0.1249\n",
            "Epoch 249/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1005 - val_loss: 0.0501 - val_mae: 0.1741\n",
            "Epoch 250/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1030 - val_loss: 0.0146 - val_mae: 0.0957\n",
            "Epoch 251/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1017 - val_loss: 0.0139 - val_mae: 0.0952\n",
            "Epoch 252/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1034 - val_loss: 0.0216 - val_mae: 0.1137\n",
            "Epoch 253/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1048 - val_loss: 0.0242 - val_mae: 0.1188\n",
            "Epoch 254/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1011 - val_loss: 0.0143 - val_mae: 0.0938\n",
            "Epoch 255/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1035 - val_loss: 0.0230 - val_mae: 0.1133\n",
            "Epoch 256/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1026 - val_loss: 0.0165 - val_mae: 0.0987\n",
            "Epoch 257/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1002 - val_loss: 0.0286 - val_mae: 0.1249\n",
            "Epoch 258/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1030 - val_loss: 0.0135 - val_mae: 0.0893\n",
            "Epoch 259/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1048 - val_loss: 0.0214 - val_mae: 0.1182\n",
            "Epoch 260/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0981 - val_loss: 0.0139 - val_mae: 0.0949\n",
            "Epoch 261/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0178 - mae: 0.1048 - val_loss: 0.0134 - val_mae: 0.0899\n",
            "Epoch 262/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1015 - val_loss: 0.0166 - val_mae: 0.0971\n",
            "Epoch 263/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1025 - val_loss: 0.0199 - val_mae: 0.1100\n",
            "Epoch 264/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1052 - val_loss: 0.0156 - val_mae: 0.1015\n",
            "Epoch 265/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1032 - val_loss: 0.0211 - val_mae: 0.1132\n",
            "Epoch 266/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1018 - val_loss: 0.0142 - val_mae: 0.0930\n",
            "Epoch 267/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1041 - val_loss: 0.0198 - val_mae: 0.1148\n",
            "Epoch 268/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0176 - mae: 0.1022 - val_loss: 0.0224 - val_mae: 0.1140\n",
            "Epoch 269/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0173 - mae: 0.1041 - val_loss: 0.0152 - val_mae: 0.0960\n",
            "Epoch 270/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1018 - val_loss: 0.0141 - val_mae: 0.0967\n",
            "Epoch 271/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1037 - val_loss: 0.0191 - val_mae: 0.1127\n",
            "Epoch 272/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0180 - mae: 0.1034 - val_loss: 0.0242 - val_mae: 0.1143\n",
            "Epoch 273/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1023 - val_loss: 0.0142 - val_mae: 0.0953\n",
            "Epoch 274/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1001 - val_loss: 0.0266 - val_mae: 0.1273\n",
            "Epoch 275/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1020 - val_loss: 0.0181 - val_mae: 0.1061\n",
            "Epoch 276/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1014 - val_loss: 0.0155 - val_mae: 0.0961\n",
            "Epoch 277/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0172 - mae: 0.1029 - val_loss: 0.0170 - val_mae: 0.1031\n",
            "Epoch 278/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1025 - val_loss: 0.0159 - val_mae: 0.1011\n",
            "Epoch 279/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1005 - val_loss: 0.0220 - val_mae: 0.1211\n",
            "Epoch 280/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0166 - mae: 0.1024 - val_loss: 0.0247 - val_mae: 0.1231\n",
            "Epoch 281/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1014 - val_loss: 0.0147 - val_mae: 0.0964\n",
            "Epoch 282/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1017 - val_loss: 0.0219 - val_mae: 0.1125\n",
            "Epoch 283/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0174 - mae: 0.1020 - val_loss: 0.0211 - val_mae: 0.1169\n",
            "Epoch 284/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1010 - val_loss: 0.0163 - val_mae: 0.1007\n",
            "Epoch 285/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1018 - val_loss: 0.0199 - val_mae: 0.1048\n",
            "Epoch 286/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1028 - val_loss: 0.0226 - val_mae: 0.1186\n",
            "Epoch 287/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1042 - val_loss: 0.0147 - val_mae: 0.0943\n",
            "Epoch 288/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0166 - mae: 0.1006 - val_loss: 0.0184 - val_mae: 0.1031\n",
            "Epoch 289/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.1006 - val_loss: 0.0139 - val_mae: 0.0930\n",
            "Epoch 290/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.0991 - val_loss: 0.0133 - val_mae: 0.0918\n",
            "Epoch 291/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1029 - val_loss: 0.0228 - val_mae: 0.1195\n",
            "Epoch 292/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0987 - val_loss: 0.0136 - val_mae: 0.0909\n",
            "Epoch 293/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.1011 - val_loss: 0.0127 - val_mae: 0.0889\n",
            "Epoch 294/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1013 - val_loss: 0.0185 - val_mae: 0.1095\n",
            "Epoch 295/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1022 - val_loss: 0.0157 - val_mae: 0.0982\n",
            "Epoch 296/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1008 - val_loss: 0.0236 - val_mae: 0.1138\n",
            "Epoch 297/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1009 - val_loss: 0.0158 - val_mae: 0.1020\n",
            "Epoch 298/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1001 - val_loss: 0.0153 - val_mae: 0.0987\n",
            "Epoch 299/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0167 - mae: 0.1005 - val_loss: 0.0132 - val_mae: 0.0902\n",
            "Epoch 300/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0994 - val_loss: 0.0191 - val_mae: 0.1081\n",
            "Epoch 301/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.0996 - val_loss: 0.0208 - val_mae: 0.1107\n",
            "Epoch 302/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0173 - mae: 0.1023 - val_loss: 0.0183 - val_mae: 0.1087\n",
            "Epoch 303/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1012 - val_loss: 0.0143 - val_mae: 0.0951\n",
            "Epoch 304/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0977 - val_loss: 0.0150 - val_mae: 0.0988\n",
            "Epoch 305/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0998 - val_loss: 0.0150 - val_mae: 0.0975\n",
            "Epoch 306/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.1009 - val_loss: 0.0341 - val_mae: 0.1418\n",
            "Epoch 307/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1013 - val_loss: 0.0160 - val_mae: 0.1011\n",
            "Epoch 308/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0981 - val_loss: 0.0239 - val_mae: 0.1240\n",
            "Epoch 309/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0987 - val_loss: 0.0229 - val_mae: 0.1190\n",
            "Epoch 310/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1019 - val_loss: 0.0201 - val_mae: 0.1072\n",
            "Epoch 311/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1014 - val_loss: 0.0142 - val_mae: 0.0941\n",
            "Epoch 312/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0997 - val_loss: 0.0230 - val_mae: 0.1184\n",
            "Epoch 313/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0177 - mae: 0.1025 - val_loss: 0.0154 - val_mae: 0.0979\n",
            "Epoch 314/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.1002 - val_loss: 0.0172 - val_mae: 0.1050\n",
            "Epoch 315/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1011 - val_loss: 0.0171 - val_mae: 0.1020\n",
            "Epoch 316/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.0991 - val_loss: 0.0159 - val_mae: 0.1013\n",
            "Epoch 317/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1009 - val_loss: 0.0135 - val_mae: 0.0920\n",
            "Epoch 318/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0156 - mae: 0.0974 - val_loss: 0.0156 - val_mae: 0.1009\n",
            "Epoch 319/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0990 - val_loss: 0.0245 - val_mae: 0.1229\n",
            "Epoch 320/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0171 - mae: 0.1006 - val_loss: 0.0164 - val_mae: 0.1037\n",
            "Epoch 321/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0166 - mae: 0.0992 - val_loss: 0.0150 - val_mae: 0.0981\n",
            "Epoch 322/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.1004 - val_loss: 0.0172 - val_mae: 0.1068\n",
            "Epoch 323/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0965 - val_loss: 0.0141 - val_mae: 0.0949\n",
            "Epoch 324/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1004 - val_loss: 0.0234 - val_mae: 0.1101\n",
            "Epoch 325/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0980 - val_loss: 0.0139 - val_mae: 0.0961\n",
            "Epoch 326/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.0992 - val_loss: 0.0198 - val_mae: 0.1126\n",
            "Epoch 327/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.1010 - val_loss: 0.0194 - val_mae: 0.1028\n",
            "Epoch 328/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1008 - val_loss: 0.0136 - val_mae: 0.0915\n",
            "Epoch 329/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0997 - val_loss: 0.0216 - val_mae: 0.1216\n",
            "Epoch 330/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0977 - val_loss: 0.0144 - val_mae: 0.0973\n",
            "Epoch 331/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0988 - val_loss: 0.0191 - val_mae: 0.1106\n",
            "Epoch 332/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1013 - val_loss: 0.0202 - val_mae: 0.1149\n",
            "Epoch 333/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.0979 - val_loss: 0.0202 - val_mae: 0.1164\n",
            "Epoch 334/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0172 - mae: 0.1028 - val_loss: 0.0184 - val_mae: 0.1111\n",
            "Epoch 335/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0169 - mae: 0.1009 - val_loss: 0.0245 - val_mae: 0.1226\n",
            "Epoch 336/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.0989 - val_loss: 0.0162 - val_mae: 0.0965\n",
            "Epoch 337/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1022 - val_loss: 0.0299 - val_mae: 0.1256\n",
            "Epoch 338/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0994 - val_loss: 0.0167 - val_mae: 0.0987\n",
            "Epoch 339/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.1001 - val_loss: 0.0160 - val_mae: 0.1036\n",
            "Epoch 340/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0982 - val_loss: 0.0257 - val_mae: 0.1268\n",
            "Epoch 341/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1011 - val_loss: 0.0148 - val_mae: 0.0996\n",
            "Epoch 342/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1014 - val_loss: 0.0230 - val_mae: 0.1210\n",
            "Epoch 343/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0979 - val_loss: 0.0277 - val_mae: 0.1244\n",
            "Epoch 344/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.1002 - val_loss: 0.0157 - val_mae: 0.1000\n",
            "Epoch 345/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0175 - mae: 0.1006 - val_loss: 0.0154 - val_mae: 0.0971\n",
            "Epoch 346/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0990 - val_loss: 0.0152 - val_mae: 0.1008\n",
            "Epoch 347/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0983 - val_loss: 0.0127 - val_mae: 0.0874\n",
            "Epoch 348/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0162 - mae: 0.1003 - val_loss: 0.0132 - val_mae: 0.0909\n",
            "Epoch 349/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0992 - val_loss: 0.0208 - val_mae: 0.1119\n",
            "Epoch 350/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0982 - val_loss: 0.0148 - val_mae: 0.0960\n",
            "Epoch 351/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.1001 - val_loss: 0.0218 - val_mae: 0.1200\n",
            "Epoch 352/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1004 - val_loss: 0.0132 - val_mae: 0.0910\n",
            "Epoch 353/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.1017 - val_loss: 0.0322 - val_mae: 0.1416\n",
            "Epoch 354/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1000 - val_loss: 0.0128 - val_mae: 0.0893\n",
            "Epoch 355/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0993 - val_loss: 0.0155 - val_mae: 0.1009\n",
            "Epoch 356/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0981 - val_loss: 0.0179 - val_mae: 0.1039\n",
            "Epoch 357/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1001 - val_loss: 0.0134 - val_mae: 0.0919\n",
            "Epoch 358/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0165 - mae: 0.1021 - val_loss: 0.0205 - val_mae: 0.1108\n",
            "Epoch 359/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0957 - val_loss: 0.0187 - val_mae: 0.1048\n",
            "Epoch 360/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1014 - val_loss: 0.0149 - val_mae: 0.0959\n",
            "Epoch 361/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0156 - mae: 0.0984 - val_loss: 0.0169 - val_mae: 0.1041\n",
            "Epoch 362/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0992 - val_loss: 0.0158 - val_mae: 0.0973\n",
            "Epoch 363/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0979 - val_loss: 0.0208 - val_mae: 0.1118\n",
            "Epoch 364/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0981 - val_loss: 0.0255 - val_mae: 0.1252\n",
            "Epoch 365/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.0983 - val_loss: 0.0156 - val_mae: 0.0967\n",
            "Epoch 366/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0156 - mae: 0.0984 - val_loss: 0.0163 - val_mae: 0.1018\n",
            "Epoch 367/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0170 - mae: 0.1010 - val_loss: 0.0200 - val_mae: 0.1085\n",
            "Epoch 368/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0985 - val_loss: 0.0184 - val_mae: 0.1047\n",
            "Epoch 369/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0156 - mae: 0.0959 - val_loss: 0.0118 - val_mae: 0.0848\n",
            "Epoch 370/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.0986 - val_loss: 0.0185 - val_mae: 0.1068\n",
            "Epoch 371/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0983 - val_loss: 0.0164 - val_mae: 0.1000\n",
            "Epoch 372/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.1006 - val_loss: 0.0158 - val_mae: 0.1005\n",
            "Epoch 373/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0168 - mae: 0.1009 - val_loss: 0.0159 - val_mae: 0.1014\n",
            "Epoch 374/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0985 - val_loss: 0.0179 - val_mae: 0.1028\n",
            "Epoch 375/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0983 - val_loss: 0.0135 - val_mae: 0.0883\n",
            "Epoch 376/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0153 - mae: 0.0983 - val_loss: 0.0182 - val_mae: 0.1095\n",
            "Epoch 377/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1013 - val_loss: 0.0163 - val_mae: 0.1065\n",
            "Epoch 378/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.0980 - val_loss: 0.0124 - val_mae: 0.0856\n",
            "Epoch 379/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0161 - mae: 0.1009 - val_loss: 0.0153 - val_mae: 0.0971\n",
            "Epoch 380/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.0985 - val_loss: 0.0141 - val_mae: 0.0952\n",
            "Epoch 381/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1002 - val_loss: 0.0133 - val_mae: 0.0906\n",
            "Epoch 382/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.1003 - val_loss: 0.0164 - val_mae: 0.0984\n",
            "Epoch 383/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0985 - val_loss: 0.0126 - val_mae: 0.0868\n",
            "Epoch 384/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0981 - val_loss: 0.0119 - val_mae: 0.0851\n",
            "Epoch 385/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0992 - val_loss: 0.0169 - val_mae: 0.1034\n",
            "Epoch 386/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0974 - val_loss: 0.0125 - val_mae: 0.0851\n",
            "Epoch 387/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0975 - val_loss: 0.0196 - val_mae: 0.1121\n",
            "Epoch 388/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0963 - val_loss: 0.0149 - val_mae: 0.0977\n",
            "Epoch 389/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0163 - mae: 0.0996 - val_loss: 0.0170 - val_mae: 0.1041\n",
            "Epoch 390/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0164 - mae: 0.0990 - val_loss: 0.0147 - val_mae: 0.0979\n",
            "Epoch 391/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0980 - val_loss: 0.0139 - val_mae: 0.0937\n",
            "Epoch 392/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0978 - val_loss: 0.0130 - val_mae: 0.0899\n",
            "Epoch 393/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0966 - val_loss: 0.0146 - val_mae: 0.0939\n",
            "Epoch 394/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0974 - val_loss: 0.0206 - val_mae: 0.1077\n",
            "Epoch 395/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0989 - val_loss: 0.0185 - val_mae: 0.1054\n",
            "Epoch 396/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0997 - val_loss: 0.0344 - val_mae: 0.1430\n",
            "Epoch 397/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0979 - val_loss: 0.0155 - val_mae: 0.0975\n",
            "Epoch 398/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0985 - val_loss: 0.0237 - val_mae: 0.1166\n",
            "Epoch 399/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0984 - val_loss: 0.0145 - val_mae: 0.0957\n",
            "Epoch 400/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0988 - val_loss: 0.0143 - val_mae: 0.0930\n",
            "Epoch 401/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0993 - val_loss: 0.0138 - val_mae: 0.0943\n",
            "Epoch 402/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0969 - val_loss: 0.0120 - val_mae: 0.0847\n",
            "Epoch 403/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0156 - mae: 0.0984 - val_loss: 0.0133 - val_mae: 0.0904\n",
            "Epoch 404/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0968 - val_loss: 0.0168 - val_mae: 0.1033\n",
            "Epoch 405/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0969 - val_loss: 0.0288 - val_mae: 0.1349\n",
            "Epoch 406/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0160 - mae: 0.0981 - val_loss: 0.0147 - val_mae: 0.0987\n",
            "Epoch 407/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0154 - mae: 0.0976 - val_loss: 0.0159 - val_mae: 0.1032\n",
            "Epoch 408/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0988 - val_loss: 0.0136 - val_mae: 0.0897\n",
            "Epoch 409/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0156 - mae: 0.0981 - val_loss: 0.0132 - val_mae: 0.0886\n",
            "Epoch 410/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0976 - val_loss: 0.0140 - val_mae: 0.0926\n",
            "Epoch 411/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0986 - val_loss: 0.0144 - val_mae: 0.0975\n",
            "Epoch 412/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0972 - val_loss: 0.0119 - val_mae: 0.0843\n",
            "Epoch 413/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0143 - val_mae: 0.0967\n",
            "Epoch 414/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.1000 - val_loss: 0.0148 - val_mae: 0.0987\n",
            "Epoch 415/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0157 - mae: 0.0978 - val_loss: 0.0245 - val_mae: 0.1157\n",
            "Epoch 416/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0973 - val_loss: 0.0179 - val_mae: 0.1045\n",
            "Epoch 417/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0965 - val_loss: 0.0150 - val_mae: 0.0964\n",
            "Epoch 418/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0968 - val_loss: 0.0190 - val_mae: 0.1025\n",
            "Epoch 419/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0967 - val_loss: 0.0141 - val_mae: 0.0934\n",
            "Epoch 420/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0987 - val_loss: 0.0141 - val_mae: 0.0950\n",
            "Epoch 421/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.1004 - val_loss: 0.0217 - val_mae: 0.1117\n",
            "Epoch 422/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0975 - val_loss: 0.0141 - val_mae: 0.0951\n",
            "Epoch 423/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0953 - val_loss: 0.0137 - val_mae: 0.0910\n",
            "Epoch 424/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0155 - mae: 0.0975 - val_loss: 0.0133 - val_mae: 0.0900\n",
            "Epoch 425/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0964 - val_loss: 0.0153 - val_mae: 0.0991\n",
            "Epoch 426/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0975 - val_loss: 0.0151 - val_mae: 0.0953\n",
            "Epoch 427/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0949 - val_loss: 0.0131 - val_mae: 0.0904\n",
            "Epoch 428/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0977 - val_loss: 0.0128 - val_mae: 0.0891\n",
            "Epoch 429/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0972 - val_loss: 0.0241 - val_mae: 0.1179\n",
            "Epoch 430/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0954 - val_loss: 0.0131 - val_mae: 0.0903\n",
            "Epoch 431/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0965 - val_loss: 0.0131 - val_mae: 0.0891\n",
            "Epoch 432/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0959 - val_loss: 0.0131 - val_mae: 0.0890\n",
            "Epoch 433/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0968 - val_loss: 0.0187 - val_mae: 0.1075\n",
            "Epoch 434/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0951 - val_loss: 0.0133 - val_mae: 0.0907\n",
            "Epoch 435/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0950 - val_loss: 0.0216 - val_mae: 0.1203\n",
            "Epoch 436/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0964 - val_loss: 0.0199 - val_mae: 0.1095\n",
            "Epoch 437/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0958 - val_loss: 0.0163 - val_mae: 0.1000\n",
            "Epoch 438/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0962 - val_loss: 0.0157 - val_mae: 0.0995\n",
            "Epoch 439/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0988 - val_loss: 0.0131 - val_mae: 0.0901\n",
            "Epoch 440/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0974 - val_loss: 0.0132 - val_mae: 0.0917\n",
            "Epoch 441/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0140 - mae: 0.0924 - val_loss: 0.0190 - val_mae: 0.1118\n",
            "Epoch 442/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0962 - val_loss: 0.0154 - val_mae: 0.0982\n",
            "Epoch 443/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0966 - val_loss: 0.0158 - val_mae: 0.1025\n",
            "Epoch 444/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0948 - val_loss: 0.0157 - val_mae: 0.0997\n",
            "Epoch 445/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0983 - val_loss: 0.0127 - val_mae: 0.0869\n",
            "Epoch 446/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0939 - val_loss: 0.0174 - val_mae: 0.1058\n",
            "Epoch 447/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0965 - val_loss: 0.0282 - val_mae: 0.1335\n",
            "Epoch 448/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0937 - val_loss: 0.0275 - val_mae: 0.1237\n",
            "Epoch 449/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0145 - mae: 0.0953 - val_loss: 0.0145 - val_mae: 0.0960\n",
            "Epoch 450/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0159 - mae: 0.0998 - val_loss: 0.0138 - val_mae: 0.0924\n",
            "Epoch 451/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0936 - val_loss: 0.0160 - val_mae: 0.1024\n",
            "Epoch 452/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0987 - val_loss: 0.0148 - val_mae: 0.0966\n",
            "Epoch 453/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0954 - val_loss: 0.0148 - val_mae: 0.0947\n",
            "Epoch 454/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0968 - val_loss: 0.0143 - val_mae: 0.0936\n",
            "Epoch 455/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0978 - val_loss: 0.0161 - val_mae: 0.0988\n",
            "Epoch 456/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0142 - mae: 0.0949 - val_loss: 0.0247 - val_mae: 0.1240\n",
            "Epoch 457/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0955 - val_loss: 0.0156 - val_mae: 0.0957\n",
            "Epoch 458/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0979 - val_loss: 0.0129 - val_mae: 0.0875\n",
            "Epoch 459/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0957 - val_loss: 0.0186 - val_mae: 0.1022\n",
            "Epoch 460/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0940 - val_loss: 0.0156 - val_mae: 0.0993\n",
            "Epoch 461/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0988 - val_loss: 0.0143 - val_mae: 0.0953\n",
            "Epoch 462/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0973 - val_loss: 0.0135 - val_mae: 0.0928\n",
            "Epoch 463/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0985 - val_loss: 0.0155 - val_mae: 0.0968\n",
            "Epoch 464/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0964 - val_loss: 0.0152 - val_mae: 0.0963\n",
            "Epoch 465/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0956 - val_loss: 0.0122 - val_mae: 0.0846\n",
            "Epoch 466/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0939 - val_loss: 0.0139 - val_mae: 0.0958\n",
            "Epoch 467/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0975 - val_loss: 0.0137 - val_mae: 0.0913\n",
            "Epoch 468/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0158 - mae: 0.0964 - val_loss: 0.0159 - val_mae: 0.1026\n",
            "Epoch 469/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0971 - val_loss: 0.0183 - val_mae: 0.1088\n",
            "Epoch 470/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0939 - val_loss: 0.0151 - val_mae: 0.0938\n",
            "Epoch 471/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0954 - val_loss: 0.0160 - val_mae: 0.1011\n",
            "Epoch 472/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0143 - mae: 0.0933 - val_loss: 0.0198 - val_mae: 0.1073\n",
            "Epoch 473/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0981 - val_loss: 0.0185 - val_mae: 0.1052\n",
            "Epoch 474/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0983 - val_loss: 0.0133 - val_mae: 0.0921\n",
            "Epoch 475/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0961 - val_loss: 0.0207 - val_mae: 0.1125\n",
            "Epoch 476/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0940 - val_loss: 0.0153 - val_mae: 0.0962\n",
            "Epoch 477/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0959 - val_loss: 0.0197 - val_mae: 0.1130\n",
            "Epoch 478/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0967 - val_loss: 0.0163 - val_mae: 0.0966\n",
            "Epoch 479/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0143 - mae: 0.0925 - val_loss: 0.0145 - val_mae: 0.0939\n",
            "Epoch 480/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0159 - mae: 0.0982 - val_loss: 0.0142 - val_mae: 0.0946\n",
            "Epoch 481/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0968 - val_loss: 0.0154 - val_mae: 0.0971\n",
            "Epoch 482/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0949 - val_loss: 0.0121 - val_mae: 0.0863\n",
            "Epoch 483/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0978 - val_loss: 0.0242 - val_mae: 0.1166\n",
            "Epoch 484/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0152 - mae: 0.0963 - val_loss: 0.0170 - val_mae: 0.1055\n",
            "Epoch 485/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0957 - val_loss: 0.0192 - val_mae: 0.1119\n",
            "Epoch 486/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0976 - val_loss: 0.0136 - val_mae: 0.0907\n",
            "Epoch 487/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0968 - val_loss: 0.0139 - val_mae: 0.0906\n",
            "Epoch 488/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0954 - val_loss: 0.0194 - val_mae: 0.1053\n",
            "Epoch 489/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0147 - mae: 0.0957 - val_loss: 0.0158 - val_mae: 0.1021\n",
            "Epoch 490/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0942 - val_loss: 0.0141 - val_mae: 0.0943\n",
            "Epoch 491/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0963 - val_loss: 0.0181 - val_mae: 0.1052\n",
            "Epoch 492/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0949 - val_loss: 0.0154 - val_mae: 0.0995\n",
            "Epoch 493/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0951 - val_loss: 0.0131 - val_mae: 0.0891\n",
            "Epoch 494/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0981 - val_loss: 0.0146 - val_mae: 0.0977\n",
            "Epoch 495/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0936 - val_loss: 0.0139 - val_mae: 0.0929\n",
            "Epoch 496/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0155 - mae: 0.0994 - val_loss: 0.0290 - val_mae: 0.1337\n",
            "Epoch 497/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0934 - val_loss: 0.0196 - val_mae: 0.1054\n",
            "Epoch 498/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0157 - mae: 0.0989 - val_loss: 0.0195 - val_mae: 0.1089\n",
            "Epoch 499/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0971 - val_loss: 0.0191 - val_mae: 0.1081\n",
            "Epoch 500/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0964 - val_loss: 0.0126 - val_mae: 0.0886\n",
            "Epoch 501/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0915 - val_loss: 0.0129 - val_mae: 0.0890\n",
            "Epoch 502/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0966 - val_loss: 0.0213 - val_mae: 0.1195\n",
            "Epoch 503/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0975 - val_loss: 0.0186 - val_mae: 0.1062\n",
            "Epoch 504/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0969 - val_loss: 0.0224 - val_mae: 0.1170\n",
            "Epoch 505/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0145 - mae: 0.0963 - val_loss: 0.0140 - val_mae: 0.0930\n",
            "Epoch 506/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0945 - val_loss: 0.0130 - val_mae: 0.0903\n",
            "Epoch 507/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0948 - val_loss: 0.0220 - val_mae: 0.1111\n",
            "Epoch 508/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0153 - mae: 0.0972 - val_loss: 0.0147 - val_mae: 0.0980\n",
            "Epoch 509/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0949 - val_loss: 0.0134 - val_mae: 0.0903\n",
            "Epoch 510/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0960 - val_loss: 0.0156 - val_mae: 0.0999\n",
            "Epoch 511/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0979 - val_loss: 0.0136 - val_mae: 0.0922\n",
            "Epoch 512/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0957 - val_loss: 0.0214 - val_mae: 0.1162\n",
            "Epoch 513/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0977 - val_loss: 0.0131 - val_mae: 0.0904\n",
            "Epoch 514/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0952 - val_loss: 0.0130 - val_mae: 0.0882\n",
            "Epoch 515/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0960 - val_loss: 0.0163 - val_mae: 0.0993\n",
            "Epoch 516/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0962 - val_loss: 0.0144 - val_mae: 0.0950\n",
            "Epoch 517/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0938 - val_loss: 0.0137 - val_mae: 0.0919\n",
            "Epoch 518/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0965 - val_loss: 0.0170 - val_mae: 0.0979\n",
            "Epoch 519/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0941 - val_loss: 0.0158 - val_mae: 0.0971\n",
            "Epoch 520/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0148 - mae: 0.0962 - val_loss: 0.0216 - val_mae: 0.1195\n",
            "Epoch 521/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0153 - mae: 0.0955 - val_loss: 0.0181 - val_mae: 0.1110\n",
            "Epoch 522/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0972 - val_loss: 0.0127 - val_mae: 0.0869\n",
            "Epoch 523/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0154 - mae: 0.0967 - val_loss: 0.0171 - val_mae: 0.1054\n",
            "Epoch 524/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0947 - val_loss: 0.0129 - val_mae: 0.0882\n",
            "Epoch 525/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0949 - val_loss: 0.0224 - val_mae: 0.1170\n",
            "Epoch 526/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0155 - mae: 0.0983 - val_loss: 0.0148 - val_mae: 0.0969\n",
            "Epoch 527/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0975 - val_loss: 0.0146 - val_mae: 0.0945\n",
            "Epoch 528/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0939 - val_loss: 0.0152 - val_mae: 0.0968\n",
            "Epoch 529/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0975 - val_loss: 0.0192 - val_mae: 0.1109\n",
            "Epoch 530/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0977 - val_loss: 0.0149 - val_mae: 0.0990\n",
            "Epoch 531/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0949 - val_loss: 0.0125 - val_mae: 0.0868\n",
            "Epoch 532/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0148 - mae: 0.0963 - val_loss: 0.0121 - val_mae: 0.0843\n",
            "Epoch 533/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0951 - val_loss: 0.0152 - val_mae: 0.0984\n",
            "Epoch 534/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0143 - mae: 0.0936 - val_loss: 0.0251 - val_mae: 0.1177\n",
            "Epoch 535/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0980 - val_loss: 0.0165 - val_mae: 0.0999\n",
            "Epoch 536/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0155 - mae: 0.0961 - val_loss: 0.0219 - val_mae: 0.1101\n",
            "Epoch 537/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0966 - val_loss: 0.0131 - val_mae: 0.0906\n",
            "Epoch 538/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0152 - mae: 0.0974 - val_loss: 0.0141 - val_mae: 0.0940\n",
            "Epoch 539/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0960 - val_loss: 0.0237 - val_mae: 0.1236\n",
            "Epoch 540/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0145 - mae: 0.0939 - val_loss: 0.0156 - val_mae: 0.1011\n",
            "Epoch 541/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0965 - val_loss: 0.0169 - val_mae: 0.0998\n",
            "Epoch 542/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0154 - mae: 0.0983 - val_loss: 0.0143 - val_mae: 0.0963\n",
            "Epoch 543/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0148 - mae: 0.0962 - val_loss: 0.0163 - val_mae: 0.1041\n",
            "Epoch 544/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0982 - val_loss: 0.0195 - val_mae: 0.1073\n",
            "Epoch 545/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0968 - val_loss: 0.0160 - val_mae: 0.1007\n",
            "Epoch 546/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0943 - val_loss: 0.0138 - val_mae: 0.0921\n",
            "Epoch 547/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0948 - val_loss: 0.0194 - val_mae: 0.1081\n",
            "Epoch 548/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0975 - val_loss: 0.0167 - val_mae: 0.1044\n",
            "Epoch 549/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0140 - mae: 0.0938 - val_loss: 0.0163 - val_mae: 0.0964\n",
            "Epoch 550/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0964 - val_loss: 0.0139 - val_mae: 0.0935\n",
            "Epoch 551/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0139 - mae: 0.0930 - val_loss: 0.0148 - val_mae: 0.0972\n",
            "Epoch 552/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0151 - mae: 0.0983 - val_loss: 0.0133 - val_mae: 0.0903\n",
            "Epoch 553/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0958 - val_loss: 0.0138 - val_mae: 0.0923\n",
            "Epoch 554/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0962 - val_loss: 0.0159 - val_mae: 0.1006\n",
            "Epoch 555/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0151 - mae: 0.0971 - val_loss: 0.0135 - val_mae: 0.0916\n",
            "Epoch 556/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0966 - val_loss: 0.0186 - val_mae: 0.1065\n",
            "Epoch 557/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0942 - val_loss: 0.0173 - val_mae: 0.1016\n",
            "Epoch 558/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0968 - val_loss: 0.0129 - val_mae: 0.0881\n",
            "Epoch 559/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0955 - val_loss: 0.0133 - val_mae: 0.0912\n",
            "Epoch 560/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0931 - val_loss: 0.0212 - val_mae: 0.1123\n",
            "Epoch 561/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0966 - val_loss: 0.0243 - val_mae: 0.1257\n",
            "Epoch 562/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0146 - mae: 0.0954 - val_loss: 0.0124 - val_mae: 0.0868\n",
            "Epoch 563/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0974 - val_loss: 0.0180 - val_mae: 0.1046\n",
            "Epoch 564/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0145 - mae: 0.0958 - val_loss: 0.0156 - val_mae: 0.0977\n",
            "Epoch 565/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0965 - val_loss: 0.0163 - val_mae: 0.1024\n",
            "Epoch 566/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0955 - val_loss: 0.0161 - val_mae: 0.0984\n",
            "Epoch 567/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0147 - mae: 0.0940 - val_loss: 0.0136 - val_mae: 0.0912\n",
            "Epoch 568/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0948 - val_loss: 0.0177 - val_mae: 0.1056\n",
            "Epoch 569/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0142 - mae: 0.0941 - val_loss: 0.0140 - val_mae: 0.0946\n",
            "Epoch 570/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0150 - mae: 0.0976 - val_loss: 0.0127 - val_mae: 0.0866\n",
            "Epoch 571/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0153 - mae: 0.0987 - val_loss: 0.0173 - val_mae: 0.1016\n",
            "Epoch 572/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0142 - mae: 0.0945 - val_loss: 0.0211 - val_mae: 0.1111\n",
            "Epoch 573/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0952 - val_loss: 0.0163 - val_mae: 0.1035\n",
            "Epoch 574/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0963 - val_loss: 0.0172 - val_mae: 0.1047\n",
            "Epoch 575/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0140 - mae: 0.0937 - val_loss: 0.0174 - val_mae: 0.1006\n",
            "Epoch 576/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0154 - mae: 0.0959 - val_loss: 0.0171 - val_mae: 0.1039\n",
            "Epoch 577/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0936 - val_loss: 0.0144 - val_mae: 0.0938\n",
            "Epoch 578/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0151 - mae: 0.0948 - val_loss: 0.0143 - val_mae: 0.0947\n",
            "Epoch 579/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0143 - mae: 0.0939 - val_loss: 0.0186 - val_mae: 0.1054\n",
            "Epoch 580/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0148 - mae: 0.0967 - val_loss: 0.0143 - val_mae: 0.0951\n",
            "Epoch 581/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0139 - mae: 0.0942 - val_loss: 0.0161 - val_mae: 0.1031\n",
            "Epoch 582/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0936 - val_loss: 0.0138 - val_mae: 0.0913\n",
            "Epoch 583/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0145 - mae: 0.0942 - val_loss: 0.0128 - val_mae: 0.0877\n",
            "Epoch 584/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0927 - val_loss: 0.0129 - val_mae: 0.0883\n",
            "Epoch 585/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0947 - val_loss: 0.0192 - val_mae: 0.1141\n",
            "Epoch 586/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0152 - mae: 0.0966 - val_loss: 0.0135 - val_mae: 0.0914\n",
            "Epoch 587/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0149 - mae: 0.0970 - val_loss: 0.0160 - val_mae: 0.1008\n",
            "Epoch 588/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0140 - mae: 0.0931 - val_loss: 0.0178 - val_mae: 0.1049\n",
            "Epoch 589/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0150 - mae: 0.0969 - val_loss: 0.0217 - val_mae: 0.1079\n",
            "Epoch 590/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0967 - val_loss: 0.0143 - val_mae: 0.0942\n",
            "Epoch 591/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0153 - mae: 0.0976 - val_loss: 0.0172 - val_mae: 0.1043\n",
            "Epoch 592/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0944 - val_loss: 0.0186 - val_mae: 0.1088\n",
            "Epoch 593/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0141 - mae: 0.0953 - val_loss: 0.0189 - val_mae: 0.1142\n",
            "Epoch 594/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0144 - mae: 0.0951 - val_loss: 0.0128 - val_mae: 0.0890\n",
            "Epoch 595/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0144 - mae: 0.0952 - val_loss: 0.0166 - val_mae: 0.0988\n",
            "Epoch 596/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0149 - mae: 0.0954 - val_loss: 0.0142 - val_mae: 0.0945\n",
            "Epoch 597/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0956 - val_loss: 0.0152 - val_mae: 0.0958\n",
            "Epoch 598/600\n",
            "600/600 [==============================] - 1s 1ms/sample - loss: 0.0143 - mae: 0.0958 - val_loss: 0.0134 - val_mae: 0.0901\n",
            "Epoch 599/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0142 - mae: 0.0940 - val_loss: 0.0212 - val_mae: 0.1192\n",
            "Epoch 600/600\n",
            "600/600 [==============================] - 1s 2ms/sample - loss: 0.0146 - mae: 0.0945 - val_loss: 0.0169 - val_mae: 0.1024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UvoWo9L-f3ak",
        "outputId": "5bc572f6-cb3d-4aba-cc65-01c90a9e8993"
      },
      "source": [
        "#Toy Problem Y=sin(x) 1000 samples of period -2pi to 2pi with batch size of 256\n",
        "!pip install tensorflow==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "SAMPLES = 1000\n",
        "SEED = 1400\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "x_values = np.random.uniform(low=-(2*math.pi), high=2*math.pi,size=SAMPLES)\n",
        "np.random.shuffle(x_values)\n",
        "y_values = np.sin(x_values)\n",
        "plt.plot(x_values,y_values, 'b.')\n",
        "plt.show()\n",
        "y_values += 0.1*np.random.randn(*y_values.shape)\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "#plt.show()\n",
        "TRAIN_SPLIT = int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "assert (x_train.size + x_validate.size + x_test.size) == SAMPLES\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model_1 = tf.keras.Sequential()\n",
        "model_1.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "model_1.add(layers.Dense(16, activation='relu'))\n",
        "model_1.add(layers.Dense(1))\n",
        "model_1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "model_1.summary()\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=600, batch_size=256, validation_data=(x_validate, y_validate))\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g.', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "SKIP = 200\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "predictions = model_1.predict(x_train)\n",
        "plt.clf()\n",
        "plt.title('training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta0 in /usr/local/lib/python3.7/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (3.17.3)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.41.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (0.37.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.7.4.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_63 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 600 samples, validate on 200 samples\n",
            "Epoch 1/600\n",
            "600/600 [==============================] - 0s 304us/sample - loss: 5.3057 - mae: 1.7068 - val_loss: 4.2714 - val_mae: 1.5084\n",
            "Epoch 2/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 4.2486 - mae: 1.5176 - val_loss: 3.6644 - val_mae: 1.3873\n",
            "Epoch 3/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 3.6690 - mae: 1.4003 - val_loss: 3.2390 - val_mae: 1.2955\n",
            "Epoch 4/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 3.2534 - mae: 1.3089 - val_loss: 2.9080 - val_mae: 1.2222\n",
            "Epoch 5/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 2.9241 - mae: 1.2349 - val_loss: 2.6259 - val_mae: 1.1596\n",
            "Epoch 6/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 2.6417 - mae: 1.1720 - val_loss: 2.3716 - val_mae: 1.1030\n",
            "Epoch 7/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 2.3968 - mae: 1.1176 - val_loss: 2.1890 - val_mae: 1.0613\n",
            "Epoch 8/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 2.2120 - mae: 1.0757 - val_loss: 2.0124 - val_mae: 1.0200\n",
            "Epoch 9/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 2.0369 - mae: 1.0368 - val_loss: 1.8559 - val_mae: 0.9855\n",
            "Epoch 10/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 1.8795 - mae: 1.0040 - val_loss: 1.7076 - val_mae: 0.9518\n",
            "Epoch 11/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 1.7343 - mae: 0.9729 - val_loss: 1.5854 - val_mae: 0.9228\n",
            "Epoch 12/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 1.6113 - mae: 0.9446 - val_loss: 1.4747 - val_mae: 0.8962\n",
            "Epoch 13/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 1.4970 - mae: 0.9181 - val_loss: 1.3619 - val_mae: 0.8701\n",
            "Epoch 14/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 1.3866 - mae: 0.8933 - val_loss: 1.2654 - val_mae: 0.8463\n",
            "Epoch 15/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 1.2886 - mae: 0.8695 - val_loss: 1.1711 - val_mae: 0.8225\n",
            "Epoch 16/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 1.1968 - mae: 0.8483 - val_loss: 1.0900 - val_mae: 0.8020\n",
            "Epoch 17/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 1.1160 - mae: 0.8282 - val_loss: 1.0170 - val_mae: 0.7831\n",
            "Epoch 18/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 1.0425 - mae: 0.8080 - val_loss: 0.9503 - val_mae: 0.7651\n",
            "Epoch 19/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.9762 - mae: 0.7908 - val_loss: 0.8890 - val_mae: 0.7476\n",
            "Epoch 20/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.9135 - mae: 0.7730 - val_loss: 0.8282 - val_mae: 0.7299\n",
            "Epoch 21/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.8517 - mae: 0.7542 - val_loss: 0.7792 - val_mae: 0.7149\n",
            "Epoch 22/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.8001 - mae: 0.7378 - val_loss: 0.7298 - val_mae: 0.6996\n",
            "Epoch 23/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.7540 - mae: 0.7242 - val_loss: 0.6875 - val_mae: 0.6853\n",
            "Epoch 24/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.7114 - mae: 0.7091 - val_loss: 0.6505 - val_mae: 0.6721\n",
            "Epoch 25/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.6722 - mae: 0.6950 - val_loss: 0.6229 - val_mae: 0.6614\n",
            "Epoch 26/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.6394 - mae: 0.6817 - val_loss: 0.5934 - val_mae: 0.6496\n",
            "Epoch 27/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.6090 - mae: 0.6696 - val_loss: 0.5624 - val_mae: 0.6363\n",
            "Epoch 28/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.5807 - mae: 0.6578 - val_loss: 0.5376 - val_mae: 0.6244\n",
            "Epoch 29/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.5545 - mae: 0.6449 - val_loss: 0.5151 - val_mae: 0.6128\n",
            "Epoch 30/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.5336 - mae: 0.6354 - val_loss: 0.4966 - val_mae: 0.6022\n",
            "Epoch 31/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.5125 - mae: 0.6228 - val_loss: 0.4784 - val_mae: 0.5923\n",
            "Epoch 32/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.4958 - mae: 0.6141 - val_loss: 0.4643 - val_mae: 0.5822\n",
            "Epoch 33/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.4795 - mae: 0.6025 - val_loss: 0.4534 - val_mae: 0.5721\n",
            "Epoch 34/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.4653 - mae: 0.5915 - val_loss: 0.4411 - val_mae: 0.5636\n",
            "Epoch 35/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.4550 - mae: 0.5842 - val_loss: 0.4323 - val_mae: 0.5550\n",
            "Epoch 36/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.4435 - mae: 0.5754 - val_loss: 0.4258 - val_mae: 0.5493\n",
            "Epoch 37/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.4353 - mae: 0.5686 - val_loss: 0.4264 - val_mae: 0.5490\n",
            "Epoch 38/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.4274 - mae: 0.5608 - val_loss: 0.4104 - val_mae: 0.5384\n",
            "Epoch 39/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.4199 - mae: 0.5568 - val_loss: 0.4060 - val_mae: 0.5334\n",
            "Epoch 40/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.4121 - mae: 0.5497 - val_loss: 0.3976 - val_mae: 0.5281\n",
            "Epoch 41/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.4074 - mae: 0.5470 - val_loss: 0.3925 - val_mae: 0.5234\n",
            "Epoch 42/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.4000 - mae: 0.5406 - val_loss: 0.3937 - val_mae: 0.5228\n",
            "Epoch 43/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.3955 - mae: 0.5349 - val_loss: 0.3856 - val_mae: 0.5161\n",
            "Epoch 44/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.3894 - mae: 0.5307 - val_loss: 0.3816 - val_mae: 0.5140\n",
            "Epoch 45/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.3846 - mae: 0.5281 - val_loss: 0.3725 - val_mae: 0.5084\n",
            "Epoch 46/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.3802 - mae: 0.5252 - val_loss: 0.3670 - val_mae: 0.5047\n",
            "Epoch 47/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.3727 - mae: 0.5196 - val_loss: 0.3622 - val_mae: 0.5020\n",
            "Epoch 48/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.3710 - mae: 0.5183 - val_loss: 0.3566 - val_mae: 0.4977\n",
            "Epoch 49/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.3639 - mae: 0.5146 - val_loss: 0.3562 - val_mae: 0.4974\n",
            "Epoch 50/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.3635 - mae: 0.5145 - val_loss: 0.3558 - val_mae: 0.4974\n",
            "Epoch 51/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.3578 - mae: 0.5078 - val_loss: 0.3495 - val_mae: 0.4922\n",
            "Epoch 52/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.3535 - mae: 0.5066 - val_loss: 0.3442 - val_mae: 0.4886\n",
            "Epoch 53/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.3509 - mae: 0.5043 - val_loss: 0.3400 - val_mae: 0.4874\n",
            "Epoch 54/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.3484 - mae: 0.5045 - val_loss: 0.3392 - val_mae: 0.4875\n",
            "Epoch 55/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.3449 - mae: 0.5020 - val_loss: 0.3349 - val_mae: 0.4844\n",
            "Epoch 56/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.3406 - mae: 0.4994 - val_loss: 0.3351 - val_mae: 0.4837\n",
            "Epoch 57/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.3383 - mae: 0.4971 - val_loss: 0.3322 - val_mae: 0.4813\n",
            "Epoch 58/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.3347 - mae: 0.4945 - val_loss: 0.3302 - val_mae: 0.4792\n",
            "Epoch 59/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.3320 - mae: 0.4919 - val_loss: 0.3277 - val_mae: 0.4761\n",
            "Epoch 60/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.3277 - mae: 0.4869 - val_loss: 0.3197 - val_mae: 0.4730\n",
            "Epoch 61/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.3276 - mae: 0.4907 - val_loss: 0.3148 - val_mae: 0.4692\n",
            "Epoch 62/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.3215 - mae: 0.4857 - val_loss: 0.3122 - val_mae: 0.4682\n",
            "Epoch 63/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.3189 - mae: 0.4841 - val_loss: 0.3089 - val_mae: 0.4649\n",
            "Epoch 64/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.3154 - mae: 0.4811 - val_loss: 0.3073 - val_mae: 0.4637\n",
            "Epoch 65/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.3122 - mae: 0.4785 - val_loss: 0.3058 - val_mae: 0.4612\n",
            "Epoch 66/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.3090 - mae: 0.4752 - val_loss: 0.3027 - val_mae: 0.4581\n",
            "Epoch 67/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.3058 - mae: 0.4711 - val_loss: 0.3007 - val_mae: 0.4567\n",
            "Epoch 68/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.3064 - mae: 0.4731 - val_loss: 0.3018 - val_mae: 0.4570\n",
            "Epoch 69/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.3041 - mae: 0.4698 - val_loss: 0.2898 - val_mae: 0.4497\n",
            "Epoch 70/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2977 - mae: 0.4675 - val_loss: 0.2870 - val_mae: 0.4469\n",
            "Epoch 71/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.2951 - mae: 0.4650 - val_loss: 0.2888 - val_mae: 0.4474\n",
            "Epoch 72/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.2914 - mae: 0.4600 - val_loss: 0.2821 - val_mae: 0.4427\n",
            "Epoch 73/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.2871 - mae: 0.4585 - val_loss: 0.2779 - val_mae: 0.4398\n",
            "Epoch 74/600\n",
            "600/600 [==============================] - 0s 15us/sample - loss: 0.2836 - mae: 0.4574 - val_loss: 0.2873 - val_mae: 0.4458\n",
            "Epoch 75/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.2822 - mae: 0.4523 - val_loss: 0.2706 - val_mae: 0.4343\n",
            "Epoch 76/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.2771 - mae: 0.4532 - val_loss: 0.2793 - val_mae: 0.4391\n",
            "Epoch 77/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.2773 - mae: 0.4495 - val_loss: 0.2620 - val_mae: 0.4279\n",
            "Epoch 78/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.2678 - mae: 0.4457 - val_loss: 0.2606 - val_mae: 0.4266\n",
            "Epoch 79/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.2636 - mae: 0.4396 - val_loss: 0.2529 - val_mae: 0.4209\n",
            "Epoch 80/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2591 - mae: 0.4380 - val_loss: 0.2486 - val_mae: 0.4175\n",
            "Epoch 81/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.2582 - mae: 0.4379 - val_loss: 0.2521 - val_mae: 0.4195\n",
            "Epoch 82/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2548 - mae: 0.4334 - val_loss: 0.2455 - val_mae: 0.4149\n",
            "Epoch 83/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2520 - mae: 0.4322 - val_loss: 0.2407 - val_mae: 0.4116\n",
            "Epoch 84/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.2487 - mae: 0.4315 - val_loss: 0.2444 - val_mae: 0.4117\n",
            "Epoch 85/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.2475 - mae: 0.4266 - val_loss: 0.2407 - val_mae: 0.4094\n",
            "Epoch 86/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.2445 - mae: 0.4246 - val_loss: 0.2338 - val_mae: 0.4045\n",
            "Epoch 87/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.2418 - mae: 0.4241 - val_loss: 0.2314 - val_mae: 0.4020\n",
            "Epoch 88/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.2401 - mae: 0.4222 - val_loss: 0.2297 - val_mae: 0.4003\n",
            "Epoch 89/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.2390 - mae: 0.4204 - val_loss: 0.2291 - val_mae: 0.3988\n",
            "Epoch 90/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.2347 - mae: 0.4152 - val_loss: 0.2252 - val_mae: 0.3967\n",
            "Epoch 91/600\n",
            "600/600 [==============================] - 0s 15us/sample - loss: 0.2322 - mae: 0.4143 - val_loss: 0.2222 - val_mae: 0.3938\n",
            "Epoch 92/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2323 - mae: 0.4136 - val_loss: 0.2192 - val_mae: 0.3914\n",
            "Epoch 93/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.2299 - mae: 0.4114 - val_loss: 0.2172 - val_mae: 0.3897\n",
            "Epoch 94/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2253 - mae: 0.4079 - val_loss: 0.2170 - val_mae: 0.3877\n",
            "Epoch 95/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2263 - mae: 0.4087 - val_loss: 0.2163 - val_mae: 0.3863\n",
            "Epoch 96/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.2227 - mae: 0.4047 - val_loss: 0.2130 - val_mae: 0.3831\n",
            "Epoch 97/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2199 - mae: 0.3997 - val_loss: 0.2098 - val_mae: 0.3816\n",
            "Epoch 98/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.2186 - mae: 0.4020 - val_loss: 0.2102 - val_mae: 0.3808\n",
            "Epoch 99/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.2154 - mae: 0.3967 - val_loss: 0.2049 - val_mae: 0.3773\n",
            "Epoch 100/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2130 - mae: 0.3960 - val_loss: 0.2186 - val_mae: 0.3859\n",
            "Epoch 101/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.2170 - mae: 0.3956 - val_loss: 0.2016 - val_mae: 0.3735\n",
            "Epoch 102/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2110 - mae: 0.3935 - val_loss: 0.1997 - val_mae: 0.3714\n",
            "Epoch 103/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.2071 - mae: 0.3886 - val_loss: 0.1962 - val_mae: 0.3694\n",
            "Epoch 104/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2057 - mae: 0.3878 - val_loss: 0.1944 - val_mae: 0.3677\n",
            "Epoch 105/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.2036 - mae: 0.3859 - val_loss: 0.1941 - val_mae: 0.3664\n",
            "Epoch 106/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.2018 - mae: 0.3837 - val_loss: 0.1987 - val_mae: 0.3673\n",
            "Epoch 107/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.2023 - mae: 0.3801 - val_loss: 0.1894 - val_mae: 0.3617\n",
            "Epoch 108/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1979 - mae: 0.3790 - val_loss: 0.1878 - val_mae: 0.3582\n",
            "Epoch 109/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1965 - mae: 0.3776 - val_loss: 0.1869 - val_mae: 0.3583\n",
            "Epoch 110/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1946 - mae: 0.3747 - val_loss: 0.1862 - val_mae: 0.3579\n",
            "Epoch 111/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1983 - mae: 0.3791 - val_loss: 0.1848 - val_mae: 0.3573\n",
            "Epoch 112/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1960 - mae: 0.3767 - val_loss: 0.1817 - val_mae: 0.3529\n",
            "Epoch 113/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1894 - mae: 0.3691 - val_loss: 0.1780 - val_mae: 0.3505\n",
            "Epoch 114/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1922 - mae: 0.3714 - val_loss: 0.1773 - val_mae: 0.3480\n",
            "Epoch 115/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1891 - mae: 0.3685 - val_loss: 0.1748 - val_mae: 0.3469\n",
            "Epoch 116/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1840 - mae: 0.3635 - val_loss: 0.1724 - val_mae: 0.3443\n",
            "Epoch 117/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1825 - mae: 0.3630 - val_loss: 0.1776 - val_mae: 0.3461\n",
            "Epoch 118/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1823 - mae: 0.3591 - val_loss: 0.1704 - val_mae: 0.3426\n",
            "Epoch 119/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1800 - mae: 0.3587 - val_loss: 0.1671 - val_mae: 0.3377\n",
            "Epoch 120/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1795 - mae: 0.3590 - val_loss: 0.1757 - val_mae: 0.3412\n",
            "Epoch 121/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1808 - mae: 0.3556 - val_loss: 0.1645 - val_mae: 0.3355\n",
            "Epoch 122/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1761 - mae: 0.3538 - val_loss: 0.1648 - val_mae: 0.3333\n",
            "Epoch 123/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1739 - mae: 0.3495 - val_loss: 0.1614 - val_mae: 0.3326\n",
            "Epoch 124/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1727 - mae: 0.3506 - val_loss: 0.1613 - val_mae: 0.3326\n",
            "Epoch 125/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1722 - mae: 0.3492 - val_loss: 0.1627 - val_mae: 0.3321\n",
            "Epoch 126/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1730 - mae: 0.3512 - val_loss: 0.1574 - val_mae: 0.3261\n",
            "Epoch 127/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.1687 - mae: 0.3446 - val_loss: 0.1569 - val_mae: 0.3275\n",
            "Epoch 128/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1682 - mae: 0.3446 - val_loss: 0.1548 - val_mae: 0.3231\n",
            "Epoch 129/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1668 - mae: 0.3408 - val_loss: 0.1535 - val_mae: 0.3218\n",
            "Epoch 130/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1645 - mae: 0.3395 - val_loss: 0.1543 - val_mae: 0.3210\n",
            "Epoch 131/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1651 - mae: 0.3380 - val_loss: 0.1536 - val_mae: 0.3210\n",
            "Epoch 132/600\n",
            "600/600 [==============================] - 0s 15us/sample - loss: 0.1679 - mae: 0.3391 - val_loss: 0.1502 - val_mae: 0.3182\n",
            "Epoch 133/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1627 - mae: 0.3375 - val_loss: 0.1491 - val_mae: 0.3179\n",
            "Epoch 134/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1607 - mae: 0.3342 - val_loss: 0.1481 - val_mae: 0.3154\n",
            "Epoch 135/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1604 - mae: 0.3332 - val_loss: 0.1462 - val_mae: 0.3129\n",
            "Epoch 136/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1589 - mae: 0.3306 - val_loss: 0.1494 - val_mae: 0.3133\n",
            "Epoch 137/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1590 - mae: 0.3293 - val_loss: 0.1447 - val_mae: 0.3128\n",
            "Epoch 138/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1577 - mae: 0.3306 - val_loss: 0.1452 - val_mae: 0.3122\n",
            "Epoch 139/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1573 - mae: 0.3291 - val_loss: 0.1540 - val_mae: 0.3150\n",
            "Epoch 140/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1616 - mae: 0.3298 - val_loss: 0.1427 - val_mae: 0.3075\n",
            "Epoch 141/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1542 - mae: 0.3240 - val_loss: 0.1415 - val_mae: 0.3056\n",
            "Epoch 142/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1573 - mae: 0.3257 - val_loss: 0.1438 - val_mae: 0.3061\n",
            "Epoch 143/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.1530 - mae: 0.3208 - val_loss: 0.1422 - val_mae: 0.3050\n",
            "Epoch 144/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1522 - mae: 0.3203 - val_loss: 0.1389 - val_mae: 0.3032\n",
            "Epoch 145/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1557 - mae: 0.3221 - val_loss: 0.1391 - val_mae: 0.3042\n",
            "Epoch 146/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1546 - mae: 0.3236 - val_loss: 0.1423 - val_mae: 0.3035\n",
            "Epoch 147/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1518 - mae: 0.3181 - val_loss: 0.1359 - val_mae: 0.3003\n",
            "Epoch 148/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.1503 - mae: 0.3199 - val_loss: 0.1401 - val_mae: 0.3017\n",
            "Epoch 149/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1490 - mae: 0.3158 - val_loss: 0.1346 - val_mae: 0.2978\n",
            "Epoch 150/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1487 - mae: 0.3163 - val_loss: 0.1352 - val_mae: 0.2982\n",
            "Epoch 151/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1490 - mae: 0.3167 - val_loss: 0.1361 - val_mae: 0.2977\n",
            "Epoch 152/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1474 - mae: 0.3129 - val_loss: 0.1324 - val_mae: 0.2964\n",
            "Epoch 153/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1462 - mae: 0.3129 - val_loss: 0.1381 - val_mae: 0.2981\n",
            "Epoch 154/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1485 - mae: 0.3136 - val_loss: 0.1404 - val_mae: 0.2997\n",
            "Epoch 155/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1484 - mae: 0.3120 - val_loss: 0.1328 - val_mae: 0.2944\n",
            "Epoch 156/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1450 - mae: 0.3113 - val_loss: 0.1396 - val_mae: 0.2966\n",
            "Epoch 157/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1525 - mae: 0.3127 - val_loss: 0.1308 - val_mae: 0.2935\n",
            "Epoch 158/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.1476 - mae: 0.3143 - val_loss: 0.1300 - val_mae: 0.2911\n",
            "Epoch 159/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1430 - mae: 0.3077 - val_loss: 0.1292 - val_mae: 0.2904\n",
            "Epoch 160/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1442 - mae: 0.3090 - val_loss: 0.1290 - val_mae: 0.2891\n",
            "Epoch 161/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1433 - mae: 0.3076 - val_loss: 0.1282 - val_mae: 0.2879\n",
            "Epoch 162/600\n",
            "600/600 [==============================] - 0s 55us/sample - loss: 0.1425 - mae: 0.3060 - val_loss: 0.1280 - val_mae: 0.2871\n",
            "Epoch 163/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.1425 - mae: 0.3041 - val_loss: 0.1282 - val_mae: 0.2892\n",
            "Epoch 164/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.1440 - mae: 0.3069 - val_loss: 0.1282 - val_mae: 0.2892\n",
            "Epoch 165/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1432 - mae: 0.3077 - val_loss: 0.1284 - val_mae: 0.2872\n",
            "Epoch 166/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1406 - mae: 0.3034 - val_loss: 0.1251 - val_mae: 0.2848\n",
            "Epoch 167/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1426 - mae: 0.3034 - val_loss: 0.1274 - val_mae: 0.2852\n",
            "Epoch 168/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1405 - mae: 0.3017 - val_loss: 0.1295 - val_mae: 0.2839\n",
            "Epoch 169/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.1392 - mae: 0.2980 - val_loss: 0.1265 - val_mae: 0.2861\n",
            "Epoch 170/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1393 - mae: 0.3022 - val_loss: 0.1335 - val_mae: 0.2858\n",
            "Epoch 171/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1434 - mae: 0.2991 - val_loss: 0.1242 - val_mae: 0.2834\n",
            "Epoch 172/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.1385 - mae: 0.2996 - val_loss: 0.1324 - val_mae: 0.2870\n",
            "Epoch 173/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1413 - mae: 0.2994 - val_loss: 0.1328 - val_mae: 0.2864\n",
            "Epoch 174/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.1399 - mae: 0.2962 - val_loss: 0.1243 - val_mae: 0.2812\n",
            "Epoch 175/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1386 - mae: 0.2975 - val_loss: 0.1287 - val_mae: 0.2827\n",
            "Epoch 176/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1379 - mae: 0.2942 - val_loss: 0.1253 - val_mae: 0.2833\n",
            "Epoch 177/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.1389 - mae: 0.2982 - val_loss: 0.1220 - val_mae: 0.2774\n",
            "Epoch 178/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1368 - mae: 0.2955 - val_loss: 0.1313 - val_mae: 0.2830\n",
            "Epoch 179/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1407 - mae: 0.2953 - val_loss: 0.1287 - val_mae: 0.2802\n",
            "Epoch 180/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.1383 - mae: 0.2925 - val_loss: 0.1225 - val_mae: 0.2768\n",
            "Epoch 181/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1360 - mae: 0.2926 - val_loss: 0.1228 - val_mae: 0.2761\n",
            "Epoch 182/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1372 - mae: 0.2917 - val_loss: 0.1263 - val_mae: 0.2787\n",
            "Epoch 183/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1374 - mae: 0.2902 - val_loss: 0.1219 - val_mae: 0.2772\n",
            "Epoch 184/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1396 - mae: 0.2961 - val_loss: 0.1208 - val_mae: 0.2776\n",
            "Epoch 185/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1356 - mae: 0.2938 - val_loss: 0.1216 - val_mae: 0.2752\n",
            "Epoch 186/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1349 - mae: 0.2898 - val_loss: 0.1266 - val_mae: 0.2788\n",
            "Epoch 187/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1369 - mae: 0.2917 - val_loss: 0.1227 - val_mae: 0.2753\n",
            "Epoch 188/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1362 - mae: 0.2897 - val_loss: 0.1201 - val_mae: 0.2740\n",
            "Epoch 189/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1338 - mae: 0.2884 - val_loss: 0.1184 - val_mae: 0.2729\n",
            "Epoch 190/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1340 - mae: 0.2888 - val_loss: 0.1179 - val_mae: 0.2718\n",
            "Epoch 191/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1334 - mae: 0.2880 - val_loss: 0.1208 - val_mae: 0.2711\n",
            "Epoch 192/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1348 - mae: 0.2881 - val_loss: 0.1360 - val_mae: 0.2830\n",
            "Epoch 193/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.1430 - mae: 0.2888 - val_loss: 0.1226 - val_mae: 0.2742\n",
            "Epoch 194/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1322 - mae: 0.2846 - val_loss: 0.1168 - val_mae: 0.2718\n",
            "Epoch 195/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1319 - mae: 0.2869 - val_loss: 0.1243 - val_mae: 0.2720\n",
            "Epoch 196/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.1328 - mae: 0.2819 - val_loss: 0.1167 - val_mae: 0.2715\n",
            "Epoch 197/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1320 - mae: 0.2855 - val_loss: 0.1250 - val_mae: 0.2740\n",
            "Epoch 198/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1334 - mae: 0.2828 - val_loss: 0.1156 - val_mae: 0.2678\n",
            "Epoch 199/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1332 - mae: 0.2856 - val_loss: 0.1197 - val_mae: 0.2698\n",
            "Epoch 200/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1307 - mae: 0.2814 - val_loss: 0.1144 - val_mae: 0.2665\n",
            "Epoch 201/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1326 - mae: 0.2845 - val_loss: 0.1161 - val_mae: 0.2675\n",
            "Epoch 202/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.1316 - mae: 0.2847 - val_loss: 0.1217 - val_mae: 0.2694\n",
            "Epoch 203/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1329 - mae: 0.2821 - val_loss: 0.1150 - val_mae: 0.2638\n",
            "Epoch 204/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1304 - mae: 0.2808 - val_loss: 0.1225 - val_mae: 0.2686\n",
            "Epoch 205/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1325 - mae: 0.2783 - val_loss: 0.1179 - val_mae: 0.2663\n",
            "Epoch 206/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1297 - mae: 0.2780 - val_loss: 0.1138 - val_mae: 0.2639\n",
            "Epoch 207/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1297 - mae: 0.2783 - val_loss: 0.1132 - val_mae: 0.2658\n",
            "Epoch 208/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1297 - mae: 0.2804 - val_loss: 0.1162 - val_mae: 0.2643\n",
            "Epoch 209/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1321 - mae: 0.2760 - val_loss: 0.1117 - val_mae: 0.2639\n",
            "Epoch 210/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1284 - mae: 0.2788 - val_loss: 0.1111 - val_mae: 0.2628\n",
            "Epoch 211/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1282 - mae: 0.2789 - val_loss: 0.1238 - val_mae: 0.2694\n",
            "Epoch 212/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1310 - mae: 0.2771 - val_loss: 0.1107 - val_mae: 0.2604\n",
            "Epoch 213/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1274 - mae: 0.2768 - val_loss: 0.1107 - val_mae: 0.2620\n",
            "Epoch 214/600\n",
            "600/600 [==============================] - 0s 15us/sample - loss: 0.1276 - mae: 0.2783 - val_loss: 0.1241 - val_mae: 0.2675\n",
            "Epoch 215/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1284 - mae: 0.2718 - val_loss: 0.1120 - val_mae: 0.2625\n",
            "Epoch 216/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.1278 - mae: 0.2779 - val_loss: 0.1131 - val_mae: 0.2608\n",
            "Epoch 217/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1267 - mae: 0.2731 - val_loss: 0.1113 - val_mae: 0.2606\n",
            "Epoch 218/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.1254 - mae: 0.2752 - val_loss: 0.1094 - val_mae: 0.2572\n",
            "Epoch 219/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.1259 - mae: 0.2740 - val_loss: 0.1115 - val_mae: 0.2564\n",
            "Epoch 220/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.1257 - mae: 0.2708 - val_loss: 0.1089 - val_mae: 0.2591\n",
            "Epoch 221/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.1248 - mae: 0.2748 - val_loss: 0.1142 - val_mae: 0.2579\n",
            "Epoch 222/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1337 - mae: 0.2783 - val_loss: 0.1081 - val_mae: 0.2568\n",
            "Epoch 223/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.1254 - mae: 0.2740 - val_loss: 0.1092 - val_mae: 0.2565\n",
            "Epoch 224/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.1238 - mae: 0.2714 - val_loss: 0.1153 - val_mae: 0.2589\n",
            "Epoch 225/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1275 - mae: 0.2715 - val_loss: 0.1087 - val_mae: 0.2559\n",
            "Epoch 226/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1254 - mae: 0.2722 - val_loss: 0.1063 - val_mae: 0.2546\n",
            "Epoch 227/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1242 - mae: 0.2710 - val_loss: 0.1099 - val_mae: 0.2550\n",
            "Epoch 228/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.1239 - mae: 0.2690 - val_loss: 0.1060 - val_mae: 0.2525\n",
            "Epoch 229/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1226 - mae: 0.2683 - val_loss: 0.1075 - val_mae: 0.2537\n",
            "Epoch 230/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.1237 - mae: 0.2686 - val_loss: 0.1072 - val_mae: 0.2552\n",
            "Epoch 231/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1227 - mae: 0.2711 - val_loss: 0.1056 - val_mae: 0.2543\n",
            "Epoch 232/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1249 - mae: 0.2713 - val_loss: 0.1064 - val_mae: 0.2542\n",
            "Epoch 233/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1233 - mae: 0.2700 - val_loss: 0.1051 - val_mae: 0.2517\n",
            "Epoch 234/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.1213 - mae: 0.2673 - val_loss: 0.1068 - val_mae: 0.2518\n",
            "Epoch 235/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.1210 - mae: 0.2663 - val_loss: 0.1105 - val_mae: 0.2541\n",
            "Epoch 236/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1215 - mae: 0.2661 - val_loss: 0.1057 - val_mae: 0.2512\n",
            "Epoch 237/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1218 - mae: 0.2671 - val_loss: 0.1102 - val_mae: 0.2542\n",
            "Epoch 238/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1207 - mae: 0.2658 - val_loss: 0.1039 - val_mae: 0.2469\n",
            "Epoch 239/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1199 - mae: 0.2635 - val_loss: 0.1123 - val_mae: 0.2530\n",
            "Epoch 240/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1200 - mae: 0.2625 - val_loss: 0.1023 - val_mae: 0.2491\n",
            "Epoch 241/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1191 - mae: 0.2641 - val_loss: 0.1057 - val_mae: 0.2493\n",
            "Epoch 242/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1195 - mae: 0.2647 - val_loss: 0.1044 - val_mae: 0.2465\n",
            "Epoch 243/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1188 - mae: 0.2615 - val_loss: 0.1103 - val_mae: 0.2500\n",
            "Epoch 244/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1197 - mae: 0.2604 - val_loss: 0.1061 - val_mae: 0.2487\n",
            "Epoch 245/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1191 - mae: 0.2632 - val_loss: 0.1112 - val_mae: 0.2510\n",
            "Epoch 246/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1222 - mae: 0.2624 - val_loss: 0.1040 - val_mae: 0.2463\n",
            "Epoch 247/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1170 - mae: 0.2593 - val_loss: 0.1002 - val_mae: 0.2436\n",
            "Epoch 248/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1164 - mae: 0.2595 - val_loss: 0.1025 - val_mae: 0.2460\n",
            "Epoch 249/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1174 - mae: 0.2617 - val_loss: 0.1078 - val_mae: 0.2458\n",
            "Epoch 250/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.1178 - mae: 0.2572 - val_loss: 0.1002 - val_mae: 0.2399\n",
            "Epoch 251/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.1174 - mae: 0.2574 - val_loss: 0.1037 - val_mae: 0.2448\n",
            "Epoch 252/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1178 - mae: 0.2593 - val_loss: 0.1071 - val_mae: 0.2465\n",
            "Epoch 253/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1187 - mae: 0.2600 - val_loss: 0.0995 - val_mae: 0.2419\n",
            "Epoch 254/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1167 - mae: 0.2585 - val_loss: 0.0985 - val_mae: 0.2421\n",
            "Epoch 255/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1146 - mae: 0.2590 - val_loss: 0.1021 - val_mae: 0.2422\n",
            "Epoch 256/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.1165 - mae: 0.2559 - val_loss: 0.1050 - val_mae: 0.2444\n",
            "Epoch 257/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1154 - mae: 0.2551 - val_loss: 0.0984 - val_mae: 0.2408\n",
            "Epoch 258/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1194 - mae: 0.2602 - val_loss: 0.0966 - val_mae: 0.2382\n",
            "Epoch 259/600\n",
            "600/600 [==============================] - 0s 40us/sample - loss: 0.1146 - mae: 0.2563 - val_loss: 0.0972 - val_mae: 0.2353\n",
            "Epoch 260/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.1145 - mae: 0.2539 - val_loss: 0.0986 - val_mae: 0.2378\n",
            "Epoch 261/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.1139 - mae: 0.2540 - val_loss: 0.0994 - val_mae: 0.2363\n",
            "Epoch 262/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.1159 - mae: 0.2549 - val_loss: 0.0961 - val_mae: 0.2389\n",
            "Epoch 263/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.1143 - mae: 0.2573 - val_loss: 0.0966 - val_mae: 0.2367\n",
            "Epoch 264/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.1118 - mae: 0.2519 - val_loss: 0.0974 - val_mae: 0.2374\n",
            "Epoch 265/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1119 - mae: 0.2522 - val_loss: 0.0955 - val_mae: 0.2379\n",
            "Epoch 266/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1140 - mae: 0.2552 - val_loss: 0.0969 - val_mae: 0.2395\n",
            "Epoch 267/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.1142 - mae: 0.2567 - val_loss: 0.0936 - val_mae: 0.2345\n",
            "Epoch 268/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.1115 - mae: 0.2519 - val_loss: 0.0936 - val_mae: 0.2344\n",
            "Epoch 269/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1119 - mae: 0.2531 - val_loss: 0.1036 - val_mae: 0.2370\n",
            "Epoch 270/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1129 - mae: 0.2486 - val_loss: 0.0939 - val_mae: 0.2327\n",
            "Epoch 271/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1093 - mae: 0.2496 - val_loss: 0.1008 - val_mae: 0.2375\n",
            "Epoch 272/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.1087 - mae: 0.2459 - val_loss: 0.0909 - val_mae: 0.2315\n",
            "Epoch 273/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1083 - mae: 0.2502 - val_loss: 0.0897 - val_mae: 0.2267\n",
            "Epoch 274/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1063 - mae: 0.2449 - val_loss: 0.0884 - val_mae: 0.2251\n",
            "Epoch 275/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.1053 - mae: 0.2437 - val_loss: 0.0974 - val_mae: 0.2321\n",
            "Epoch 276/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.1080 - mae: 0.2451 - val_loss: 0.0946 - val_mae: 0.2309\n",
            "Epoch 277/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.1059 - mae: 0.2432 - val_loss: 0.0905 - val_mae: 0.2298\n",
            "Epoch 278/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1077 - mae: 0.2492 - val_loss: 0.0922 - val_mae: 0.2270\n",
            "Epoch 279/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.1052 - mae: 0.2424 - val_loss: 0.0927 - val_mae: 0.2255\n",
            "Epoch 280/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1060 - mae: 0.2419 - val_loss: 0.0879 - val_mae: 0.2232\n",
            "Epoch 281/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.1040 - mae: 0.2406 - val_loss: 0.0887 - val_mae: 0.2284\n",
            "Epoch 282/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.1047 - mae: 0.2453 - val_loss: 0.0854 - val_mae: 0.2208\n",
            "Epoch 283/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.1037 - mae: 0.2409 - val_loss: 0.0892 - val_mae: 0.2235\n",
            "Epoch 284/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.1076 - mae: 0.2454 - val_loss: 0.0849 - val_mae: 0.2203\n",
            "Epoch 285/600\n",
            "600/600 [==============================] - 0s 41us/sample - loss: 0.1021 - mae: 0.2407 - val_loss: 0.0878 - val_mae: 0.2201\n",
            "Epoch 286/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1071 - mae: 0.2429 - val_loss: 0.0909 - val_mae: 0.2224\n",
            "Epoch 287/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1041 - mae: 0.2374 - val_loss: 0.0908 - val_mae: 0.2196\n",
            "Epoch 288/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1039 - mae: 0.2376 - val_loss: 0.0917 - val_mae: 0.2231\n",
            "Epoch 289/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.1025 - mae: 0.2349 - val_loss: 0.0834 - val_mae: 0.2177\n",
            "Epoch 290/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1014 - mae: 0.2375 - val_loss: 0.0910 - val_mae: 0.2232\n",
            "Epoch 291/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1016 - mae: 0.2363 - val_loss: 0.0831 - val_mae: 0.2184\n",
            "Epoch 292/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.1004 - mae: 0.2375 - val_loss: 0.0830 - val_mae: 0.2173\n",
            "Epoch 293/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1010 - mae: 0.2386 - val_loss: 0.0907 - val_mae: 0.2226\n",
            "Epoch 294/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1018 - mae: 0.2390 - val_loss: 0.0847 - val_mae: 0.2154\n",
            "Epoch 295/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.1015 - mae: 0.2358 - val_loss: 0.0865 - val_mae: 0.2150\n",
            "Epoch 296/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.1025 - mae: 0.2329 - val_loss: 0.0832 - val_mae: 0.2160\n",
            "Epoch 297/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0986 - mae: 0.2341 - val_loss: 0.0831 - val_mae: 0.2185\n",
            "Epoch 298/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.1033 - mae: 0.2403 - val_loss: 0.0827 - val_mae: 0.2161\n",
            "Epoch 299/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0991 - mae: 0.2366 - val_loss: 0.0876 - val_mae: 0.2169\n",
            "Epoch 300/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.1043 - mae: 0.2368 - val_loss: 0.0807 - val_mae: 0.2143\n",
            "Epoch 301/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0981 - mae: 0.2347 - val_loss: 0.0797 - val_mae: 0.2125\n",
            "Epoch 302/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.0985 - mae: 0.2328 - val_loss: 0.0844 - val_mae: 0.2145\n",
            "Epoch 303/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.1017 - mae: 0.2378 - val_loss: 0.0795 - val_mae: 0.2116\n",
            "Epoch 304/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0975 - mae: 0.2330 - val_loss: 0.0796 - val_mae: 0.2087\n",
            "Epoch 305/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0972 - mae: 0.2321 - val_loss: 0.0811 - val_mae: 0.2099\n",
            "Epoch 306/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0966 - mae: 0.2283 - val_loss: 0.0836 - val_mae: 0.2115\n",
            "Epoch 307/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0976 - mae: 0.2303 - val_loss: 0.0893 - val_mae: 0.2142\n",
            "Epoch 308/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0993 - mae: 0.2286 - val_loss: 0.0842 - val_mae: 0.2125\n",
            "Epoch 309/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0989 - mae: 0.2308 - val_loss: 0.0842 - val_mae: 0.2102\n",
            "Epoch 310/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0974 - mae: 0.2244 - val_loss: 0.0790 - val_mae: 0.2122\n",
            "Epoch 311/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0950 - mae: 0.2308 - val_loss: 0.0863 - val_mae: 0.2118\n",
            "Epoch 312/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0961 - mae: 0.2258 - val_loss: 0.0777 - val_mae: 0.2069\n",
            "Epoch 313/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0943 - mae: 0.2277 - val_loss: 0.0870 - val_mae: 0.2101\n",
            "Epoch 314/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0970 - mae: 0.2228 - val_loss: 0.0777 - val_mae: 0.2086\n",
            "Epoch 315/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.1009 - mae: 0.2335 - val_loss: 0.0796 - val_mae: 0.2072\n",
            "Epoch 316/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0936 - mae: 0.2254 - val_loss: 0.0764 - val_mae: 0.2049\n",
            "Epoch 317/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0934 - mae: 0.2269 - val_loss: 0.0846 - val_mae: 0.2083\n",
            "Epoch 318/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0970 - mae: 0.2243 - val_loss: 0.0755 - val_mae: 0.2033\n",
            "Epoch 319/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0922 - mae: 0.2246 - val_loss: 0.0765 - val_mae: 0.2027\n",
            "Epoch 320/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0946 - mae: 0.2247 - val_loss: 0.0760 - val_mae: 0.2037\n",
            "Epoch 321/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0926 - mae: 0.2246 - val_loss: 0.0756 - val_mae: 0.2022\n",
            "Epoch 322/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0920 - mae: 0.2223 - val_loss: 0.0782 - val_mae: 0.2057\n",
            "Epoch 323/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0916 - mae: 0.2212 - val_loss: 0.0784 - val_mae: 0.2066\n",
            "Epoch 324/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0953 - mae: 0.2279 - val_loss: 0.0786 - val_mae: 0.2033\n",
            "Epoch 325/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0915 - mae: 0.2211 - val_loss: 0.0754 - val_mae: 0.2025\n",
            "Epoch 326/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0912 - mae: 0.2226 - val_loss: 0.0779 - val_mae: 0.2020\n",
            "Epoch 327/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0906 - mae: 0.2193 - val_loss: 0.0728 - val_mae: 0.1980\n",
            "Epoch 328/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0899 - mae: 0.2190 - val_loss: 0.0731 - val_mae: 0.2011\n",
            "Epoch 329/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0894 - mae: 0.2208 - val_loss: 0.0724 - val_mae: 0.1973\n",
            "Epoch 330/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0893 - mae: 0.2189 - val_loss: 0.0727 - val_mae: 0.1974\n",
            "Epoch 331/600\n",
            "600/600 [==============================] - 0s 42us/sample - loss: 0.0903 - mae: 0.2187 - val_loss: 0.0781 - val_mae: 0.2024\n",
            "Epoch 332/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.0911 - mae: 0.2217 - val_loss: 0.0739 - val_mae: 0.2002\n",
            "Epoch 333/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.0886 - mae: 0.2184 - val_loss: 0.0735 - val_mae: 0.1992\n",
            "Epoch 334/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0891 - mae: 0.2186 - val_loss: 0.0711 - val_mae: 0.1965\n",
            "Epoch 335/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0892 - mae: 0.2191 - val_loss: 0.0833 - val_mae: 0.2063\n",
            "Epoch 336/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0919 - mae: 0.2188 - val_loss: 0.0802 - val_mae: 0.2044\n",
            "Epoch 337/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0888 - mae: 0.2159 - val_loss: 0.0703 - val_mae: 0.1942\n",
            "Epoch 338/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0875 - mae: 0.2174 - val_loss: 0.0752 - val_mae: 0.1957\n",
            "Epoch 339/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0873 - mae: 0.2129 - val_loss: 0.0728 - val_mae: 0.2005\n",
            "Epoch 340/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0875 - mae: 0.2174 - val_loss: 0.0704 - val_mae: 0.1920\n",
            "Epoch 341/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0873 - mae: 0.2149 - val_loss: 0.0690 - val_mae: 0.1920\n",
            "Epoch 342/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.0858 - mae: 0.2131 - val_loss: 0.0742 - val_mae: 0.1971\n",
            "Epoch 343/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0889 - mae: 0.2163 - val_loss: 0.0688 - val_mae: 0.1921\n",
            "Epoch 344/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0867 - mae: 0.2159 - val_loss: 0.0684 - val_mae: 0.1897\n",
            "Epoch 345/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0858 - mae: 0.2133 - val_loss: 0.0698 - val_mae: 0.1916\n",
            "Epoch 346/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0851 - mae: 0.2116 - val_loss: 0.0693 - val_mae: 0.1889\n",
            "Epoch 347/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0842 - mae: 0.2086 - val_loss: 0.0712 - val_mae: 0.1971\n",
            "Epoch 348/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0878 - mae: 0.2161 - val_loss: 0.0697 - val_mae: 0.1897\n",
            "Epoch 349/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0843 - mae: 0.2096 - val_loss: 0.0712 - val_mae: 0.1938\n",
            "Epoch 350/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0869 - mae: 0.2149 - val_loss: 0.0666 - val_mae: 0.1880\n",
            "Epoch 351/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0852 - mae: 0.2097 - val_loss: 0.0701 - val_mae: 0.1961\n",
            "Epoch 352/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0840 - mae: 0.2137 - val_loss: 0.0733 - val_mae: 0.1908\n",
            "Epoch 353/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0849 - mae: 0.2090 - val_loss: 0.0662 - val_mae: 0.1875\n",
            "Epoch 354/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0823 - mae: 0.2091 - val_loss: 0.0666 - val_mae: 0.1870\n",
            "Epoch 355/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0833 - mae: 0.2089 - val_loss: 0.0664 - val_mae: 0.1885\n",
            "Epoch 356/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.0862 - mae: 0.2125 - val_loss: 0.0728 - val_mae: 0.1917\n",
            "Epoch 357/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0828 - mae: 0.2064 - val_loss: 0.0653 - val_mae: 0.1865\n",
            "Epoch 358/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0843 - mae: 0.2094 - val_loss: 0.0674 - val_mae: 0.1887\n",
            "Epoch 359/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0856 - mae: 0.2116 - val_loss: 0.0674 - val_mae: 0.1864\n",
            "Epoch 360/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0813 - mae: 0.2064 - val_loss: 0.0649 - val_mae: 0.1846\n",
            "Epoch 361/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0837 - mae: 0.2098 - val_loss: 0.0643 - val_mae: 0.1847\n",
            "Epoch 362/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0807 - mae: 0.2054 - val_loss: 0.0685 - val_mae: 0.1907\n",
            "Epoch 363/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.0811 - mae: 0.2064 - val_loss: 0.0666 - val_mae: 0.1833\n",
            "Epoch 364/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0809 - mae: 0.2030 - val_loss: 0.0668 - val_mae: 0.1863\n",
            "Epoch 365/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0797 - mae: 0.2034 - val_loss: 0.0651 - val_mae: 0.1867\n",
            "Epoch 366/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0803 - mae: 0.2069 - val_loss: 0.0635 - val_mae: 0.1802\n",
            "Epoch 367/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0801 - mae: 0.2025 - val_loss: 0.0649 - val_mae: 0.1821\n",
            "Epoch 368/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0790 - mae: 0.2028 - val_loss: 0.0629 - val_mae: 0.1781\n",
            "Epoch 369/600\n",
            "600/600 [==============================] - 0s 45us/sample - loss: 0.0799 - mae: 0.2024 - val_loss: 0.0626 - val_mae: 0.1821\n",
            "Epoch 370/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0792 - mae: 0.2032 - val_loss: 0.0620 - val_mae: 0.1775\n",
            "Epoch 371/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0788 - mae: 0.2006 - val_loss: 0.0632 - val_mae: 0.1796\n",
            "Epoch 372/600\n",
            "600/600 [==============================] - 0s 39us/sample - loss: 0.0781 - mae: 0.2008 - val_loss: 0.0620 - val_mae: 0.1776\n",
            "Epoch 373/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.0794 - mae: 0.2009 - val_loss: 0.0620 - val_mae: 0.1794\n",
            "Epoch 374/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0794 - mae: 0.2025 - val_loss: 0.0646 - val_mae: 0.1842\n",
            "Epoch 375/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0817 - mae: 0.2038 - val_loss: 0.0631 - val_mae: 0.1766\n",
            "Epoch 376/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.0770 - mae: 0.1964 - val_loss: 0.0619 - val_mae: 0.1792\n",
            "Epoch 377/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0783 - mae: 0.2011 - val_loss: 0.0628 - val_mae: 0.1768\n",
            "Epoch 378/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0772 - mae: 0.1972 - val_loss: 0.0608 - val_mae: 0.1753\n",
            "Epoch 379/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0764 - mae: 0.1978 - val_loss: 0.0617 - val_mae: 0.1814\n",
            "Epoch 380/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0769 - mae: 0.2012 - val_loss: 0.0613 - val_mae: 0.1760\n",
            "Epoch 381/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0756 - mae: 0.1960 - val_loss: 0.0627 - val_mae: 0.1788\n",
            "Epoch 382/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0777 - mae: 0.2003 - val_loss: 0.0686 - val_mae: 0.1843\n",
            "Epoch 383/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0757 - mae: 0.1940 - val_loss: 0.0596 - val_mae: 0.1777\n",
            "Epoch 384/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0764 - mae: 0.1993 - val_loss: 0.0597 - val_mae: 0.1748\n",
            "Epoch 385/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0745 - mae: 0.1962 - val_loss: 0.0596 - val_mae: 0.1720\n",
            "Epoch 386/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0765 - mae: 0.1946 - val_loss: 0.0607 - val_mae: 0.1758\n",
            "Epoch 387/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0745 - mae: 0.1958 - val_loss: 0.0592 - val_mae: 0.1757\n",
            "Epoch 388/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0742 - mae: 0.1967 - val_loss: 0.0633 - val_mae: 0.1791\n",
            "Epoch 389/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0754 - mae: 0.1947 - val_loss: 0.0587 - val_mae: 0.1719\n",
            "Epoch 390/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0733 - mae: 0.1934 - val_loss: 0.0583 - val_mae: 0.1731\n",
            "Epoch 391/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0734 - mae: 0.1931 - val_loss: 0.0574 - val_mae: 0.1725\n",
            "Epoch 392/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0737 - mae: 0.1951 - val_loss: 0.0572 - val_mae: 0.1699\n",
            "Epoch 393/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0732 - mae: 0.1944 - val_loss: 0.0650 - val_mae: 0.1743\n",
            "Epoch 394/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.0775 - mae: 0.1911 - val_loss: 0.0583 - val_mae: 0.1713\n",
            "Epoch 395/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0731 - mae: 0.1917 - val_loss: 0.0614 - val_mae: 0.1785\n",
            "Epoch 396/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0734 - mae: 0.1946 - val_loss: 0.0575 - val_mae: 0.1739\n",
            "Epoch 397/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0729 - mae: 0.1925 - val_loss: 0.0565 - val_mae: 0.1694\n",
            "Epoch 398/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0754 - mae: 0.1955 - val_loss: 0.0586 - val_mae: 0.1714\n",
            "Epoch 399/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0713 - mae: 0.1891 - val_loss: 0.0566 - val_mae: 0.1724\n",
            "Epoch 400/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0728 - mae: 0.1929 - val_loss: 0.0584 - val_mae: 0.1685\n",
            "Epoch 401/600\n",
            "600/600 [==============================] - 0s 47us/sample - loss: 0.0728 - mae: 0.1925 - val_loss: 0.0654 - val_mae: 0.1781\n",
            "Epoch 402/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0739 - mae: 0.1916 - val_loss: 0.0567 - val_mae: 0.1664\n",
            "Epoch 403/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0734 - mae: 0.1919 - val_loss: 0.0555 - val_mae: 0.1702\n",
            "Epoch 404/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.0705 - mae: 0.1899 - val_loss: 0.0551 - val_mae: 0.1690\n",
            "Epoch 405/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0699 - mae: 0.1900 - val_loss: 0.0570 - val_mae: 0.1681\n",
            "Epoch 406/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0700 - mae: 0.1886 - val_loss: 0.0544 - val_mae: 0.1654\n",
            "Epoch 407/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0720 - mae: 0.1925 - val_loss: 0.0580 - val_mae: 0.1665\n",
            "Epoch 408/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0707 - mae: 0.1862 - val_loss: 0.0539 - val_mae: 0.1655\n",
            "Epoch 409/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0701 - mae: 0.1897 - val_loss: 0.0539 - val_mae: 0.1647\n",
            "Epoch 410/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0691 - mae: 0.1855 - val_loss: 0.0553 - val_mae: 0.1663\n",
            "Epoch 411/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0712 - mae: 0.1881 - val_loss: 0.0544 - val_mae: 0.1691\n",
            "Epoch 412/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0693 - mae: 0.1890 - val_loss: 0.0569 - val_mae: 0.1674\n",
            "Epoch 413/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0714 - mae: 0.1891 - val_loss: 0.0550 - val_mae: 0.1627\n",
            "Epoch 414/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.0682 - mae: 0.1838 - val_loss: 0.0578 - val_mae: 0.1690\n",
            "Epoch 415/600\n",
            "600/600 [==============================] - 0s 39us/sample - loss: 0.0687 - mae: 0.1843 - val_loss: 0.0530 - val_mae: 0.1649\n",
            "Epoch 416/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0675 - mae: 0.1855 - val_loss: 0.0576 - val_mae: 0.1660\n",
            "Epoch 417/600\n",
            "600/600 [==============================] - 0s 53us/sample - loss: 0.0678 - mae: 0.1820 - val_loss: 0.0577 - val_mae: 0.1701\n",
            "Epoch 418/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0680 - mae: 0.1849 - val_loss: 0.0524 - val_mae: 0.1642\n",
            "Epoch 419/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.0688 - mae: 0.1861 - val_loss: 0.0563 - val_mae: 0.1638\n",
            "Epoch 420/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0674 - mae: 0.1817 - val_loss: 0.0546 - val_mae: 0.1654\n",
            "Epoch 421/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0698 - mae: 0.1884 - val_loss: 0.0522 - val_mae: 0.1627\n",
            "Epoch 422/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0668 - mae: 0.1832 - val_loss: 0.0530 - val_mae: 0.1623\n",
            "Epoch 423/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0691 - mae: 0.1863 - val_loss: 0.0521 - val_mae: 0.1615\n",
            "Epoch 424/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0659 - mae: 0.1837 - val_loss: 0.0598 - val_mae: 0.1705\n",
            "Epoch 425/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0674 - mae: 0.1806 - val_loss: 0.0530 - val_mae: 0.1598\n",
            "Epoch 426/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0661 - mae: 0.1802 - val_loss: 0.0507 - val_mae: 0.1607\n",
            "Epoch 427/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0661 - mae: 0.1809 - val_loss: 0.0508 - val_mae: 0.1614\n",
            "Epoch 428/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0670 - mae: 0.1839 - val_loss: 0.0523 - val_mae: 0.1587\n",
            "Epoch 429/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0652 - mae: 0.1796 - val_loss: 0.0584 - val_mae: 0.1672\n",
            "Epoch 430/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0666 - mae: 0.1795 - val_loss: 0.0501 - val_mae: 0.1590\n",
            "Epoch 431/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0643 - mae: 0.1803 - val_loss: 0.0529 - val_mae: 0.1596\n",
            "Epoch 432/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0636 - mae: 0.1761 - val_loss: 0.0520 - val_mae: 0.1627\n",
            "Epoch 433/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0651 - mae: 0.1797 - val_loss: 0.0495 - val_mae: 0.1587\n",
            "Epoch 434/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0675 - mae: 0.1815 - val_loss: 0.0541 - val_mae: 0.1603\n",
            "Epoch 435/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0641 - mae: 0.1777 - val_loss: 0.0495 - val_mae: 0.1570\n",
            "Epoch 436/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0640 - mae: 0.1794 - val_loss: 0.0552 - val_mae: 0.1617\n",
            "Epoch 437/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0643 - mae: 0.1782 - val_loss: 0.0493 - val_mae: 0.1566\n",
            "Epoch 438/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0667 - mae: 0.1826 - val_loss: 0.0499 - val_mae: 0.1616\n",
            "Epoch 439/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0639 - mae: 0.1817 - val_loss: 0.0565 - val_mae: 0.1628\n",
            "Epoch 440/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0660 - mae: 0.1773 - val_loss: 0.0486 - val_mae: 0.1566\n",
            "Epoch 441/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0621 - mae: 0.1764 - val_loss: 0.0535 - val_mae: 0.1625\n",
            "Epoch 442/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0628 - mae: 0.1748 - val_loss: 0.0486 - val_mae: 0.1554\n",
            "Epoch 443/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0628 - mae: 0.1759 - val_loss: 0.0498 - val_mae: 0.1617\n",
            "Epoch 444/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0629 - mae: 0.1780 - val_loss: 0.0481 - val_mae: 0.1582\n",
            "Epoch 445/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0623 - mae: 0.1763 - val_loss: 0.0480 - val_mae: 0.1574\n",
            "Epoch 446/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0620 - mae: 0.1770 - val_loss: 0.0477 - val_mae: 0.1558\n",
            "Epoch 447/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0619 - mae: 0.1739 - val_loss: 0.0474 - val_mae: 0.1559\n",
            "Epoch 448/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0619 - mae: 0.1766 - val_loss: 0.0480 - val_mae: 0.1540\n",
            "Epoch 449/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0614 - mae: 0.1729 - val_loss: 0.0470 - val_mae: 0.1529\n",
            "Epoch 450/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0613 - mae: 0.1731 - val_loss: 0.0494 - val_mae: 0.1594\n",
            "Epoch 451/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0638 - mae: 0.1792 - val_loss: 0.0535 - val_mae: 0.1605\n",
            "Epoch 452/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0629 - mae: 0.1725 - val_loss: 0.0468 - val_mae: 0.1534\n",
            "Epoch 453/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0601 - mae: 0.1723 - val_loss: 0.0486 - val_mae: 0.1598\n",
            "Epoch 454/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0608 - mae: 0.1749 - val_loss: 0.0483 - val_mae: 0.1558\n",
            "Epoch 455/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0626 - mae: 0.1771 - val_loss: 0.0516 - val_mae: 0.1596\n",
            "Epoch 456/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0594 - mae: 0.1713 - val_loss: 0.0476 - val_mae: 0.1547\n",
            "Epoch 457/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0610 - mae: 0.1750 - val_loss: 0.0456 - val_mae: 0.1513\n",
            "Epoch 458/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0599 - mae: 0.1715 - val_loss: 0.0483 - val_mae: 0.1567\n",
            "Epoch 459/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0623 - mae: 0.1767 - val_loss: 0.0466 - val_mae: 0.1544\n",
            "Epoch 460/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0602 - mae: 0.1747 - val_loss: 0.0484 - val_mae: 0.1537\n",
            "Epoch 461/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0591 - mae: 0.1678 - val_loss: 0.0485 - val_mae: 0.1563\n",
            "Epoch 462/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0602 - mae: 0.1691 - val_loss: 0.0455 - val_mae: 0.1531\n",
            "Epoch 463/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0589 - mae: 0.1719 - val_loss: 0.0480 - val_mae: 0.1600\n",
            "Epoch 464/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0603 - mae: 0.1740 - val_loss: 0.0456 - val_mae: 0.1523\n",
            "Epoch 465/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0577 - mae: 0.1691 - val_loss: 0.0461 - val_mae: 0.1505\n",
            "Epoch 466/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0576 - mae: 0.1684 - val_loss: 0.0447 - val_mae: 0.1509\n",
            "Epoch 467/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0595 - mae: 0.1727 - val_loss: 0.0494 - val_mae: 0.1540\n",
            "Epoch 468/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0584 - mae: 0.1667 - val_loss: 0.0447 - val_mae: 0.1480\n",
            "Epoch 469/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0581 - mae: 0.1680 - val_loss: 0.0451 - val_mae: 0.1518\n",
            "Epoch 470/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0590 - mae: 0.1734 - val_loss: 0.0531 - val_mae: 0.1594\n",
            "Epoch 471/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0593 - mae: 0.1672 - val_loss: 0.0442 - val_mae: 0.1490\n",
            "Epoch 472/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0617 - mae: 0.1723 - val_loss: 0.0492 - val_mae: 0.1536\n",
            "Epoch 473/600\n",
            "600/600 [==============================] - 0s 65us/sample - loss: 0.0575 - mae: 0.1651 - val_loss: 0.0437 - val_mae: 0.1479\n",
            "Epoch 474/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0565 - mae: 0.1663 - val_loss: 0.0434 - val_mae: 0.1477\n",
            "Epoch 475/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.0563 - mae: 0.1671 - val_loss: 0.0448 - val_mae: 0.1512\n",
            "Epoch 476/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0572 - mae: 0.1681 - val_loss: 0.0445 - val_mae: 0.1498\n",
            "Epoch 477/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0569 - mae: 0.1699 - val_loss: 0.0446 - val_mae: 0.1482\n",
            "Epoch 478/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0562 - mae: 0.1633 - val_loss: 0.0454 - val_mae: 0.1524\n",
            "Epoch 479/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0613 - mae: 0.1748 - val_loss: 0.0440 - val_mae: 0.1492\n",
            "Epoch 480/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0562 - mae: 0.1679 - val_loss: 0.0448 - val_mae: 0.1473\n",
            "Epoch 481/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0554 - mae: 0.1638 - val_loss: 0.0462 - val_mae: 0.1483\n",
            "Epoch 482/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0556 - mae: 0.1636 - val_loss: 0.0444 - val_mae: 0.1484\n",
            "Epoch 483/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0549 - mae: 0.1633 - val_loss: 0.0427 - val_mae: 0.1487\n",
            "Epoch 484/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0545 - mae: 0.1647 - val_loss: 0.0457 - val_mae: 0.1483\n",
            "Epoch 485/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0572 - mae: 0.1671 - val_loss: 0.0488 - val_mae: 0.1522\n",
            "Epoch 486/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0566 - mae: 0.1657 - val_loss: 0.0448 - val_mae: 0.1483\n",
            "Epoch 487/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0540 - mae: 0.1620 - val_loss: 0.0430 - val_mae: 0.1495\n",
            "Epoch 488/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0542 - mae: 0.1658 - val_loss: 0.0525 - val_mae: 0.1601\n",
            "Epoch 489/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0550 - mae: 0.1616 - val_loss: 0.0432 - val_mae: 0.1478\n",
            "Epoch 490/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0567 - mae: 0.1677 - val_loss: 0.0429 - val_mae: 0.1495\n",
            "Epoch 491/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0551 - mae: 0.1657 - val_loss: 0.0437 - val_mae: 0.1460\n",
            "Epoch 492/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0556 - mae: 0.1637 - val_loss: 0.0499 - val_mae: 0.1549\n",
            "Epoch 493/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0566 - mae: 0.1640 - val_loss: 0.0417 - val_mae: 0.1439\n",
            "Epoch 494/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0533 - mae: 0.1618 - val_loss: 0.0503 - val_mae: 0.1565\n",
            "Epoch 495/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0569 - mae: 0.1627 - val_loss: 0.0408 - val_mae: 0.1437\n",
            "Epoch 496/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0525 - mae: 0.1606 - val_loss: 0.0423 - val_mae: 0.1445\n",
            "Epoch 497/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0537 - mae: 0.1612 - val_loss: 0.0533 - val_mae: 0.1595\n",
            "Epoch 498/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0554 - mae: 0.1590 - val_loss: 0.0423 - val_mae: 0.1455\n",
            "Epoch 499/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0542 - mae: 0.1615 - val_loss: 0.0411 - val_mae: 0.1466\n",
            "Epoch 500/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0529 - mae: 0.1625 - val_loss: 0.0428 - val_mae: 0.1477\n",
            "Epoch 501/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0535 - mae: 0.1617 - val_loss: 0.0400 - val_mae: 0.1430\n",
            "Epoch 502/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0523 - mae: 0.1603 - val_loss: 0.0406 - val_mae: 0.1436\n",
            "Epoch 503/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0558 - mae: 0.1604 - val_loss: 0.0399 - val_mae: 0.1433\n",
            "Epoch 504/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0521 - mae: 0.1615 - val_loss: 0.0440 - val_mae: 0.1514\n",
            "Epoch 505/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0522 - mae: 0.1608 - val_loss: 0.0420 - val_mae: 0.1422\n",
            "Epoch 506/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0517 - mae: 0.1569 - val_loss: 0.0392 - val_mae: 0.1414\n",
            "Epoch 507/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0516 - mae: 0.1599 - val_loss: 0.0413 - val_mae: 0.1486\n",
            "Epoch 508/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0531 - mae: 0.1613 - val_loss: 0.0399 - val_mae: 0.1438\n",
            "Epoch 509/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0507 - mae: 0.1600 - val_loss: 0.0542 - val_mae: 0.1608\n",
            "Epoch 510/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0568 - mae: 0.1616 - val_loss: 0.0394 - val_mae: 0.1404\n",
            "Epoch 511/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0504 - mae: 0.1563 - val_loss: 0.0423 - val_mae: 0.1469\n",
            "Epoch 512/600\n",
            "600/600 [==============================] - 0s 37us/sample - loss: 0.0503 - mae: 0.1558 - val_loss: 0.0398 - val_mae: 0.1420\n",
            "Epoch 513/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.0507 - mae: 0.1570 - val_loss: 0.0440 - val_mae: 0.1460\n",
            "Epoch 514/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0516 - mae: 0.1561 - val_loss: 0.0413 - val_mae: 0.1448\n",
            "Epoch 515/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0531 - mae: 0.1632 - val_loss: 0.0403 - val_mae: 0.1399\n",
            "Epoch 516/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0505 - mae: 0.1551 - val_loss: 0.0385 - val_mae: 0.1401\n",
            "Epoch 517/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0501 - mae: 0.1567 - val_loss: 0.0394 - val_mae: 0.1440\n",
            "Epoch 518/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0497 - mae: 0.1570 - val_loss: 0.0384 - val_mae: 0.1404\n",
            "Epoch 519/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0495 - mae: 0.1559 - val_loss: 0.0386 - val_mae: 0.1406\n",
            "Epoch 520/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0500 - mae: 0.1575 - val_loss: 0.0378 - val_mae: 0.1386\n",
            "Epoch 521/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0505 - mae: 0.1563 - val_loss: 0.0405 - val_mae: 0.1421\n",
            "Epoch 522/600\n",
            "600/600 [==============================] - 0s 36us/sample - loss: 0.0492 - mae: 0.1549 - val_loss: 0.0388 - val_mae: 0.1431\n",
            "Epoch 523/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0500 - mae: 0.1590 - val_loss: 0.0397 - val_mae: 0.1410\n",
            "Epoch 524/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0492 - mae: 0.1528 - val_loss: 0.0398 - val_mae: 0.1432\n",
            "Epoch 525/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0491 - mae: 0.1550 - val_loss: 0.0370 - val_mae: 0.1378\n",
            "Epoch 526/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0484 - mae: 0.1538 - val_loss: 0.0403 - val_mae: 0.1419\n",
            "Epoch 527/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0527 - mae: 0.1585 - val_loss: 0.0406 - val_mae: 0.1447\n",
            "Epoch 528/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0481 - mae: 0.1522 - val_loss: 0.0381 - val_mae: 0.1422\n",
            "Epoch 529/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0497 - mae: 0.1569 - val_loss: 0.0380 - val_mae: 0.1426\n",
            "Epoch 530/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0483 - mae: 0.1557 - val_loss: 0.0447 - val_mae: 0.1475\n",
            "Epoch 531/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0518 - mae: 0.1555 - val_loss: 0.0408 - val_mae: 0.1403\n",
            "Epoch 532/600\n",
            "600/600 [==============================] - 0s 41us/sample - loss: 0.0488 - mae: 0.1517 - val_loss: 0.0365 - val_mae: 0.1375\n",
            "Epoch 533/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0475 - mae: 0.1546 - val_loss: 0.0378 - val_mae: 0.1392\n",
            "Epoch 534/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0469 - mae: 0.1512 - val_loss: 0.0380 - val_mae: 0.1375\n",
            "Epoch 535/600\n",
            "600/600 [==============================] - 0s 47us/sample - loss: 0.0495 - mae: 0.1546 - val_loss: 0.0361 - val_mae: 0.1365\n",
            "Epoch 536/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0489 - mae: 0.1524 - val_loss: 0.0368 - val_mae: 0.1397\n",
            "Epoch 537/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0477 - mae: 0.1532 - val_loss: 0.0375 - val_mae: 0.1411\n",
            "Epoch 538/600\n",
            "600/600 [==============================] - 0s 18us/sample - loss: 0.0470 - mae: 0.1528 - val_loss: 0.0377 - val_mae: 0.1380\n",
            "Epoch 539/600\n",
            "600/600 [==============================] - 0s 16us/sample - loss: 0.0466 - mae: 0.1495 - val_loss: 0.0359 - val_mae: 0.1369\n",
            "Epoch 540/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0462 - mae: 0.1504 - val_loss: 0.0405 - val_mae: 0.1474\n",
            "Epoch 541/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0497 - mae: 0.1578 - val_loss: 0.0367 - val_mae: 0.1373\n",
            "Epoch 542/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0476 - mae: 0.1537 - val_loss: 0.0373 - val_mae: 0.1399\n",
            "Epoch 543/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0480 - mae: 0.1516 - val_loss: 0.0389 - val_mae: 0.1409\n",
            "Epoch 544/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0463 - mae: 0.1489 - val_loss: 0.0380 - val_mae: 0.1411\n",
            "Epoch 545/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0458 - mae: 0.1488 - val_loss: 0.0392 - val_mae: 0.1428\n",
            "Epoch 546/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0466 - mae: 0.1499 - val_loss: 0.0359 - val_mae: 0.1360\n",
            "Epoch 547/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0489 - mae: 0.1558 - val_loss: 0.0400 - val_mae: 0.1414\n",
            "Epoch 548/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0462 - mae: 0.1474 - val_loss: 0.0360 - val_mae: 0.1359\n",
            "Epoch 549/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0469 - mae: 0.1489 - val_loss: 0.0360 - val_mae: 0.1374\n",
            "Epoch 550/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0448 - mae: 0.1477 - val_loss: 0.0347 - val_mae: 0.1337\n",
            "Epoch 551/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0456 - mae: 0.1484 - val_loss: 0.0368 - val_mae: 0.1408\n",
            "Epoch 552/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0457 - mae: 0.1502 - val_loss: 0.0357 - val_mae: 0.1349\n",
            "Epoch 553/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0465 - mae: 0.1524 - val_loss: 0.0353 - val_mae: 0.1340\n",
            "Epoch 554/600\n",
            "600/600 [==============================] - 0s 17us/sample - loss: 0.0466 - mae: 0.1496 - val_loss: 0.0391 - val_mae: 0.1419\n",
            "Epoch 555/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0455 - mae: 0.1467 - val_loss: 0.0343 - val_mae: 0.1331\n",
            "Epoch 556/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0445 - mae: 0.1483 - val_loss: 0.0357 - val_mae: 0.1355\n",
            "Epoch 557/600\n",
            "600/600 [==============================] - 0s 30us/sample - loss: 0.0443 - mae: 0.1461 - val_loss: 0.0354 - val_mae: 0.1366\n",
            "Epoch 558/600\n",
            "600/600 [==============================] - 0s 35us/sample - loss: 0.0443 - mae: 0.1475 - val_loss: 0.0350 - val_mae: 0.1354\n",
            "Epoch 559/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0446 - mae: 0.1469 - val_loss: 0.0339 - val_mae: 0.1324\n",
            "Epoch 560/600\n",
            "600/600 [==============================] - 0s 29us/sample - loss: 0.0445 - mae: 0.1471 - val_loss: 0.0359 - val_mae: 0.1345\n",
            "Epoch 561/600\n",
            "600/600 [==============================] - 0s 38us/sample - loss: 0.0457 - mae: 0.1516 - val_loss: 0.0356 - val_mae: 0.1359\n",
            "Epoch 562/600\n",
            "600/600 [==============================] - 0s 43us/sample - loss: 0.0436 - mae: 0.1453 - val_loss: 0.0347 - val_mae: 0.1358\n",
            "Epoch 563/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0435 - mae: 0.1470 - val_loss: 0.0405 - val_mae: 0.1397\n",
            "Epoch 564/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0464 - mae: 0.1470 - val_loss: 0.0346 - val_mae: 0.1334\n",
            "Epoch 565/600\n",
            "600/600 [==============================] - 0s 49us/sample - loss: 0.0432 - mae: 0.1436 - val_loss: 0.0357 - val_mae: 0.1395\n",
            "Epoch 566/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0437 - mae: 0.1473 - val_loss: 0.0331 - val_mae: 0.1323\n",
            "Epoch 567/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0428 - mae: 0.1454 - val_loss: 0.0347 - val_mae: 0.1333\n",
            "Epoch 568/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0431 - mae: 0.1428 - val_loss: 0.0365 - val_mae: 0.1383\n",
            "Epoch 569/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0451 - mae: 0.1479 - val_loss: 0.0331 - val_mae: 0.1314\n",
            "Epoch 570/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0439 - mae: 0.1488 - val_loss: 0.0355 - val_mae: 0.1387\n",
            "Epoch 571/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0433 - mae: 0.1502 - val_loss: 0.0386 - val_mae: 0.1412\n",
            "Epoch 572/600\n",
            "600/600 [==============================] - 0s 33us/sample - loss: 0.0448 - mae: 0.1448 - val_loss: 0.0331 - val_mae: 0.1300\n",
            "Epoch 573/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0418 - mae: 0.1412 - val_loss: 0.0338 - val_mae: 0.1329\n",
            "Epoch 574/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0431 - mae: 0.1479 - val_loss: 0.0357 - val_mae: 0.1419\n",
            "Epoch 575/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0422 - mae: 0.1437 - val_loss: 0.0324 - val_mae: 0.1310\n",
            "Epoch 576/600\n",
            "600/600 [==============================] - 0s 23us/sample - loss: 0.0430 - mae: 0.1444 - val_loss: 0.0333 - val_mae: 0.1322\n",
            "Epoch 577/600\n",
            "600/600 [==============================] - 0s 24us/sample - loss: 0.0415 - mae: 0.1421 - val_loss: 0.0339 - val_mae: 0.1316\n",
            "Epoch 578/600\n",
            "600/600 [==============================] - 0s 34us/sample - loss: 0.0431 - mae: 0.1441 - val_loss: 0.0344 - val_mae: 0.1347\n",
            "Epoch 579/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0437 - mae: 0.1486 - val_loss: 0.0332 - val_mae: 0.1339\n",
            "Epoch 580/600\n",
            "600/600 [==============================] - 0s 31us/sample - loss: 0.0415 - mae: 0.1416 - val_loss: 0.0327 - val_mae: 0.1328\n",
            "Epoch 581/600\n",
            "600/600 [==============================] - 0s 25us/sample - loss: 0.0418 - mae: 0.1449 - val_loss: 0.0328 - val_mae: 0.1312\n",
            "Epoch 582/600\n",
            "600/600 [==============================] - 0s 32us/sample - loss: 0.0470 - mae: 0.1509 - val_loss: 0.0311 - val_mae: 0.1275\n",
            "Epoch 583/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0411 - mae: 0.1435 - val_loss: 0.0333 - val_mae: 0.1325\n",
            "Epoch 584/600\n",
            "600/600 [==============================] - 0s 28us/sample - loss: 0.0415 - mae: 0.1417 - val_loss: 0.0354 - val_mae: 0.1392\n",
            "Epoch 585/600\n",
            "600/600 [==============================] - 0s 27us/sample - loss: 0.0424 - mae: 0.1455 - val_loss: 0.0328 - val_mae: 0.1328\n",
            "Epoch 586/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0405 - mae: 0.1411 - val_loss: 0.0344 - val_mae: 0.1326\n",
            "Epoch 587/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0426 - mae: 0.1426 - val_loss: 0.0313 - val_mae: 0.1289\n",
            "Epoch 588/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0419 - mae: 0.1450 - val_loss: 0.0311 - val_mae: 0.1274\n",
            "Epoch 589/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0401 - mae: 0.1402 - val_loss: 0.0309 - val_mae: 0.1279\n",
            "Epoch 590/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0401 - mae: 0.1415 - val_loss: 0.0306 - val_mae: 0.1271\n",
            "Epoch 591/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0404 - mae: 0.1416 - val_loss: 0.0337 - val_mae: 0.1315\n",
            "Epoch 592/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0422 - mae: 0.1460 - val_loss: 0.0320 - val_mae: 0.1315\n",
            "Epoch 593/600\n",
            "600/600 [==============================] - 0s 20us/sample - loss: 0.0399 - mae: 0.1408 - val_loss: 0.0346 - val_mae: 0.1354\n",
            "Epoch 594/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0428 - mae: 0.1447 - val_loss: 0.0323 - val_mae: 0.1327\n",
            "Epoch 595/600\n",
            "600/600 [==============================] - 0s 22us/sample - loss: 0.0405 - mae: 0.1426 - val_loss: 0.0304 - val_mae: 0.1262\n",
            "Epoch 596/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0395 - mae: 0.1408 - val_loss: 0.0332 - val_mae: 0.1329\n",
            "Epoch 597/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0401 - mae: 0.1390 - val_loss: 0.0309 - val_mae: 0.1297\n",
            "Epoch 598/600\n",
            "600/600 [==============================] - 0s 19us/sample - loss: 0.0393 - mae: 0.1405 - val_loss: 0.0299 - val_mae: 0.1257\n",
            "Epoch 599/600\n",
            "600/600 [==============================] - 0s 26us/sample - loss: 0.0397 - mae: 0.1406 - val_loss: 0.0303 - val_mae: 0.1259\n",
            "Epoch 600/600\n",
            "600/600 [==============================] - 0s 21us/sample - loss: 0.0389 - mae: 0.1391 - val_loss: 0.0302 - val_mae: 0.1273\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}